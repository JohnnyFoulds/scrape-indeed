[{"JobTitle":" Database Administrator - AWS/ Azure","Url":"https://www.indeed.co.za/pagead/clk?mo=r&ad=-6NYlbfkN0AMOOo83f3x9FLd22RLK3YfFusStXJLn5R4tAT9NKF0tAvdVEybpYDI30GAsFF9juak1s8CYOn1JDC3CkKQ6iRkDSYPSYKX8Z_3q9xm6EmXHSho3kZ5oQQvAxDJ7VjGusL9dCuPoPkG5IQVTp8hCPE4miamZrJQhjxYcNQ-Rrcyg6mpMuKmXBJ_Yqp9oZWlnpULrH3ybeGQPupTuq7TLQ114TJ84SxC2eACVvpuaIRXCS9PdUlZxZOnh5jzAPbfnMJqrmjK2iZca6s4HK_FB2lJIfUnc53MsOrkZZEfEJ_aZbxxZE_vSarMtMV9XaASb8xmt9EdcYsgUTftvVMRblx4LXYqTB7lMMxdLwYGTahTdmvROodU2tmmvbqB9k58dEVa47fAFa2B1a6Lm2lWG6c72MDcG4NIzhx2HQOfvweUDQtnAliEuWTNolXtVM4u08sSwTRymyxk3cbx6Say4JWJ2XCy3nJu7WIalwPuDQq-QwkTfX3psnf0EQEqlhjz2ISaESwJ_DbCfAPkooU1PvPWlUxWkFl4C_-W3GqkyuNp6ROaMGSuI5-nHD5gdQQ9Jw7D72FBeqSf-YugOOIachBjp1U5OwHR1h6ZKT4N-cyetw==&p=0&fvj=0&vjs=3","Source":" Data Centrix","Age":null,"Salary":null,"Location":"Cape Town, Western Cape","Description":"\r\n\r\n\r\nCape Town, Western Cape\r\n\r\n\r\nResponsibilities\r\n To research, evaluate and recommend NoSQL products\r\n Evaluate pros and cons of NoSQL products\r\n Produce documentation to be used in solution architecture decision making\r\n Rank ease of setup and management effort required for each product\r\n Rank monitoring and alerting capabilities for each product\r\n Determine best use cases for each product\r\n Conduct system performance testing for each product\r\n Perform daily database operational tasks ensuring databases are backed up and running optimally.\r\n Assist Development Teams in designing, modelling and validating NoSQL solutions for their applications\r\n Liaise closely with development teams gathering their requirements.\r\n Propose appropriate NoSQL database management system\r\n Ensure cloud based solutions are built optimally, keeping maximum cost saving in mind\r\n To ensure information security and regulatory compliance:\r\n Ensuring system security meets regulatory compliance\r\n Manage server security remediation activities which will include conducting vulnerability scans and patching\r\n To carry out database administration tasks ensuring data is available, protected and recoverable\r\n Perform daily health checks for databases and resolve any issues identified\r\n Ensure database backups are scheduled and completing successfully\r\n Verify backups are valid by testing restore process regularly.\r\n Monitor databases so that capacity constraints can be mitigated by timeous provisioning of resources.\r\n Close incidents within SLA\r\n Execute database changes according to change management process\r\n Assist developers with any database issues\r\n\r\n Qualifications and Experience\r\n Grade 12 \r\nIndustry Certification: AWS Associate Architect and Developer certificate (advantageous)\r\n 3+ years Managing all aspects of NoSQL database management systems from installation , configuration , backup management and security\r\n 3+ years Managing all aspects of NoSQL database management systems from installation , configuration , backup management and security\r\n 3+ years Experience working with services in AWS\r\n 3+ years Exposure to one or more Apache Software Foundation Big Data & Database projects such as Cassandra, Hadoop, Hbase, MongoDB\r\n 3+ years Proficient with some of the common developer tool sets such as Java, XML, JSON, REST, Shell, Perl and Python\r\n 4+ years General understanding of database management concepts\r\n 3+ years Basic familiarity with Linux operating system\r\n 3+ years Some experience engineering and/or administering NoSQL infrastructure\r\n 3+ years Proficient with one or more Apache Software Foundation Big Data & Database projects such as Cassandra, Hadoop, Hbase, MongoDB\r\n 2+ years Knowledgeable in designing, developing & documenting use cases.\r\n 3+ years Proficient with some of the common developer tool sets such as Java, XML, JSON, REST, Shell, Perl"},{"JobTitle":" SENIOR DATA ENGINEER","Url":"https://www.indeed.co.za/company/PEPKOR/jobs/Senior-Data-Engineer-b151ab5a05b44e17?fccid=8fdbbfa32556ef52&vjs=3","Source":" Pepkor","Age":"4 days ago","Salary":null,"Location":"Tygervalley, Western Cape","Description":"\r\n\r\n\r\nTygervalley, Western Cape\r\n\r\nPURPOSE OF THE JOB\r\nWe are looking for a data/ML Engineer that will assist and work closely with the Data Science Team to develop and implement practical and realistic data modelling solutions within the business. These solutions must also be made to be long lasting, fail-safe and reusable, with a strong focus on automation.\r\n\r\nKEY RESPONSIBILITIES:\r\nEnsures that all production analytical products are working properly in terms of actual execution and requirements\r\nEnsures that output/products from the Data Science team is usable in production, maintainable, scalable and reusable\r\nAutomates and abstracts away different repeatable routines that are present in most machine learning tasks\r\nEnables the best product development practices are used within the team and helps them to speed up work from an advisory perspective\r\nIntegral part of choosing architectural environment and tool choices\r\nCollaborate with data engineers and IT teams to build data and model pipelines\r\nManage the infrastructure and data pipelines needed to bring code to production\r\nUnderstand and use computer science fundamentals, including data structures, algorithms, computability and complexity and computer architecture\r\nUse mathematical skills, in order to perform computations and work with the algorithms involved in this type of programming\r\nDemonstrate end-to-end understanding of applications (including, but not limited to, the machine learning algorithms) being created\r\nUnderstand algorithms based on statistical modelling procedures and build and maintain scalable machine learning solutions in production\r\nCommunicate and explain complex processes to people who are not programming experts\r\nLiaise with stakeholders to analyse business problems, clarify requirements and define the scope of the resolution needed\r\nResearch and implement best practices to improve the existing machine learning infrastructure\r\n\r\nJOB INCUMBENT REQUIREMENTS\r\nBachelor's degree in Computer Science, Engineering, Information Systems, or similar degrees.\r\n3 + years' of experience in data engineering or software development would be advantageous\r\nDeep understanding of predictive modelling, machine-learning, clustering and classification techniques, and algorithms such as k-NN, Naive Bayes, SVM, Decision Forests, etc.\r\nFluency in a programming language including but not limited to Python, SQL\r\nExperience in cloud technologies would be advantageous\r\nFamiliarity with Big Data frameworks (Cassandra, Hadoop, Spark)\r\nExperience with data visualisation tools, such as D3.js, GGplot, Shiny, etc.would be an advantage\r\nExperience with NoSQL databases, such as MongoDB, Cassandra, HBase would be an advantage\r\nGreat communication skills\r\nWorks well in a team\r\n\r\nJob Type: Full-time"},{"JobTitle":" Senior Data Engineer","Url":"https://www.indeed.co.za/rc/clk?jk=2ac4dd802f3e65b3&fccid=745f50042cd32f08&vjs=3","Source":" Unique Personnel","Age":"4 days ago","Salary":null,"Location":"South Africa","Description":"\r\n\r\n\r\nSouth Africa\r\n\r\n\r\nContract\r\n\r\n\r\n\r\n\r\n\r\nJob Listing \r\n\r\n\r\n\r\n\r\n\r\nJob Number\r\n\r\n58073 \r\n\r\n\r\n\r\n\r\nJob Type\r\n\r\nContract \r\n\r\n\r\n\r\n\r\nJob Title\r\n\r\nSenior Data Engineer \r\n\r\n\r\n\r\n\r\nComputer Skills\r\n\r\nData Analytics,Database Administration,Java,MS Excel,MS Outlook,MS PowerPoint,MS SQL,MS Word,MySQL,Python,SQL,Windows 10 \r\n\r\n\r\n\r\n\r\nIndustry\r\n\r\nIT Development & Software \r\n\r\n\r\n\r\n\r\nCity\r\n\r\nPlease select city \r\n\r\n\r\n\r\n\r\nProvince\r\n\r\nGauteng \r\n\r\n\r\n\r\n\r\nJob Description\r\n\r\nThe Senior Data Engineer is responsible for overseeing junior data engineering activities and aiding in building the business’ data collection systems and processing pipelines. The role of the Senior Data Engineer is responsible for building and maintaining optimized and highly available data pipelines that facilitate deeper analysis and reporting by the Data and Analytics department. The Senior Data Engineer builds data processing frameworks that handle the business’s growing database. He works with senior data science leadership as well as other Data and Analytics teams in leveraging data with reporting and scientific tools, for example, Tableau, R, and Spark. The Senior Data Engineer strives to continuously develop new and improved data engineering capabilities. Management and Strategy: The managerial role of the Senior Data Engineer is primarily for overseeing activities of the junior data engineering teams, ensuring proper execution of their duties and alignment with business vision and objectives. He provides senior-level contribution to a team that is responsible for the design, deployment, and maintenance of the business’s data platforms. However, the Senior Data Analyst will also implement strategies directed at acquiring data and promoting the development of new insights across the business. The Senior Data Engineer owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets. It is his duty to monitor the existing metrics, analyze data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. The Senior Data Engineer will additionally develop queries for ad hoc business projects, as well as ongoing reporting. In this capacity, the Senior Data Engineer builds a metadata system where all available data is maintained and cataloged. The Senior Data Engineer also plays a major role in the development of reliable data pipelines that translate raw data into powerful features and signals. He designs, architects, implements, and supports key datasets that avail structured and timely access to actionable business insights. The Senior Data Engineer is additionally tasked with developing ETL processes that convert data into formats through a team of data analysts and dashboard charts. Collaboration and Support: The Senior Data Engineer plays a collaborative role where he works closely with the business’s Data and Analytics teams, gathering technical requirements for exceptional data governance across the department and the business at large. In this collaboration, the Senior Data Engineer works the data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large. The Senior Data Engineer will also work with senior data science management and departments beyond the Data and Analytics department in analyzing and understanding data sources, participating in design, and providing insights and guidance on database technology and data modeling best practices. In this capacity, the Senior Data Engineer will further be required to draw performance reports and strategic proposals form his gathered knowledge and analyses results for senior data science leadership. Analytics: The Senior Data Engineering plays an analytical role where he develops and manages scalable data processing platforms that he uses for exploratory data analysis and real-time analytics. It is also the role of the Senior Data Engineer to oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and efficient data acquisition. In this capacity, the Senior Data Engineer retrieves and analyzes data through the use of SQL, Excel, among other data management systems. He also builds data loading services for the purpose of importing data from numerous disparate data sources, inclusive of APIs, logs, relational, and non-relational databases. Knowledge and Opportunity: The Senior Data Engineer is tasked with the responsibility of contributing to the continual improvement of the business’s data platforms through his observations and well-researched knowledge. He keeps track of industry best practices and trends and through his acquired knowledge, takes advantage of process and system improvement opportunities. Other Duties: The Senior Data Engineer performs similar duties as he deems fit for the proper execution of his duties and duties as delegated by the Head of Data Science, Director Data Science, Chief Data Officer, or the Employer. Experience: A candidate for this position must have had at least 5 years of working experience working in a data engineering department, preferably as a Data Engineer in a fast-paced environment and complex business setting. The candidate must have a demonstrated experience in building and maintaining reliable and scalable ETL on big data platforms as well as experience working with varied forms of data infrastructure inclusive of relational databases such as SQL, Hadoop, Spark and column-oriented databases such as Redshift, MySQL, and Vertica. The candidate must also have had experience in data warehousing inclusive of dimensional modeling concepts and demonstrate proficiency in scripting languages, for example, Python, Perl, and so forth. A suitable candidate will also demonstrate machine learning experience and experience with big data infrastructure inclusive of MapReduce, Hive, HDFS, YARN, HBase, Oozie, etc. The candidate will additionally demonstrate substantial experience and a deep knowledge of data mining techniques, relational, and non-relational databases. Communication Skills: Communication Skills for the Senior Data Engineer are just as important as they are for the Data Engineer, both in verbal and written form. The Senior Data Engineer oversees and manages junior data engineering teams and to ensure effective management, he must be capable of conveying information and instructions clearly down the line to the junior team. Communication skills are also imperative for the Senior Data Engineer in his collaborative role where he will have to interact cross-functionally with non-technical departments. To enable effective collaborations, the Senior Data Engineer will have an exceptional ability to convey complex messages in a clear, simplified, and understandable manner. He will also be required to draft reports and prepare presentations for senior data science leadership. These reports and presentation must be clear, concise, unambiguous, engaging and convincing, which will demand exceptional communication skills on the Senior Data Engineer’s part. Ms Office/Software: A candidate for this position must be highly proficient in the use of Ms Word, Ms Excel, PowerPoint, and Outlook, which will all be necessary for the creation of both visually and verbally engaging reports and presentations, for senior data science leadership. The Senior Data Engineer must further have exceptional skills in SQL server reporting services, analysis services, Tableau, Salesforce, integration services, or any other data visualization tools. Technological Savvy/Analytical Skills: A candidate for this position will also demonstrate strong computer skills and a deep passion for analytics. The candidate for this position must possess an ability to perform complex data analyses with large data volumes. He will be an expert in SQL, Java, and have a keen understanding of data models and data warehouse concepts. The candidate will demonstrate an ability translate algorithms provided by senior data science management and implement them in as well as strong knowledge in Linux, OS tools, and file-system level troubleshooting. The candidate must have substantial experience working with big data infrastructure tools such as Python, SQS, and Redshift. A suitable candidate will also be proficient Scala, Spark, Spark Streaming, AWS, and EMR. Interpersonal Skills: The Senior Data Engineer must have certain preferable personal attributes that will make him that much more suited for the position. The Senior Data Engineer will be a result-driven individual, be passionate and a self-starter, be proactive requiring minimal supervision, be highly organized, have an ability to handle multiple tasks and meet tight deadlines, be a creative and strategic thinker, work comfortably work in a collaborative setting, work comfortably with senior departmental leadership, and demonstrate an ability to remain calm during times of uncertainty and stress, inspiring the same in his team. People Skill: The candidate must be a people person who is able to form strong, meaningful, and lasting connections with others, enabling smooth and continued collaborative relationships, earning him the trust of his juniors who will readily follow in his directives, and gaining the confidence of senior data science leadership \r\n\r\nTo apply immediately for this position click here: http://www.unique.co.za/candidate_registration_1.aspx?JobID=58073&referrer=Unique\r\n\r\n\r\n\r\n\r\nInherent Requirements\r\n\r\nThe Senior Data Engineer must have a bachelor’s degree (masters’ preferred) in Computer Science, Applied Mathematics, Engineering, or any other technology related field. An equivalent of this educational requirement in working experience is also acceptable. \r\n\r\n\r\n\r\n\r\nWhat Qualification\r\n\r\nRelated to Industry \r\n\r\n\r\n\r\n\r\nMinimum Qualification\r\n\r\nMasters \r\n\r\n\r\n\r\n\r\nStatus\r\n\r\nAvailable"},{"JobTitle":" NoSQL Database Administrator II","Url":"https://www.indeed.co.za/rc/clk?jk=948122757574f2a9&fccid=26d01f64c124ba71&vjs=3","Source":" Datafin IT Recruitment","Age":"12 days ago","Salary":null,"Location":"Cape Town, Western Cape","Description":"\r\n\r\n\r\nCape Town, Western Cape\r\n\r\n\r\nPermanent\r\n\r\n\r\n\r\n–\r\n4+ Years –\r\nGeneral understanding of database management concepts.\r\n 3+ Years –\r\nManaging all aspects of NoSQL database management systems from installation, configuration, backup management and security.\r\n Working with services in AWS.\r\n Exposure to one or more Apache Software Foundation Big Data & Database projects such as Cassandra, Hadoop, Hbase, MongoDB.\r\n Proficient with some of the common developer tool sets such as Java, XML, JSON, REST, Shell, Perl and Python.\r\n Installing, configuring, administering, using and benchmarking NoSQL solutions.\r\n Basic familiarity with Linux operating system.\r\n 2+ Years –\r\nKnowledgeable in designing, developing & documenting use cases.\r\n\r\nWhile we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.\r\n\r\nCOMMENTS:\r\n When applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence. Please e-mail a word copy of your CV to taryn@datafin.com and mention the reference numbers of the jobs."},{"JobTitle":" NoSQL Database Administrator","Url":"https://www.indeed.co.za/company/Recru--IT/jobs/Nosql-Database-Administrator-7a50e8e07ac04416?fccid=7ce178ce4d9efe7d&vjs=3","Source":" Recru-IT","Age":"11 days ago","Salary":null,"Location":"Brackenfell, Western Cape","Description":"\r\n\r\n\r\nBrackenfell, Western Cape\r\n\r\nPosition Purpose: \r\n\r\nThis position involves researching, evaluating and recommending NoSQL database management products available in AWS, Azure and Google cloud platforms.\r\n\r\nThe person will also have to do daily operational support of these databases as well as engage with developers to gain an understanding of their requirements and propose appropriate database management technologies.\r\n\r\nQualifications: \r\n\r\nGrade 12\r\n\r\nIndustry Certification: AWS Associate Architect and Developer certificate (Advantageous)\r\n3+ years Managing all aspects of NoSQL database management systems from installation , configuration , backup management and security\r\n3+ years Experience working with services in AWS\r\n3+ years Exposure to one or more Apache Software Foundation Big Data & Database projects such as Cassandra, Hadoop, Hbase, MongoDB\r\n3+ years Proficient with some of the common developer tool sets such as Java, XML, JSON, REST, Shell, Perl and Python.\r\n\r\nKnowledge: \r\n4+ years General understanding of database management concepts\r\n\r\nSkills: \r\n3+ years Proficient with installing, configuring, administering, using and benchmarking NoSQL solutions.\r\n3+ years Basic familiarity with Linux operating system\r\n3+ years Some experience engineering and/or administering NoSQL infrastructure\r\n3+ years Proficient with one or more Apache Software Foundation Big Data & Database projects such as Cassandra, Hadoop, Hbase, MongoDB\r\n2+ years Knowledgeable in designing, developing & documenting use cases.\r\n3+ years Proficient with some of the common developer tool sets such as Java, XML, JSON, REST, Shell, Perl and etc.\r\n\r\nJob objectives: \r\n\r\nTo research, evaluate and recommend NoSQL products: \r\nEvaluate pros and cons of NoSQL products\r\nProduce documentation to be used in solution architecture decision making\r\nRank ease of setup and management effort required for each product\r\nRank monitoring and alerting capabilities for each product\r\nDetermine best use cases for each product\r\nConduct system performance testing for each product\r\nPerform daily database operational tasks ensuring databases are backed up and running optimally.\r\n\r\nAssist Development Teams in designing, modelling and validating NoSQL solutions for their applications: \r\nLiaise closely with development teams gathering their requirements.\r\nPropose appropriate NoSQL database management system\r\nEnsure cloud based solutions are built optimally, keeping maximum cost saving in mind\r\n\r\nTo ensure information security and regulatory compliance: \r\nEnsuring system security meets regulatory compliance\r\nManage server security remediation activities which will include conducting vulnerability scans and patching\r\n\r\nTo carry out database administration tasks ensuring data is available, protected and recoverable: \r\nPerform daily health checks for databases and resolve any issues identified\r\nEnsure database backups are scheduled and completing successfully\r\nVerify backups are valid by testing restore process regularly.\r\nMonitor databases so that capacity constraints can be mitigated by timeous provisioning of resources.\r\nClose incidents within SLA\r\nExecute database changes according to change management process\r\nAssist developers with any database issues\r\n\r\nSend a detailed copy of your CV to Bonita (bonita AT recru-it.co.za – replace the AT with @)\r\n\r\nShould you not be contacted within 7 days, please consider your application as unsuccessful.\r\n\r\nJob Type: Full-time"},{"JobTitle":" Database Administrator II","Url":"https://www.indeed.co.za/rc/clk?jk=7719004d783bd87f&fccid=cfba5d68db1b7af1&vjs=3","Source":" GoldenRule","Age":"10 days ago","Salary":null,"Location":"Cape Town, Western Cape","Description":"\r\n\r\n\r\nCape Town, Western Cape\r\n\r\n\r\nPermanent\r\n\r\n\r\n\r\nThe Role\r\n\r\nThis position involves researching, evaluating and recommending NoSQL database management products available in AWS, Azure and Google cloud platforms. The person will also have to do daily operational support of these databases as well as engage with developers to gain an understanding of their requirements and propose appropriate database management technologies.\r\n\r\n\r\n\r\n1. RTO RESEARCH, EVALUATE AND RECOMMEND NoSQL PRODUCTS:\r\nEvaluate the pros and cons of NoSQL products\r\nProduce documentation to be used in solution architecture decision making\r\nRank ease of setup and management effort required for each product\r\nRank monitoring and alerting capabilities for each product\r\nDetermine the best use cases for each product\r\nConduct system performance testing for each product\r\nPerform daily database operational tasks ensuring databases are backed up and running optimally\r\n2. ASSIST DEVELOPMENT TEAM IN DESIGNING, MODELING AND VALIDATING NoSQL SOLUTIONS FOR THEIR APPLICATIONS:\r\nLiaise closely with development teams gathering their requirements\r\nPropose appropriate NoSQL database management system\r\nEnsure cloud-based solutions are built optimally, keeping maximum cost saving in mind\r\n3. TO ENSURE INFORMATION SECURITY AND REGULATORY COMPLIANCE:\r\nEnsuring system security meets regulatory compliance\r\nManage server security remediation activities which will include conducting vulnerability scans and patching\r\n4. TO CARRY OUT DATABASE ADMINISTRATION TASKS ENSURING DATA IS AVAILABLE, PROTECTED AND RECOVERABLE:\r\nPerform daily health checks for databases and resolve any issues identified\r\nEnsure database backups are scheduled and completing successfully\r\nVerify backups are valid by testing to restore process regularly\r\nMonitor databases so that capacity constraints can be mitigated by timeous provisioning of resources\r\nClose incidents within SLA\r\nExecute database changes according to the change management process\r\nAssist developers with any database issues\r\n\r\n\r\nSkills and Experience\r\n\r\nQUALIFICATIONS:\r\nGrade 12\r\nIndustry Certification:\r\no AWS Associate Architect and Developer certificate (advantageous)\r\n\r\nEXPERIENCE:\r\n Essential:\r\n3 + years managing all aspects of NoSQL database management systems from installation, configuration, backup management, and security\r\n3 + years’ Experience working with services in AWS\r\n3 + years Exposure to one or more Apache Software Foundation Big Data & Database projects such as Cassandra, Hadoop, Hbase, MongoDB\r\n3 + years Proficient with some of the common developer toolsets such as Java, XML, JSON, REST, Shell, Perl, and Python\r\n\r\n KNOWLEDGE:\r\n4 + years General understanding of database management concepts\r\n\r\n\r\nSKILLS:\r\n Essential:\r\n3 + years Proficient with installing, configuring, administering, using and benchmarking NoSQL solutions\r\n3 + years Basic familiarity with Linux operating system\r\n3 + years Some experience engineering and/or administering NoSQL infrastructure\r\n3 + years Proficient with one or more Apache Software Foundation Big Data and Database projects such as Cassandra, Hadoop, Hbase, MongoDB\r\n2 + years Knowledgeable in designing, developing and documenting use cases.\r\n3 + years Proficient with some of the common developer toolsets such as Java, XML, JSON, REST, Shell, Perl and etc."},{"JobTitle":" Senior Specialist: Support Analyst","Url":"https://www.indeed.co.za/rc/clk?jk=acbd902ab746d6c9&fccid=374d720d3973ca1c&vjs=3","Source":" Vodafone","Age":"30+ days ago","Salary":null,"Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\n\r\nVodacom is a Leading African Mobile communication company providing wider range of communication services including mobile voice, messaging, data and converged services to over 73.6 million customers. From our roots in South Africa, we have grown our mobile network business to include operations in Tanzania, DRC, Mozambique and Lesotho. The mobile networks cover a total population of approximately 200 million people. Through Vodacom Business Africa (VBA) we also offer business managed services to enterprises in over 40 countries across the continent. Vodafone is the majority shareholder of Vodacom and has a 65% share.\r\n\r\n\r\n\r\n\r\n\r\nWere at our best when we lead and over the past 20 years, as the Company that pioneered mobile in South Africa, Vodacom has achieved a remarkable list of firsts. Were immensely proud to be a leader in our field and are 100% committed to continue trailblazing.\r\n\r\n\r\n\r\n\r\nWe employ individuals who are as passionate about customers as we are. We are truly Customer Obsessed which means that we are passionate about exceeding customer expectations; work relentlessly to really understand the customer; look at decisions through the customers eyes and take personal accountability for the customer experience.\r\n\r\n\r\n\r\n\r\nWe have the below vacancy available in our Organisation:\r\n\r\n\r\n\r\n\r\n\r\nThe G Band Senior Specialist: Support Analyst role is based within Local Technology\r\n\r\n\r\n\r\n\r\n\r\nThe role of the Senior Specialist: Support Analyst is to be responsible for and ensuring of data import and processing into the BDP. Installation of CDH repository, OS level configuration, new type of I/O compression library cluster, and Hadoop installation &support including the Cloudera manager, adding new nodes and services to the cluster\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nYour responsibilities will include:\r\n\r\n\r\n Configure and Maintain Name Node/ Resource manager High Availability (HA), including Hive, Impala\r\n\r\n\r\n\r\n Manage cluster support by rebalancing the cluster, setting up alerting for disk fill, and YARN resource management;\r\n\r\n\r\n\r\nConfigure HDFS ACLs, Sentry, Hue user authorization and authentication;\r\n\r\n\r\n\r\nContinuous benchmarking of the cluster s operational metrics, test systems configuration for operational efficiency;\r\n\r\n\r\n\r\nResolve all logged incidences and service requests (SR) Troubleshoot and resolve errors/warnings in Cloudera Manager and application delays. Resolve performance problems/errors in operations\r\n\r\n\r\n Provide guidance and decisive technical leadership\r\n\r\n\r\n Ensure the BDP cluster is secured from potential vulnerabilities\r\n\r\n\r\n Provided a leadership role with key stakeholders for optimal deliverance of use cases\r\n\r\n\r\n Drive DevOps way of working\r\n\r\n\r\n Expert level experience with using Spark, Yarn, Hive and Oozie\r\n\r\n\r\n Python and Scala programming ability will be an advantage\r\n\r\n\r\n Working knowledge of HBase, Kafka, Cassandra and Flume\r\n\r\n\r\n Ability to work standby and overtime when required\r\n\r\n\r\n Expert knowledge of NiFi, Sqoop and Flume will be an added advantage.\r\n\r\n\r\n\r\n\r\n\r\n\r\nKey accountabilities and decision ownership:\r\n\r\n\r\n\r\nExtensive experience in designing, building and managing BDP applications in ingesting and storing large amounts of data in a Hadoop/HDFS ecosystem;\r\n Extensive experience with performance tuning applications on Hadoop/YARN and configuring Hadoop/YARN systems to maximise performance;\r\n Extensive experience in installing, testing, configuring BDP ecosystems\r\n Extensive experience is solving complex requests or service impacting incidents within the BDP cluster\r\n Experience working in a multi tenancy Hadoop environment\r\n\r\n\r\n\r\n\r\n\r\nCore competencies, knowledge and experience:\r\n\r\n Hadoop,\r\n\r\n YARN,\r\n Linux,\r\n HDFS\r\n CDH\r\n Scripting/Java/Python/R\r\n\r\n\r\n\r\n The ideal candidate for this role will have:\r\n Matric/ Grade 12 qualification\r\n 3 year completed Ndip/Degree in Information Technology or equivalent\r\n At least 5-8 years IT experience (Telecoms or Fixed mobile advantageous)\r\n CCA131 certification (desirable)\r\n Knowledge of Big Data (essential)\r\n Agile Methodology(desirable)\r\n Hadoop or YARN or Linux or HDFS or CDH or Scripting/Java/Python/R (essential)\r\n\r\n\r\n\r\nIn addition to the details listed above, the ideal candidate will have an in-depth knowledge and understanding\r\n\r\n\r\n\r\n Availability and optimal functioning of the BDP cluster ecosystems\r\n Servicing incidents and service requests in a timely manner\r\n Adjustment to the Agile environment\r\n\r\n\r\n\r\nThe base location for this role is Midrand, Commercial Park\r\n\r\n\r\n\r\nThe Companys approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply.\r\n\r\n\r\n\r\nVodacom is committed to an organisational culture that recognises, appreciates and values diversity inclusion."},{"JobTitle":" Data Scientist","Url":"https://www.indeed.co.za/company/FletchSys-Technologies/jobs/Data-Scientist-d5af1d22799a5dec?fccid=e3fced02ca80240f&vjs=3","Source":" FletchSys Technologies","Age":"3 days ago","Salary":null,"Location":"Cape Town, Western Cape","Description":"\r\n\r\n\r\nCape Town, Western Cape\r\n\r\nJob Summary\r\nThe position is for Kenya Location - No bar fro Right candidate. Housing , Car and Secured Job from Kenya's top most company .\r\n\r\nWe are looking for a 5 to 7 Years experienced candidate into data science.\r\nResponsibilities and Duties\r\n\r\nQualifications\r\nBSC. or MS. in Computer Science, Statistics, Mathematics or equivalent practical experience\r\n2 – 4 years data science working experience and with a leadership role.\r\nExcellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests\r\n\r\nExperience with common data science toolkits, such as R, Weka, NumPy, MatLab\r\nExperience with data visualization tools, such as D3.js, GGplot\r\nExperience with NoSQL databases, such as MongoDB, Cassandra, HBase\r\nGood applied statistics skills, such as distributions, statistical testing, regression\r\nGood scripting and programming skills\r\nGood understanding of big data technologies like Hadoop\r\nStrong communications and interpersonal skills and quick grasps to understand business problems\r\n\r\nRequired Experience, Skills and Qualifications\r\n\r\nReporting to the Head of Big Data & Business Analytics, the position holder will lead the data science team to create value from Safaricom’s vast amount and variety of data using advance analytical and statistical methods and models to answer complex business questions. This will serve to aid in decision making, unlock new revenue opportunities and areas to create efficiency through deep insights.\r\nThe role requires deployment of Artificial Intelligence driven by Companies data to create Machine learning models and solutions to deliver specific business relevant use cases. Safaricom is investing heavily in big data and this will be a truly exciting role in view of the organizations unique data set and position in this region.\r\n\r\nResponsibilities\r\nData mining using state-of-the-art methods\r\nSelecting features, building and optimizing classifiers using machine learning techniques\r\nProcessing, cleansing, and verifying the integrity of data used for analysis\r\nCollaborate with business units and engineering teams to understand and prioritize company needs and devise possible solutions based on business use cases\r\nCreate various machine learning-based tools or processes within the company, such as recommendation engines or automated lead scoring systems to drive revenue or create cost efficiencies\r\nCreate visualizations using state of the art visualization tools\r\nLead and manage data science team\r\nQualifications\r\nBenefits\r\nBest in Market Salary Package\r\nCar and House in Kenya.\r\n\r\nThis opportunity is for our client in Kenya Location.\r\n\r\nJob Type: Full-time\r\n\r\nSalary: R500,000.00 to R600,000.00 /month\r\n\r\nExperience:\r\nData Science: 4 years (Preferred)"},{"JobTitle":" Snr Engineer: Data","Url":"https://www.indeed.co.za/rc/clk?jk=8f233e8206d6760c&fccid=745f50042cd32f08&vjs=3","Source":" Unique Personnel","Age":"11 days ago","Salary":null,"Location":"Pretoria, Gauteng","Description":"\r\n\r\n\r\nPretoria, Gauteng\r\n\r\n\r\nPermanent\r\n\r\n\r\n\r\n\r\n\r\nJob Listing \r\n\r\n\r\n\r\n\r\n\r\nJob Number\r\n\r\n58002 \r\n\r\n\r\n\r\n\r\nJob Type\r\n\r\nPermanent \r\n\r\n\r\n\r\n\r\nJob Title\r\n\r\nSnr Engineer: Data \r\n\r\n\r\n\r\n\r\nComputer Skills\r\n\r\nOracle,SAP,SQL \r\n\r\n\r\n\r\n\r\nIndustry\r\n\r\nTelecommunications \r\n\r\n\r\n\r\n\r\nCity\r\n\r\nTshwane (Pretoria) \r\n\r\n\r\n\r\n\r\nProvince\r\n\r\nGauteng \r\n\r\n\r\n\r\n\r\nJob Description\r\n\r\n\r\nResponsible to support data science projects and solutions by leveraging your big data engineering and architecture experience to solve a variety of use cases across the Company and its customers.\r\n Expected to be an expert in batch and real-time data ingestion with the ability to design, build and scale data pipelines for big data processing.\r\n Together with a team of data engineers, responsible for developing and maintaining our cloud-based development and production platforms.\r\n Expected to stay abreast of new data engineering developments and put them into practice.\r\n Play a strong role in the training and development of junior data engineering resources.\r\n Engage with stakeholders to support the design and delivery of data science projects and solutions\r\n Use big data architecture and engineering techniques to solve business problems\r\n Architect, build and maintain batch and real-time data pipelines for on-prem and cloud processing\r\n Support ETL/ ELT processes and data ingestion for exploratory data analysis and solution development\r\n Lead and develop a team of junior data engineers\r\n Contribute to our agile way of work and our innovation culture\r\n Up to date knowledge of data platforms and related technologies\r\n Translate business requirements into system requirements\r\n Consistent documentation of all implemented systems and processes\r\n\r\n Operational:\r\n Work with the data management team to retrieve data from source\r\n Guide most appropriate data engineering tools/approaches for specific projects\r\n Develop and maintain data pipeline architecture for data science solutions\r\n Work with software engineering to develop, administer and maintain our technology and application stack\r\n Ensure performance of visualisation, advanced analytics and data science solutions for users\r\n Architect highly scalable distributed systems, using different open source tools\r\n Work with developers to make sure that all data solutions are consistent\r\n Build best practice standards\r\n\r\n\r\n\r\nTo apply immediately for this position click here: http://www.unique.co.za/candidate_registration_1.aspx?JobID=58002&referrer=Unique\r\n\r\n\r\n\r\n\r\nInherent Requirements\r\n\r\n\r\nRelational SQL and NoSQL databases (e.g. Postgres, Cassandra, HBase, Oracle).\r\n 3-year Degree (NQF level 7) preferably in Computer Science, Mathematics, Statistics, Engineering\r\n 5 years of work experience in the field of data engineering and at least 2 years having been on management\r\n\r\n\r\n\r\n\r\nWhat Qualification\r\n\r\nComputer Science \r\n\r\n\r\n\r\n\r\nMinimum Qualification\r\n\r\nBachelors \r\n\r\n\r\n\r\n\r\nStatus\r\n\r\nAvailable"},{"JobTitle":" ETL Developer","Url":"https://www.indeed.co.za/rc/clk?jk=3723d2f4ad7de8b5&fccid=456208dd78cb7bb1&vjs=3","Source":" Altron","Age":"30+ days ago","Salary":null,"Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\nContract\r\n\r\n\r\n\r\nThe ETL Developer is responsible for the design, build and deployment of a project's ETL components. A typical ETL effort usually involves multiple ETL Developers developing the Informatica mappings, executing them in native and/or pushdown mode and validating the results. These tasks involve data ingestion into Hadoop, Data Integration and Data Quality on Hadoop and Data extraction from Hadoop to external systems. \r\n\r\n\r\nJob Requirements:\r\n\r\n\r\nResponsibilities:\r\nUses the Informatica DI platform to extract data from external sources and ingest them into Hadoop.\r\nUses the Informatica Developer to perform DI operations on data within Hadoop.\r\nUses the Informatica Developer to perform DQ operations on data within Hadoop.\r\nIntegrates the Hadoop ecosystem (i.e., services such as HDFS, Hive and HBase) with other non Hadoop enterprise level technologies such as ERP and RDBMS.\r\nDevelops Data Integration workflows and load processes.\r\nEnsures adherence to locally defined standards for all developed components.\r\nPerforms data analysis for both Source and Target tables/columns including those on HDFS.\r\nProvides technical documentation of Source and Target mappings.\r\nParticipates in design and development reviews.\r\nWorks with System owners to resolve source data issues and refine transformation rules.\r\nEnsures performance metrics are met and tracked.\r\nWrites and maintains unit tests.\r\nConduct QA Reviews."},{"JobTitle":" Senior Application Developer","Url":"https://www.indeed.co.za/rc/clk?jk=6dcf0988599a5242&fccid=a4bf7e93f92792dd&vjs=3","Source":" PRR Recruitment Services","Age":"30+ days ago","Salary":" R60 000 - R70 000 a year","Location":"Cape Town, Western Cape","Description":"\r\n\r\n\r\nCape Town, Western Cape\r\n\r\n\r\nR60 000 - R70 000 a year\r\n\r\n\r\nLooking for a skilled and versatile full-stack developer to join the team in either of our South African offices. The role involves building applications for a high profile Big Data project that promises to revolutionize an area of finance.\r\nHave great working knowledge of at least one JavaScript web application framework (e.g. Angular, React, Vue, Aurelia). We use Angular so you should at least be familiar with its concepts.\r\nExperience with HTML5, CSS3, SVG, Web Standards, Progressive Enhancement.\r\nExperience with modern web development libraries and tools (e.g. Webpack, Typescript, D3.js, Babel, SASS etc).\r\nProven ability in at least one server-side MVC framework (e.g. Java Spark, .NET Core MVC, Node js).\r\nDesign capabilities using OO and SOLID techniques.\r\nGeneral technology problem solving skills to a high level.\r\n\r\nTo succeed in the role, you’ll need\r\nTo use Docker to deploy applications and run them on our Kubernetes clusters\r\nTo extensively use GIT\r\nTo understand NoSQL databases. At the moment our tech stack includes Elasticsearch, Hive and HBase.\r\nTo be able to write performant complex queries over Postgres and Redshift"},{"JobTitle":" Data Scientist","Url":"https://www.indeed.co.za/rc/clk?jk=339d1d027a90ca5b&fccid=50a816ef18fe262a&vjs=3","Source":" Network Recruitment","Age":"19 days ago","Salary":" R600 000 - R800 000 a year","Location":"Johannesburg North, Gauteng","Description":"\r\n\r\n\r\nJohannesburg North, Gauteng\r\n\r\n\r\nR600 000 - R800 000 a year\r\n\r\n\r\n\r\n\r\nJob Description:\r\n\r\n\r\n\r\n\r\nYou will design, develop, maintain and support projects using a variety of Big Data/Data Science technologies. You will use machine learning techniques, data mining, do ad-hoc analysis and create automated anomaly detection systems as well as dashboards, reports and visualisations.\r\n\r\n\r\n\r\n Education:\r\nMatric\r\nBSc Honours Computer Science / Engineering is mandatory.\r\nMasters or Doctoral degree is preferred\r\n\r\n\r\n\r\n\r\nJob Experience & Skills Required:\r\n4-5 years’ experience in a comparable environment\r\nVery strong analytical, communication and negotiation skills\r\nData Science (essential)\r\nAI and ML experience (essential)\r\nR, Weka, NumPy, MatLab (essential)\r\nExcellent understanding of machine learning techniques and algorithms such as k-NN, Naïve, SVM\r\nJava\r\nPython\r\nHTML\r\nJavaScript\r\nLinux shell scripting\r\nNodeJS\r\nMSSQL\r\nMySQL\r\nMongoDB\r\nElasticSearch\r\nCassandra\r\nHDFS, Hadoop, Hbase\r\n\r\n\r\n\r\n\r\nApply now!\r\n\r\n\r\nEmail your cv to : Nbhana@networkrecruitment.co.za\r\n\r\n\r\nIf you have not had any response in two weeks, please consider the vacancy application unsuccessful. Your profile will be kept on our database for any other suitable roles / positions.\r\n\r\n\r\n\r\nFor more information contact:\r\n\r\nNikita Bhana\r\n\r\nIT Recruitment Consultant"},{"JobTitle":" Data Scientist","Url":"https://www.indeed.co.za/rc/clk?jk=810352e1744ef4d8&fccid=75800947701c95ac&vjs=3","Source":" NETWORK IT BRUMA","Age":"18 days ago","Salary":" R600 000 a year","Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\nR600 000 a year\r\n\r\n\r\nJob & Company Description:\r\n\r\nYou will design, develop, maintain and support projects using a variety of Big Data/Data Science technologies. You will use machine learning techniques, data mining, do ad-hoc analysis and create automated anomaly detection systems as well as dashboards, reports and visualisations.\r\n\r\n\r\n\r\n Education:\r\n Matric\r\n BSc Honours Computer Science / Engineering is mandatory.\r\n Masters or Doctoral degree is preferred\r\n\r\n\r\n\r\n Job Experience & Skills Required:\r\n 4-5 years’ experience in a comparable environment\r\n Very strong analytical, communication and negotiation skills\r\n Data Science (essential)\r\n AI and ML experience (essential)\r\n R, Weka, NumPy, MatLab (essential)\r\n Excellent understanding of machine learning techniques and algorithms such as k-NN, Naïve, SVM\r\n Java\r\n Python\r\n HTML\r\n JavaScript\r\n Linux shell scripting\r\n NodeJS\r\n MSSQL\r\n MySQL\r\n MongoDB\r\n ElasticSearch\r\n Cassandra\r\n HDFS, Hadoop, Hbase\r\n\r\n\r\n\r\n Apply now!\r\n\r\n\r\n Email your cv to : Nbhana@-\r\n\r\n\r\nIf you have not had any response in two weeks, please consider the vacancy application unsuccessful. Your profile will be kept on our database for any other suitable roles / positions.\r\n\r\n\r\n\r\nFor more information contact:\r\n\r\nNikita Bhana\r\n\r\nIT Recruitment Consultant"},{"JobTitle":" Data Scientist","Url":"https://www.indeed.co.za/rc/clk?jk=79b07c24bea88b88&fccid=8de4e5eeef794daa&vjs=3","Source":" Tipp Focus","Age":"30+ days ago","Salary":" R550 - R650 a week","Location":"Midrand, Gauteng","Description":"\r\n\r\n\r\nMidrand, Gauteng\r\n\r\n\r\nR550 - R650 a week\r\nThis position will provide complete application lifecycle development, deployment, and operations support for Big Data solutions and infrastructure. ? In this role, you will collaborate with product owners, data scientists, solutions engineers, and business analysts to facilitate the development, automation, and seamless delivery of analytics solutions into Big Data clusters. \r\n\r\n Strong background in mathematics and have very good analytical and problem solving skills. \r\n\r\n Languages Python, Scala, SQL, Java, PL/SQL Web Technologies Web Service, SOAP, Rest web services, JSP \r\nBig Data Eco System \r\nHDFS, Spark, Yarn, Map Reduce, Hive, Pig, Sqoop, ZooKeeper, Kafka, Oozie, Hue, Impala, Flume. Scripting Languages HTML, JavaScript, CSS, XML and Ajax Machine Learning R, SAS, Python, SKLearn, MATLAB, Octave, Spark ML No SQL Databases Cassandra, HBase, MongoDB, Vertica Cloud AWS, EC2, S3, EMR, Azure Operating System Windows, Linux and Unix \r\nBI/DWH/ETL Tools Informatica 9.5/9.1/8.6, Tableau, Cognos DBMS / RDBMS Oracle 12c/11g, SQL Server 2014, DB2, Teradata 14/12, AWS Redshift \r\nIDEs \r\nEclipse, Jupiter Notebooks, Microsoft Visual Studio, Flex Builder, Spyder, TOAD, NetBeans, PL/SQL Developer, Putty, Squirrel SQL Version Control SVN, CVS, Git, and Rational Clear Case \r\nTools FileZilla, JUnit, Splunk, HP ALM, Clear Quest, Rally, Jira \r\n\r\nActivities:\r\n Installing, configuring and using ecosystem components like Hadoop Map Reduce, Spark, Hive, Sqoop, Pig, HDFS, HBase, Cassandra, ZooKeeper, Oozie, Hue, Impala and Flume. ? Strong experience in Data Warehousing and ETL using Informatica Power Center. ? Very good experience in analyzing the data and reporting it using data visualization tools such as Tableau, Cognos, MicroStrategy. ? Good understanding of Hadoop architecture & various components of HDFS/ Yarn. ? Experience in Data Mining, Data Analysis, Data Migration, Data Validation, Data Cleansing, Data Verification and identifying Data Mismatch. ? Experience in Machine Learning solving classification and clustering \r\nproblems. ? Interpreting the results of statistical and predictive experiments and regression analysis. ? Importing and exporting data using Sqoop from HDFS to Relational Database Systems and vice-versa. ? Experience with CSV, JSON, Sequence files, AVRO, Parquet, RC file formats. ? Experience with Spark Context, SQL Context, Spark-SQL, Data Frames, Pair RDD's, transformations, actions in Spark. ? Expert in creating PIG and HIVE UDFs using java in order to analyze data sets. ? Experience using HBase, Cassandra, MongoDB No-SQL databases for real time low latency queries. ? Experience with Spark programs, Hive queries, pig Latin scripts, and MapReduce programs for data analysis and to process the data and loading into databases for visualization. ? Extensively worked on data extraction, Transformation and loading (ETL) data from various sources like Oracle, SQL Server and flat files and loaded into DWH for reporting and data analysis. ? Well versed in developing the complex SQL queries, multiple table joins, analytical functions, regular expressions etc. ? Experience in preparing and executing test plan and test cases after software development. ? In depth understanding of data structures and algorithms. ? Experience working with both the Waterfall and Agile methodologies. ? Experience in giving training and guiding new team members in the Project. ? Experience coding and testing the Standardization, Normalization, Load, Extract and AVRO models to filter/massage the data and its validation. ? Proficient in HealthCare, Education, Retail and Banking Domains. ? Very good experience in customer specification study, requirements gathering, system architectural design and turning the requirements into final product. ? Experience in interacting with customers and working at client locations for real time field testing of products and services. ? Ability to work effectively with associates at all levels within the organization."}]