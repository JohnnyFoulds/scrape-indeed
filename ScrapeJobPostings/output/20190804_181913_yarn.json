[{"JobTitle":" Quality Assurance Manager â€† Textiles","Url":"https://www.indeed.co.za/pagead/clk?mo=r&ad=-6NYlbfkN0AMOOo83f3x9FLd22RLK3YfFusStXJLn5R4tAT9NKF0tCpHzgZ9ffqffL_dRgSAAfzxG0Ji_djMbSbdL_vW9E5KFkEtsOJb4IRH72qId_wURBBITCakA3VbjQZivYS-dEsRz42vI1WSXwSl772Zw10tZdBMNbEcUzbaVw5QeTe2BeBQzL0dvJqAzZjpV1pq2aLVJyjxcVPKH5P6DpNWyY8d4MI6jO6uYfCApfww5_pZ5r__amXJ7gxuZWisPwpJfiuAzg-az30HRhA1VFDzrseOCMjiZ2E3KOUCvAzzVdYlCCIvDkcrnvoEiApD3CQR-8RNIEzfvPWgCfRbNNAvLYX0-ncrJRmqKFyo1ZpQ2kNr2aLVgXzbF1iVXpfnUSaLvK0OCxDAYYcUGTexMheKrsc5qyXJqUWE2pKanonSEBYEPWto94xHBBeuQMIpvFrhzzSfViHE3kTZfqPUrO8wHpszmKkiKfhPUR6leNQ6EWraxIzmFsrZ0Uaof6DADACpkXPInvyNyakC1eOFSsEl2vtCyZ3ixM8YOnDWZj1qBICUgDGPRCZeonrs2GQlo4HEL3C67tBevjSHG4rAI_IiENWSpfMSCNCT-S4=&p=0&fvj=0&vjs=3","Source":" Pollock & Associates","Age":null,"Salary":null,"Location":"Durban, KwaZulu-Natal","Description":"\r\n\r\n\r\nDurban, KwaZulu-Natal\r\n\r\n\r\nKey Result Areas:\r\n Conducting yarn tests to determine strength, length, stretch, absorption rate\r\n Preparing laydowns\r\n Understanding Statistical Process Control and able to interpret results\r\n Proven Management Skills\r\n Liaising with Customers on Quality issues\r\n Application of technical skills to better utilise yarn types\r\n Managing the ISO system"},{"JobTitle":null,"Url":"https://www.indeed.co.za","Source":" Structureit","Age":"30+ days ago","Salary":null,"Location":null,"Description":null},{"JobTitle":" Senior Data Engineer","Url":"https://www.indeed.co.za/rc/clk?jk=2ac4dd802f3e65b3&fccid=745f50042cd32f08&vjs=3","Source":" Unique Personnel","Age":"5 days ago","Salary":null,"Location":"South Africa","Description":"\r\n\r\n\r\nSouth Africa\r\n\r\n\r\nContract\r\n\r\n\r\n\r\n\r\n\r\nJob Listing \r\n\r\n\r\n\r\n\r\n\r\nJob Number\r\n\r\n58073 \r\n\r\n\r\n\r\n\r\nJob Type\r\n\r\nContract \r\n\r\n\r\n\r\n\r\nJob Title\r\n\r\nSenior Data Engineer \r\n\r\n\r\n\r\n\r\nComputer Skills\r\n\r\nData Analytics,Database Administration,Java,MS Excel,MS Outlook,MS PowerPoint,MS SQL,MS Word,MySQL,Python,SQL,Windows 10 \r\n\r\n\r\n\r\n\r\nIndustry\r\n\r\nIT Development & Software \r\n\r\n\r\n\r\n\r\nCity\r\n\r\nPlease select city \r\n\r\n\r\n\r\n\r\nProvince\r\n\r\nGauteng \r\n\r\n\r\n\r\n\r\nJob Description\r\n\r\nThe Senior Data Engineer is responsible for overseeing junior data engineering activities and aiding in building the business’ data collection systems and processing pipelines. The role of the Senior Data Engineer is responsible for building and maintaining optimized and highly available data pipelines that facilitate deeper analysis and reporting by the Data and Analytics department. The Senior Data Engineer builds data processing frameworks that handle the business’s growing database. He works with senior data science leadership as well as other Data and Analytics teams in leveraging data with reporting and scientific tools, for example, Tableau, R, and Spark. The Senior Data Engineer strives to continuously develop new and improved data engineering capabilities. Management and Strategy: The managerial role of the Senior Data Engineer is primarily for overseeing activities of the junior data engineering teams, ensuring proper execution of their duties and alignment with business vision and objectives. He provides senior-level contribution to a team that is responsible for the design, deployment, and maintenance of the business’s data platforms. However, the Senior Data Analyst will also implement strategies directed at acquiring data and promoting the development of new insights across the business. The Senior Data Engineer owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets. It is his duty to monitor the existing metrics, analyze data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. The Senior Data Engineer will additionally develop queries for ad hoc business projects, as well as ongoing reporting. In this capacity, the Senior Data Engineer builds a metadata system where all available data is maintained and cataloged. The Senior Data Engineer also plays a major role in the development of reliable data pipelines that translate raw data into powerful features and signals. He designs, architects, implements, and supports key datasets that avail structured and timely access to actionable business insights. The Senior Data Engineer is additionally tasked with developing ETL processes that convert data into formats through a team of data analysts and dashboard charts. Collaboration and Support: The Senior Data Engineer plays a collaborative role where he works closely with the business’s Data and Analytics teams, gathering technical requirements for exceptional data governance across the department and the business at large. In this collaboration, the Senior Data Engineer works the data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large. The Senior Data Engineer will also work with senior data science management and departments beyond the Data and Analytics department in analyzing and understanding data sources, participating in design, and providing insights and guidance on database technology and data modeling best practices. In this capacity, the Senior Data Engineer will further be required to draw performance reports and strategic proposals form his gathered knowledge and analyses results for senior data science leadership. Analytics: The Senior Data Engineering plays an analytical role where he develops and manages scalable data processing platforms that he uses for exploratory data analysis and real-time analytics. It is also the role of the Senior Data Engineer to oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and efficient data acquisition. In this capacity, the Senior Data Engineer retrieves and analyzes data through the use of SQL, Excel, among other data management systems. He also builds data loading services for the purpose of importing data from numerous disparate data sources, inclusive of APIs, logs, relational, and non-relational databases. Knowledge and Opportunity: The Senior Data Engineer is tasked with the responsibility of contributing to the continual improvement of the business’s data platforms through his observations and well-researched knowledge. He keeps track of industry best practices and trends and through his acquired knowledge, takes advantage of process and system improvement opportunities. Other Duties: The Senior Data Engineer performs similar duties as he deems fit for the proper execution of his duties and duties as delegated by the Head of Data Science, Director Data Science, Chief Data Officer, or the Employer. Experience: A candidate for this position must have had at least 5 years of working experience working in a data engineering department, preferably as a Data Engineer in a fast-paced environment and complex business setting. The candidate must have a demonstrated experience in building and maintaining reliable and scalable ETL on big data platforms as well as experience working with varied forms of data infrastructure inclusive of relational databases such as SQL, Hadoop, Spark and column-oriented databases such as Redshift, MySQL, and Vertica. The candidate must also have had experience in data warehousing inclusive of dimensional modeling concepts and demonstrate proficiency in scripting languages, for example, Python, Perl, and so forth. A suitable candidate will also demonstrate machine learning experience and experience with big data infrastructure inclusive of MapReduce, Hive, HDFS, YARN, HBase, Oozie, etc. The candidate will additionally demonstrate substantial experience and a deep knowledge of data mining techniques, relational, and non-relational databases. Communication Skills: Communication Skills for the Senior Data Engineer are just as important as they are for the Data Engineer, both in verbal and written form. The Senior Data Engineer oversees and manages junior data engineering teams and to ensure effective management, he must be capable of conveying information and instructions clearly down the line to the junior team. Communication skills are also imperative for the Senior Data Engineer in his collaborative role where he will have to interact cross-functionally with non-technical departments. To enable effective collaborations, the Senior Data Engineer will have an exceptional ability to convey complex messages in a clear, simplified, and understandable manner. He will also be required to draft reports and prepare presentations for senior data science leadership. These reports and presentation must be clear, concise, unambiguous, engaging and convincing, which will demand exceptional communication skills on the Senior Data Engineer’s part. Ms Office/Software: A candidate for this position must be highly proficient in the use of Ms Word, Ms Excel, PowerPoint, and Outlook, which will all be necessary for the creation of both visually and verbally engaging reports and presentations, for senior data science leadership. The Senior Data Engineer must further have exceptional skills in SQL server reporting services, analysis services, Tableau, Salesforce, integration services, or any other data visualization tools. Technological Savvy/Analytical Skills: A candidate for this position will also demonstrate strong computer skills and a deep passion for analytics. The candidate for this position must possess an ability to perform complex data analyses with large data volumes. He will be an expert in SQL, Java, and have a keen understanding of data models and data warehouse concepts. The candidate will demonstrate an ability translate algorithms provided by senior data science management and implement them in as well as strong knowledge in Linux, OS tools, and file-system level troubleshooting. The candidate must have substantial experience working with big data infrastructure tools such as Python, SQS, and Redshift. A suitable candidate will also be proficient Scala, Spark, Spark Streaming, AWS, and EMR. Interpersonal Skills: The Senior Data Engineer must have certain preferable personal attributes that will make him that much more suited for the position. The Senior Data Engineer will be a result-driven individual, be passionate and a self-starter, be proactive requiring minimal supervision, be highly organized, have an ability to handle multiple tasks and meet tight deadlines, be a creative and strategic thinker, work comfortably work in a collaborative setting, work comfortably with senior departmental leadership, and demonstrate an ability to remain calm during times of uncertainty and stress, inspiring the same in his team. People Skill: The candidate must be a people person who is able to form strong, meaningful, and lasting connections with others, enabling smooth and continued collaborative relationships, earning him the trust of his juniors who will readily follow in his directives, and gaining the confidence of senior data science leadership \r\n\r\nTo apply immediately for this position click here: http://www.unique.co.za/candidate_registration_1.aspx?JobID=58073&referrer=Unique\r\n\r\n\r\n\r\n\r\nInherent Requirements\r\n\r\nThe Senior Data Engineer must have a bachelor’s degree (masters’ preferred) in Computer Science, Applied Mathematics, Engineering, or any other technology related field. An equivalent of this educational requirement in working experience is also acceptable. \r\n\r\n\r\n\r\n\r\nWhat Qualification\r\n\r\nRelated to Industry \r\n\r\n\r\n\r\n\r\nMinimum Qualification\r\n\r\nMasters \r\n\r\n\r\n\r\n\r\nStatus\r\n\r\nAvailable"},{"JobTitle":" BIG DATA DEVELOPER","Url":"https://www.indeed.co.za/rc/clk?jk=18680d22d246ddf2&fccid=36b7d079d13b5af5&vjs=3","Source":" Acuity Consultants","Age":"19 days ago","Salary":" R900 000 - R1 000 000 a year","Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\nPermanent\r\n\r\n\r\nR900 000 - R1 000 000 a year\r\n\r\n\r\n\r\nThis is an excellent opportunity for a BIG DATA DEVELOPER to join an international SOFTWARE COMPANY and create DATA SOLUTIONS for Major Global CAPITAL MARKETS FINANCIAL INSTITUTIONS.\r\n This role is with an established Data Solutions & Software company operating in South Africa, UK, USA, New Zealand, Thailand, & Mauritius.\r\n\r\nBased in JOHANNESBURG this BIG DATA DEVELOPER role offers a salary of R900K – R1M/annum, with benefits on top.\r\n\r\nTHE COMPANY:\r\n Over their 15 year history this DATA SOLUTIONS SOFTWARE COMPANY has provided CAPITAL MARKETS Financial Institutions with BIG DATA ENGINEERING and CUSTOM DEVELOPMENT aligned to deploying technology and unlocking the potential of data - to gather, process, compare and analyse data from multiple sources, and uncover hidden insights to drive business advantage.\r\n This is a fast-growing international business using technology to solve complex financial data challenges in a simple way. Having grown across 5 continents, this business continues to enjoy success and is a recognised specialist in CAPITAL MARKETS.\r\n\r\nTHE ROLE:\r\n As BIG DATA DEVELOPER, your role will involve building and operating a content management platform for high profile big data projects that revolutionise an area of finance by providing unprecedented market insight in a timely manner.\r\n You'll be working closely within a team of developers distributed in London, South Africa and New Zealand.\r\n The role will involve building and operating an ingestion and analytics platform that collects frequently changing data and exposing the normalised and aggregated data via APIs. This includes data cleansing, aggregation, financial computations.\r\n\r\nTHE TEAM are diverse, smart, agile but laid-back who are passionate about technology, open-minded and open to new ideas. In this business you’ll find serious hardware, and no red tape or unnecessary process. Not only will you get to work with a great team, you’ll also enjoy flexible hours, the flexibility to work from home when needed, private medical and a relaxed dress code.\r\n\r\nREQUIRED SKILLS:\r\n Ability to pick up a new technology quickly and deliver features in a highly agile manner.\r\n Experience writing functional Scala in a production grade system. (Not a Java developer writing OO in Scala).\r\n To have used Apache Spark SQL in a production system using Scala with YARN as the resource manager.\r\n A clear and practical understanding of how Hive works, which includes running Hive on Tez.\r\n Practical experience using Debian flavoured Linux distributions.\r\n Familiarity with event driven development and architecture.\r\n Used Docker containers to deploy your systems.\r\n Ability to navigate the administration of an HDP cluster on AWS.\r\n Able to index millions of documents from Hadoop into Elasticsearch.\r\n Work with various messaging systems, such as Kafka and RabbitMQ.\r\n Able to aggregate data using Apache Kylin Cube.\r\n Can pick up Python if you have not used it previously.\r\n Operate and deploy to a Kubernetes cluster on AWS.\r\n Understand basic concepts about mortgage backed securities.\r\n\r\nIf you qualify for this role, please email your CV directly to:\r\n Gary Silbermann\r\n gary@acuityconsultants.co.za\r\n 021 801 5001\r\n\r\nIf you have not had a response to your application within 14 days please consider your application to be unsuccessful."},{"JobTitle":" Big Data Developer (CPT)","Url":"https://www.indeed.co.za/rc/clk?jk=960548b153c061f5&fccid=6ab9a95a1ff7d948&vjs=3","Source":" Parvana Strategic Sourcing","Age":"30+ days ago","Salary":null,"Location":"Cape Town, Western Cape","Description":"\r\n\r\n\r\nCape Town, Western Cape\r\n\r\n\r\nPermanent\r\n\r\n\r\n\r\n\r\nResponsibilities: Building and operating a content management platform for a high-profile big data project that promises to revolutionise an area of finance by providing unprecedented market insight in a timely manner.\r\nWorking closely within a team of developers distributed in London, Johannesburg, Cape Town and New Zealand.\r\nBuilding and operating an ingestion and analytics platform that collects frequently changing data and exposing the normalised and aggregated data via APIs to our client’s customers. This will include data cleansing, aggregation, financial computations.\r\n\r\n\r\n\r\nSkills & Experience: Must be able to pick up a new technology quickly and deliver features in a highly agile manner.\r\nExperience writing functional Scala in a production grade system. You are not a Java developer writing OO in Scala.\r\nPrevious experience using Apache Spark SQL in a production system using Scala with YARN as the resource manager.\r\nClear and practical understanding of how Hive works, which includes running Hive on Tez.\r\nPractical experience using Debian flavoured Linux distributions.\r\nFamiliarity with event driven development and architectures.\r\nPrevious experience using Docker containers to deploy your systems.\r\nAbility to easily navigate the administration of an HDP cluster on AWS.\r\nMust be able to index millions of documents from Hadoop into Elasticsearch.\r\nAbility to work with various messaging systems, such as Kafka and RabbitMQ.\r\nMust be able to aggregate data using Apache Kylin Cube.\r\nMust be able to easily pick up Python if you have not used it previously.\r\nAbility to operate and deploy to a Kubernetes cluster on AWS.\r\nMust be able to understand basic concepts about mortgage backed securities.\r\n\r\n\r\n\r\nTo apply use the application tool or send us an email to recruitment@parvana.co.uk \r\n\r\n\r\n\r\nBig Data Developer (CPT) (New) | (1002333)\r\n\r\n[Permanent | Competitive Salary | Cape Town]\r\n\r\n\r\nClient Background: Our client develops and supports software and data solutions across a variety of industries. \r\n They want you to get ahead of the market and stay there. They offer a combination of plug and play products that can be integrated with existing systems and processes and can also be customised to client needs. \r\n Their capabilities extend to big data engineering and bespoke software development, solutions are available as both cloud-based and hosted.\r\n\r\n\r\nResponsibilities: Building and operating a content management platform for a high-profile big data project that promises to revolutionise an area of finance by providing unprecedented market insight in a timely manner.\r\nWorking closely within a team of developers distributed in London, Johannesburg, Cape Town and New Zealand.\r\nBuilding and operating an ingestion and analytics platform that collects frequently changing data and exposing the normalised and aggregated data via APIs to our client’s customers. This will include data cleansing, aggregation, financial computations.\r\n\r\nSkills & Experience: Must be able to pick up a new technology quickly and deliver features in a highly agile manner.\r\nExperience writing functional Scala in a production grade system. You are not a Java developer writing OO in Scala.\r\nPrevious experience using Apache Spark SQL in a production system using Scala with YARN as the resource manager.\r\nClear and practical understanding of how Hive works, which includes running Hive on Tez.\r\nPractical experience using Debian flavoured Linux distributions.\r\nFamiliarity with event driven development and architectures.\r\nPrevious experience using Docker containers to deploy your systems.\r\nAbility to easily navigate the administration of an HDP cluster on AWS.\r\nMust be able to index millions of documents from Hadoop into Elasticsearch.\r\nAbility to work with various messaging systems, such as Kafka and RabbitMQ.\r\nMust be able to aggregate data using Apache Kylin Cube.\r\nMust be able to easily pick up Python if you have not used it previously.\r\nAbility to operate and deploy to a Kubernetes cluster on AWS.\r\nMust be able to understand basic concepts about mortgage backed securities.\r\n\r\nTo apply use the application tool or send us an email to recruitment@parvana.co.uk"},{"JobTitle":" Hadoop developer","Url":"https://www.indeed.co.za/company/Prorek/jobs/Hadoop-Developer-002d963619151341?fccid=6c17122040c57e81&vjs=3","Source":" Prorek Solutions","Age":"12 days ago","Salary":null,"Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\nContract\r\n\r\nCandidate should have hands on experience in Hadoop along with ecosystem (including HDFS, Spark, Sqoop, Flume, Hive, Impala, PIG, MapReduce/YARN)\r\n\r\n- Experience working on Unix / Linux environment, as well as Windows environment\r\nMinimum 3 - 5 years required.\r\nPlease send resume to hr@prorek dot net\r\n\r\nJob Type: Contract\r\n\r\nExperience:\r\nHadoop: 3 years (Preferred)"},{"JobTitle":" Front End Developer","Url":"https://www.indeed.co.za/rc/clk?jk=6206c545a95c231d&fccid=e78d1a1c06467894&vjs=3","Source":" Mass Staffing Projects","Age":"30+ days ago","Salary":" R35 000 a month","Location":"Cape Town, Western Cape","Description":"\r\n\r\n\r\nCape Town, Western Cape\r\n\r\n\r\nR35 000 a month\r\nA new client in the design and advertising industry is looking for a Front-End Developer to join their team. The ideal candidate needs to be highly creative and experienced. \r\n\r\nRequirements:\r\nIT Education\r\n4+ years exp\r\nHTML5, CSS, JavaScript\r\nSCSS, UX, CSS3\r\nVue.JS, Git, Angualr\r\nReact, SVN, Yarn, Gulp\r\nWebpack, NPM, SEO\r\nPHP Knowledge, API, Sketch etc.\r\nShould you meet the requirements for this position, please email your CV to it.jobs@staffingprojects.co.za. You can also contact Michelle on 021 555 0432 or visit our website at http://www.staffingprojects.co.za \r\nNOTE: When replying to the advert, also include the reference number in the subject line. \r\nCorrespondence will only be conducted with short listed candidates. Should you not hear from us within 3 days, please consider your application unsuccessful."},{"JobTitle":" Senior Specialist: Support Analyst","Url":"https://www.indeed.co.za/rc/clk?jk=acbd902ab746d6c9&fccid=374d720d3973ca1c&vjs=3","Source":" Vodafone","Age":"30+ days ago","Salary":null,"Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\n\r\nVodacom is a Leading African Mobile communication company providing wider range of communication services including mobile voice, messaging, data and converged services to over 73.6 million customers. From our roots in South Africa, we have grown our mobile network business to include operations in Tanzania, DRC, Mozambique and Lesotho. The mobile networks cover a total population of approximately 200 million people. Through Vodacom Business Africa (VBA) we also offer business managed services to enterprises in over 40 countries across the continent. Vodafone is the majority shareholder of Vodacom and has a 65% share.\r\n\r\n\r\n\r\n\r\n\r\nWere at our best when we lead and over the past 20 years, as the Company that pioneered mobile in South Africa, Vodacom has achieved a remarkable list of firsts. Were immensely proud to be a leader in our field and are 100% committed to continue trailblazing.\r\n\r\n\r\n\r\n\r\nWe employ individuals who are as passionate about customers as we are. We are truly Customer Obsessed which means that we are passionate about exceeding customer expectations; work relentlessly to really understand the customer; look at decisions through the customers eyes and take personal accountability for the customer experience.\r\n\r\n\r\n\r\n\r\nWe have the below vacancy available in our Organisation:\r\n\r\n\r\n\r\n\r\n\r\nThe G Band Senior Specialist: Support Analyst role is based within Local Technology\r\n\r\n\r\n\r\n\r\n\r\nThe role of the Senior Specialist: Support Analyst is to be responsible for and ensuring of data import and processing into the BDP. Installation of CDH repository, OS level configuration, new type of I/O compression library cluster, and Hadoop installation &support including the Cloudera manager, adding new nodes and services to the cluster\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nYour responsibilities will include:\r\n\r\n\r\n Configure and Maintain Name Node/ Resource manager High Availability (HA), including Hive, Impala\r\n\r\n\r\n\r\n Manage cluster support by rebalancing the cluster, setting up alerting for disk fill, and YARN resource management;\r\n\r\n\r\n\r\nConfigure HDFS ACLs, Sentry, Hue user authorization and authentication;\r\n\r\n\r\n\r\nContinuous benchmarking of the cluster s operational metrics, test systems configuration for operational efficiency;\r\n\r\n\r\n\r\nResolve all logged incidences and service requests (SR) Troubleshoot and resolve errors/warnings in Cloudera Manager and application delays. Resolve performance problems/errors in operations\r\n\r\n\r\n Provide guidance and decisive technical leadership\r\n\r\n\r\n Ensure the BDP cluster is secured from potential vulnerabilities\r\n\r\n\r\n Provided a leadership role with key stakeholders for optimal deliverance of use cases\r\n\r\n\r\n Drive DevOps way of working\r\n\r\n\r\n Expert level experience with using Spark, Yarn, Hive and Oozie\r\n\r\n\r\n Python and Scala programming ability will be an advantage\r\n\r\n\r\n Working knowledge of HBase, Kafka, Cassandra and Flume\r\n\r\n\r\n Ability to work standby and overtime when required\r\n\r\n\r\n Expert knowledge of NiFi, Sqoop and Flume will be an added advantage.\r\n\r\n\r\n\r\n\r\n\r\n\r\nKey accountabilities and decision ownership:\r\n\r\n\r\n\r\nExtensive experience in designing, building and managing BDP applications in ingesting and storing large amounts of data in a Hadoop/HDFS ecosystem;\r\n Extensive experience with performance tuning applications on Hadoop/YARN and configuring Hadoop/YARN systems to maximise performance;\r\n Extensive experience in installing, testing, configuring BDP ecosystems\r\n Extensive experience is solving complex requests or service impacting incidents within the BDP cluster\r\n Experience working in a multi tenancy Hadoop environment\r\n\r\n\r\n\r\n\r\n\r\nCore competencies, knowledge and experience:\r\n\r\n Hadoop,\r\n\r\n YARN,\r\n Linux,\r\n HDFS\r\n CDH\r\n Scripting/Java/Python/R\r\n\r\n\r\n\r\n The ideal candidate for this role will have:\r\n Matric/ Grade 12 qualification\r\n 3 year completed Ndip/Degree in Information Technology or equivalent\r\n At least 5-8 years IT experience (Telecoms or Fixed mobile advantageous)\r\n CCA131 certification (desirable)\r\n Knowledge of Big Data (essential)\r\n Agile Methodology(desirable)\r\n Hadoop or YARN or Linux or HDFS or CDH or Scripting/Java/Python/R (essential)\r\n\r\n\r\n\r\nIn addition to the details listed above, the ideal candidate will have an in-depth knowledge and understanding\r\n\r\n\r\n\r\n Availability and optimal functioning of the BDP cluster ecosystems\r\n Servicing incidents and service requests in a timely manner\r\n Adjustment to the Agile environment\r\n\r\n\r\n\r\nThe base location for this role is Midrand, Commercial Park\r\n\r\n\r\n\r\nThe Companys approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply.\r\n\r\n\r\n\r\nVodacom is committed to an organisational culture that recognises, appreciates and values diversity inclusion."},{"JobTitle":" Big Data Developer (JHB)","Url":"https://www.indeed.co.za/rc/clk?jk=dc2adc6e2281aaed&fccid=6ab9a95a1ff7d948&vjs=3","Source":" Parvana Strategic Sourcing","Age":"30+ days ago","Salary":null,"Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\nPermanent\r\n\r\n\r\n\r\n\r\nResponsibilities: Building and operating a content management platform for a high-profile big data project that promises to revolutionise an area of finance by providing unprecedented market insight in a timely manner.\r\nWorking closely within a team of developers distributed in London, Johannesburg, Cape Town and New Zealand.\r\nBuilding and operating an ingestion and analytics platform that collects frequently changing data and exposing the normalised and aggregated data via APIs to our client’s customers. This will include data cleansing, aggregation, financial computations.\r\n\r\n\r\n\r\nSkills & Experience: Must be able to pick up a new technology quickly and deliver features in a highly agile manner.\r\nExperience writing functional Scala in a production grade system. You are not a Java developer writing OO in Scala.\r\nPrevious experience using Apache Spark SQL in a production system using Scala with YARN as the resource manager.\r\nClear and practical understanding of how Hive works, which includes running Hive on Tez.\r\nPractical experience using Debian flavoured Linux distributions.\r\nFamiliarity with event driven development and architectures.\r\nPrevious experience using Docker containers to deploy your systems.\r\nAbility to easily navigate the administration of an HDP cluster on AWS.\r\nMust be able to index millions of documents from Hadoop into Elasticsearch.\r\nAbility to work with various messaging systems, such as Kafka and RabbitMQ.\r\nMust be able to aggregate data using Apache Kylin Cube.\r\nMust be able to easily pick up Python if you have not used it previously.\r\nAbility to operate and deploy to a Kubernetes cluster on AWS.\r\nMust be able to understand basic concepts about mortgage backed securities.\r\n\r\n\r\n\r\nTo apply use the application tool or send us an email to recruitment@parvana.co.uk \r\n\r\n\r\n\r\nBig Data Developer (JHB) (New) | (1002332)\r\n\r\n[Permanent | Competitive Salary | Johannesburg]\r\n\r\n\r\nClient Background: Our client develops and supports software and data solutions across a variety of industries. \r\n They want you to get ahead of the market and stay there. They offer a combination of plug and play products that can be integrated with existing systems and processes and can also be customised to client needs. \r\n Their capabilities extend to big data engineering and bespoke software development, solutions are available as both cloud-based and hosted.\r\n\r\n\r\nResponsibilities: Building and operating a content management platform for a high-profile big data project that promises to revolutionise an area of finance by providing unprecedented market insight in a timely manner.\r\nWorking closely within a team of developers distributed in London, Johannesburg, Cape Town and New Zealand.\r\nBuilding and operating an ingestion and analytics platform that collects frequently changing data and exposing the normalised and aggregated data via APIs to our client’s customers. This will include data cleansing, aggregation, financial computations.\r\n\r\nSkills & Experience: Must be able to pick up a new technology quickly and deliver features in a highly agile manner.\r\nExperience writing functional Scala in a production grade system. You are not a Java developer writing OO in Scala.\r\nPrevious experience using Apache Spark SQL in a production system using Scala with YARN as the resource manager.\r\nClear and practical understanding of how Hive works, which includes running Hive on Tez.\r\nPractical experience using Debian flavoured Linux distributions.\r\nFamiliarity with event driven development and architectures.\r\nPrevious experience using Docker containers to deploy your systems.\r\nAbility to easily navigate the administration of an HDP cluster on AWS.\r\nMust be able to index millions of documents from Hadoop into Elasticsearch.\r\nAbility to work with various messaging systems, such as Kafka and RabbitMQ.\r\nMust be able to aggregate data using Apache Kylin Cube.\r\nMust be able to easily pick up Python if you have not used it previously.\r\nAbility to operate and deploy to a Kubernetes cluster on AWS.\r\nMust be able to understand basic concepts about mortgage backed securities.\r\n\r\nTo apply use the application tool or send us an email to recruitment@parvana.co.uk"},{"JobTitle":null,"Url":"https://www.indeed.co.za","Source":" PRR Recruitment Services","Age":"30+ days ago","Salary":" R80 000 - R90 000 a year","Location":null,"Description":null},{"JobTitle":" Data Scientist","Url":"https://www.indeed.co.za/rc/clk?jk=79b07c24bea88b88&fccid=8de4e5eeef794daa&vjs=3","Source":" Tipp Focus","Age":"30+ days ago","Salary":" R550 - R650 a week","Location":"Midrand, Gauteng","Description":"\r\n\r\n\r\nMidrand, Gauteng\r\n\r\n\r\nR550 - R650 a week\r\nThis position will provide complete application lifecycle development, deployment, and operations support for Big Data solutions and infrastructure. ? In this role, you will collaborate with product owners, data scientists, solutions engineers, and business analysts to facilitate the development, automation, and seamless delivery of analytics solutions into Big Data clusters. \r\n\r\n Strong background in mathematics and have very good analytical and problem solving skills. \r\n\r\n Languages Python, Scala, SQL, Java, PL/SQL Web Technologies Web Service, SOAP, Rest web services, JSP \r\nBig Data Eco System \r\nHDFS, Spark, Yarn, Map Reduce, Hive, Pig, Sqoop, ZooKeeper, Kafka, Oozie, Hue, Impala, Flume. Scripting Languages HTML, JavaScript, CSS, XML and Ajax Machine Learning R, SAS, Python, SKLearn, MATLAB, Octave, Spark ML No SQL Databases Cassandra, HBase, MongoDB, Vertica Cloud AWS, EC2, S3, EMR, Azure Operating System Windows, Linux and Unix \r\nBI/DWH/ETL Tools Informatica 9.5/9.1/8.6, Tableau, Cognos DBMS / RDBMS Oracle 12c/11g, SQL Server 2014, DB2, Teradata 14/12, AWS Redshift \r\nIDEs \r\nEclipse, Jupiter Notebooks, Microsoft Visual Studio, Flex Builder, Spyder, TOAD, NetBeans, PL/SQL Developer, Putty, Squirrel SQL Version Control SVN, CVS, Git, and Rational Clear Case \r\nTools FileZilla, JUnit, Splunk, HP ALM, Clear Quest, Rally, Jira \r\n\r\nActivities:\r\n Installing, configuring and using ecosystem components like Hadoop Map Reduce, Spark, Hive, Sqoop, Pig, HDFS, HBase, Cassandra, ZooKeeper, Oozie, Hue, Impala and Flume. ? Strong experience in Data Warehousing and ETL using Informatica Power Center. ? Very good experience in analyzing the data and reporting it using data visualization tools such as Tableau, Cognos, MicroStrategy. ? Good understanding of Hadoop architecture & various components of HDFS/ Yarn. ? Experience in Data Mining, Data Analysis, Data Migration, Data Validation, Data Cleansing, Data Verification and identifying Data Mismatch. ? Experience in Machine Learning solving classification and clustering \r\nproblems. ? Interpreting the results of statistical and predictive experiments and regression analysis. ? Importing and exporting data using Sqoop from HDFS to Relational Database Systems and vice-versa. ? Experience with CSV, JSON, Sequence files, AVRO, Parquet, RC file formats. ? Experience with Spark Context, SQL Context, Spark-SQL, Data Frames, Pair RDD's, transformations, actions in Spark. ? Expert in creating PIG and HIVE UDFs using java in order to analyze data sets. ? Experience using HBase, Cassandra, MongoDB No-SQL databases for real time low latency queries. ? Experience with Spark programs, Hive queries, pig Latin scripts, and MapReduce programs for data analysis and to process the data and loading into databases for visualization. ? Extensively worked on data extraction, Transformation and loading (ETL) data from various sources like Oracle, SQL Server and flat files and loaded into DWH for reporting and data analysis. ? Well versed in developing the complex SQL queries, multiple table joins, analytical functions, regular expressions etc. ? Experience in preparing and executing test plan and test cases after software development. ? In depth understanding of data structures and algorithms. ? Experience working with both the Waterfall and Agile methodologies. ? Experience in giving training and guiding new team members in the Project. ? Experience coding and testing the Standardization, Normalization, Load, Extract and AVRO models to filter/massage the data and its validation. ? Proficient in HealthCare, Education, Retail and Banking Domains. ? Very good experience in customer specification study, requirements gathering, system architectural design and turning the requirements into final product. ? Experience in interacting with customers and working at client locations for real time field testing of products and services. ? Ability to work effectively with associates at all levels within the organization."},{"JobTitle":" Mobile App Developer","Url":"https://www.indeed.co.za/rc/clk?jk=92b9e6cdda0b00a6&fccid=745f50042cd32f08&vjs=3","Source":" Unique Personnel","Age":"30+ days ago","Salary":null,"Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\nPermanent\r\n\r\n\r\n\r\n\r\n\r\nJob Listing \r\n\r\n\r\n\r\n\r\n\r\nJob Number\r\n\r\n55531 \r\n\r\n\r\n\r\n\r\nJob Type\r\n\r\nPermanent \r\n\r\n\r\n\r\n\r\nJob Title\r\n\r\nMobile App Developer \r\n\r\n\r\n\r\n\r\nComputer Skills\r\n\r\nCSS,HTML,JavaScript,MS Access,MS Excel,MS Explorer,MS Outlook,MS PowerPoint,MS Word,PHP \r\n\r\n\r\n\r\n\r\nIndustry\r\n\r\nTelecommunications \r\n\r\n\r\n\r\n\r\nCity\r\n\r\nJohannesburg (Incl. Northern Suburbs) \r\n\r\n\r\n\r\n\r\nProvince\r\n\r\nGauteng \r\n\r\n\r\n\r\n\r\nJob Description\r\n\r\nWe’re already a leader of innovation and experience within the digital, telecoms and internet space in South Africa, and we want to push harder towards creating best-of-breed experiences for our clientbase - one such example is the company App. We're seeking highly talented and experienced Mobile App developers to help us do this. company has all the trappings of an creative or development agency, along with the freedom of an internet or startup type company. The position is for a willing, enthusiastic and meticulous person who will work in the Mobile Application Team under the supervision of the Head of Mobile Development. An ideal candidate would have excellent technical knowledge and a strong portfolio of past work. This is a great career opportunity if you want to push the envelope and further refine your skills in a specialised environment. You’ll have the leeway and resources to create work that makes a significant impact while reaching hundreds of thousands of clients. Some perks include Buckets of Coffee DSL or Fibre + Mobile Internet Web Hosting Personality Enthusiastic Hard Working Reliable Positive Attitude Team Player Creative Able to work Independently Looking for a Career, not a Job Meticulous Attention to Detail Motivated to learn new skills and share knowledge Required Technologies and Skills React React Native HTML CSS JSON REST Javascript NPM/Yarn Ajax Gulp Git Command Line iOS and Android Bonus Points for any of the following PHP GraphQL Angular Vue Node OOP Web Sockets App Store Deployment Skill & Knowledge Requirements Understanding of Corporate Identities Understanding of UX Understanding of UIs Complete Fluency in English Solid understanding of Design and Usability Can navigate and build from provided wireframe and artwork files Good Communication skills to achieve the best outcomes within the team Technical Knowledge/Person (As you will be creating apps for technology and telecoms products you need to understand them) Mac Competency / Willing to migrate to Mac Good Time Management Minimum 2+ years in the field What You Will Be Responsible For App Development App Deployment App Testing \r\n\r\nTo apply immediately for this position click here: http://www.unique.co.za/candidate_registration_1.aspx?JobID=55531&referrer=Unique\r\n\r\n\r\n\r\n\r\nInherent Requirements\r\n\r\nUnderstanding of Corporate Identities Understanding of UX Understanding of UIs Complete Fluency in English Solid understanding of Design and Usability Can navigate and build from provided wireframe and artwork files Good Communication skills to achieve the best outcomes within the team Technical Knowledge/Person \r\n\r\n\r\n\r\n\r\nWhat Qualification\r\n\r\nMatric \r\n\r\n\r\n\r\n\r\nMinimum Qualification\r\n\r\nAny \r\n\r\n\r\n\r\n\r\nStatus\r\n\r\nAvailable"},{"JobTitle":" Quality Assurance Manager","Url":"https://www.indeed.co.za/rc/clk?jk=d7cbc29801e5b970&fccid=c4de7ba0ba36a5a6&vjs=3","Source":" Pollock & Associates","Age":"24 days ago","Salary":null,"Location":"Durban, KwaZulu-Natal","Description":"\r\n\r\n\r\nDurban, KwaZulu-Natal\r\n\r\n\r\n\r\nEssential that you are in possession of a Textile Technology Degree/Diploma with specific reference to the Dry spinning process, coupled with 10 years’ experience in textiles\r\n\r\nKey Result Areas:\r\nConducting yarn tests to determine strength, length, stretch, absorption rate\r\nPreparing laydowns\r\nUnderstanding Statistical Process Control and able to interpret results\r\nProven Management Skills\r\nLiaising with Customers on Quality issues\r\nApplication of technical skills to better utilise yarn types\r\nManaging the ISO system\r\n\r\n\r\n\r\n\r\n\r\n Skills Required"},{"JobTitle":" Full Stack Developer (Java, Python, Angular, Vue)","Url":"https://www.indeed.co.za/rc/clk?jk=73f9529f1735aa53&fccid=26d01f64c124ba71&vjs=3","Source":" Datafin IT Recruitment","Age":"30+ days ago","Salary":null,"Location":"Cape Town, Western Cape","Description":"\r\n\r\n\r\nCape Town, Western Cape\r\n\r\n\r\nPermanent\r\n\r\n\r\n\r\nA dynamic social impact platform seeks a highly skilled Full Stack Developer to join its team. You will be able to work remotely 3 days of the week. Your tech toolset should include: Angular and Vue.js, JavaScript (ES6 and up), HTML, JSON, Java, Nodejs, Python, Spring, Express, Flask, GIT, NPM, Yarn, Maven, PIP. You are also required to understand the SDLC and Agile concepts.\r\n\r\n\r\n\r\nREQUIREMENTS:\r\nExperience building applications with modern UI frameworks such as Angular and Vue.js.\r\nProficient knowledge of web technologies: modern JavaScript (ES6 and up), HTML, JSON.\r\nProficient knowledge of backend programming languages: Java, Nodejs, Python.\r\nExperience with server-side frameworks such as: Spring, Express, Flask\r\nKnowledge of development tools: GIT, NPM, Yarn, Maven, PIP\r\nHigh quality coding skills with a focus on delivering reliable code.\r\nAble to self-check and produce code with low error rates.\r\nUnderstand the software development lifecycle as well as Agile concepts.\r\nArchitecture, application design.\r\n\r\n\r\n\r\n\r\nATTRIBUTES:\r\nStrong creativity and problem-solving skills.\r\nAble to work within a remote team, be well self-managed, be able to prioritize tasks and deliver objectives on time.\r\nStrong communication skills.\r\n\r\n\r\n\r\n\r\nWhile we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.\r\n\r\n\r\n\r\nCOMMENTS:\r\n\r\nWhen applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence. Please e-mail a word copy of your CV to therese@datafin.com and mention the reference numbers of the jobs."},{"JobTitle":" AWS Cloud Solutions Architect","Url":"https://www.indeed.co.za/rc/clk?jk=8355c7b436298d63&fccid=399f716a0307ef50&vjs=3","Source":" Communicate Recruitment","Age":"23 days ago","Salary":" R1 000 000 - R1 250 000 a year","Location":"Centurion, Gauteng","Description":"\r\n\r\n\r\nCenturion, Gauteng\r\n\r\n\r\nR1 000 000 - R1 250 000 a year\r\n\r\n\r\n\r\nAWS Cloud Solutions Architect\r\n\r\n\r\n\r\nRef. No:\r\n\r\nCER008147/TKE\r\n\r\n\r\n\r\nSalary Range:\r\n\r\nR1000000 - R1250000 Annually\r\n\r\n\r\n\r\nBrief Description:\r\n\r\nMy client is looking for an individual who will be responsible for architect, with a solid background in software development \r\n\r\n\r\n\r\nJob Description:\r\n\r\n\r\nEducation: \r\nBachelor degree in related field or comparable experience in the web development required. Substantial experience working with similar technologies and environment\r\nMinimum 6 years’ experience in software engineering\r\nStrong DevOps and Automation Knowledge experience\r\nKnowledge and experience in Docker\r\nDesigning, building and architecting applications for the AWS Cloud\r\n\r\n\r\n\r\n\r\nStrong Knowledge\r\nGit\r\nSVN\r\nGradle\r\nMaven\r\nYarn\r\nBower\r\nYarn\r\nBower\r\nNpm\r\nJenkins\r\nBamboo\r\nGitlab\r\nBitbucket\r\n\r\n\r\n\r\n\r\nWorking Knowledge\r\nSecurity\r\nLoad Balancing\r\nProxies\r\nDNS\r\nCDN\r\nCaching\r\nDatabase\r\n\r\n\r\n\r\n\r\nArchitectural Document and diagrams\r\nUML\r\nFlow diagrams\r\nActivity diagrams\r\n\r\n\r\n\r\n\r\nPlease visit our website www.communicate.co.za to submit your CV directly or to view other I.T related jobs. If you have not had any response in two weeks, please consider your application unsuccessful. Your profile will be kept on our database for any other suitable positions.\r\n\r\n\r\n\r\nWe also invite you to contact us to discuss other exciting career opportunities in our niche area! For more information, please call Thato Kekana on 087 351 0711 or email on thkekana@communicate.co.za\r\n\r\n\r\nSector:\r\n\r\nArchitecture\r\n\r\n\r\nTown:\r\n\r\nCenturion\r\n\r\n\r\nDate:\r\n\r\n11/07/2019\r\n\r\n\r\nExpiry Date:\r\n\r\n10/08/2019"},{"JobTitle":" AWS Cloud Solutions Architect","Url":"https://www.indeed.co.za/rc/clk?jk=7d6c2da7fe1a3a58&fccid=987c1d76161f6506&vjs=3","Source":" Rosstone Consulting","Age":"23 days ago","Salary":null,"Location":"Centurion, Gauteng","Description":"\r\n\r\n\r\nCenturion, Gauteng\r\n\r\n\r\nPermanent\r\nA well-known investment holdings company based in Gauteng, are seeking the expertise of an AWS Cloud Solutions Architect to join on either a contract or permanent basis \r\n\r\n\r\n\r\n\r\n\r\n\r\nTo provide expert advice and solutions pertaining to AWS Cloud\r\n\r\n Experience: 6+ years\r\n6+ years of experience in software engineering and development in large enterprise systems\r\n+- 2 Years in designing, building and architecting applications for the AWS Cloud\r\nStrong technical and analytical skills\r\nStrong DevOps and Automation knowledge and experience\r\nKnowledge and experience in containers (docker) and container management (docker-compose and Kubernetes)\r\nA solid background in software development, the SDLC and working in an Agile and the Scaled Agile Framework environment\r\nFamiliarity with JIRA is preferable\r\nStrong experience and knowledge in CI/CD practices\r\nDevelopment experience in at least one development language\r\nA working knowledge of general IT tools and practices\r\nStrong communication, presentation and mentorship skills, and being able to translate technical jargon to less technical people\r\nThe ability to produce easily understandable Architectural documentation and diagrams\r\n\r\n\r\n\r\n\r\nMinimum educational level: \r\nAn AWS Solutions Architect Professional level certificate is preferable, but candidates with an AWS Solutions Architect Associate level certificate will also be considered\r\nA relevant degree in IT or related engineering discipline is preferable\r\n\r\n\r\n\r\n\r\nTechnical Requirements: \r\nGit\r\nSvn\r\nGradle\r\nMaven\r\nYarn\r\nBower\r\nNpm\r\nJenkins\r\nBamboo\r\nGitlab\r\nBitbucket\r\nPython\r\nJava\r\nJavaScript\r\nC#\r\nKotlin\r\nScala\r\nSecurity\r\nNetworks\r\nLoad Balancing\r\nProxies\r\nDNS\r\nCDN\r\nCaching\r\nDatabases\r\n\r\n\r\n\r\n\r\nAd visible until: 10 August 2019"}]