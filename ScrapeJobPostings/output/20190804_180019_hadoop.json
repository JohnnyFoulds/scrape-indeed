[{"JobTitle":" Data Analyst","Url":"https://www.indeed.co.za/pagead/clk?mo=r&ad=-6NYlbfkN0AMOOo83f3x9FLd22RLK3YfFusStXJLn5R4tAT9NKF0tAvdVEybpYDI30GAsFF9juaiqG3zxw-cD87bqLTaTVKtRYYU9-5DbuE0LhcG591gauzjESTEsxKGpizst-AYVcET6FNpaizeCe-qxSvWUvRGrLn7KYUubG2Vsvty0-3sHVVanbXBNfhwmcb2hpbTCbRdx3gs9LtQNY3uRdDBi7j4ozgpXlyKUni_X-B9dtctPYxtQC9JC6I79kKcV9k3BFNbz6WyR1GyvYv4D5BMM5dpttFrtL9scbKNXOZYz76fuAs2HgMzeRuklv_YU7bh9k5_sRND0hye7N7bfS-U8AP1zlf1Ffb-K-bKuk9bD2TmFYXhUAx3Iex5mDomsCyQM18g69Busb5QqKVMvlHfbwonOX2CtLhzljy0V9AINnH3B1Eardi5qToZSEOizV9a866y0IFijilVdLRJFsUgEtPU4fnI2NFZkhZe65JMXcxnRLmuEEfq8EZOTl0SeJT9H0LdtN8fqMEYJ3lC1DVX4De_JvOJr3a6WeDuDm4A6b9n6fyH9_jN87fIEX6Y_baGb3U=&p=0&fvj=0&vjs=3","Source":" ClarkHouse","Salary":null,"Age":null,"Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\nOur client is looking to drive the advancement and development of analytics within a specific business unit. They are looking to make it more future focused and automate a number of processes and systems. The aim is to also integrate more data science into this area.\r\n\r\nIdeal candidates will have strong analytical abilities and experience with visualisation tools such as Qlikview and PowerBI. Ideal candidates will also have practical experience with Python, R, Hadoop and/or Machine learning, however this is not essential.\r\n\r\n Minimum requirements:\r\n Minimum of a Degree in Computer Science/Informatics/Statistics or similar\r\n Minimum 4 years’ experience in data analytics and practical knowledge of data mining and data analysis\r\n Extensive experience with advanced analytics (predictive and/or descriptive)\r\n Experience with Python, R, Hadoop and/or Machine Learning will be highly advantageous\r\n Experience/exposure to assurance/regulatory/governance/risk will be advantageous"},{"JobTitle":" Data Specialist / Analyst","Url":"https://www.indeed.co.za/pagead/clk?mo=r&ad=-6NYlbfkN0AMOOo83f3x9FLd22RLK3YfFusStXJLn5R4tAT9NKF0tAvdVEybpYDI30GAsFF9juYB5YyDZ_50_6ojKT1s_GEDurYT_PP94C5TK2_0k43iIbEXvk3MviTvWk5gpk1O5XGeIpBmrECqYnC4t79wEciiKYMXX8EdZXR-xj9d5u42FHt0l4TT4zIXb6WLwnaQoSO6y2zWyM-gar__Q8f9Sn6B3wD6XlBDpeLvWH18bSdmtVjNOlkdM-54Dd3W8ULT934yIwP27AQdsgQhK9R8dPHVqYMowXbACael_pUHrCA8CMsKizaGDslvcawiH1XgSBWJpWlvfix9BjMr9Akk5Od7WW3eAC_7HJzxUk-zC59-GBS1XXo80DPrWxfQUXW91AjpM5fXnjJUKIk0JZCEn06nUrd9y7GZbiqPBirtd-VdurhSDxR-sXNcsDhFcKYIWuXqfwS__9RGzauoS1KO8MPzwGZSDvUHYMZI2NuX6v196V9bCL1YqGTzs13r6asGjICJlgyRLJpCj1lKjbqGor9t9GKdLPrerRnk65uzkP4ktfMpajqy6aF1tG6toIpq_nHde42XN3iYtQ==&p=1&fvj=0&vjs=3","Source":" Whizants","Salary":" R800 000 a year","Age":null,"Location":"Pretoria, Gauteng","Description":"\r\n\r\n\r\nPretoria, Gauteng\r\n\r\n\r\nR800 000 a year\r\n\r\n\r\nRate: R- – R- per annum\r\n\r\n Additional to CTC: Car insurance, funeral cover, work cell contract, rebate on fixed line /cell services for private use.\r\n\r\n Location: Centurion & Cape Town\r\n\r\n Role description\r\n\r\nThe incumbent's primary role will be to participate in and to lead data science projects, solving a variety of use cases across the organisation and for its customers. Responsible for playing the role of the expert in employing and evolving data science tools and frameworks across on-prem and cloud big data infrastructure to assist the Insights team to unlock measurable value for the group.\r\n\r\n Minimum Requirements\r\n 3-year degree (NQF level 7) preferably in Computer Science, Mathematics, Statistics, Engineering or a related field; OR Actuarial Science with data science experience. A relevant post graduate degree will be an added advantage.\r\n 5 years relevant experience, at least 2 years of which must have been in a data science environment. Experience in ICT will be an advantage.\r\n Strong statistical & mathematical foundations.\r\n Programming experience (Python, R, Git, Linux).\r\n Cloud computing experience (GCP preferable).\r\n\r\n Key Stakeholders (Internal/External)\r\n Lead data scientist\r\n Senior Data Scientists\r\n Enterprise Information Warehouse\r\n Data Engineering\r\n Software Engineering\r\n Internal and external client’s management\r\n\r\n Job Responsibilities:\r\n Engage with stakeholders to support and in some cases to lead data science project delivery solving business problems or developing solutions\r\n Using mathematical, statistical and machine learning techniques to solve problems\r\n Programming solutions using data science programming languages (Python, R etc.)\r\n Executing end to end exploratory data analysis and product development processes\r\n Implementing visualization (Tableau, PowerBI), advanced analytics and data science solutions for customers\r\n Participate in the development of junior data scientists\r\n Strong support to the lead and senior data scientists\r\n Contribute to our agile way of work and our culture of innovation\r\n\r\n Operational:\r\n Work with the data management team to retrieve data from source\r\n Input on most appropriate data science tools and/or approaches for specific projects\r\n Contribute to our ML/DL codebase through reusable modules\r\n Developing & peer reviewing code\r\n Input into best practice standards\r\n\r\n Core Competencies\r\n\r\n Functional Knowledge\r\n Statistical foundations; Mathematical foundations; Data science and analytics frameworks; Programming (Python, R, Git, Linux); Cloud computing (GCP preferable); Big Data (preferably Hadoop, PySpark)\r\n\r\n Functional Skills\r\n Problem Solving; Coding capability (specifically Python, R, Git, Linux); Cloud computing (GCP preferable); Machine learning; Research & development ability; Communication (written and verbal); Stakeholder management\r\n\r\n Attitudes/ Leadership Competencies\r\n Problem solver; Takes initiative; Task oriented; Hard working with a \"can do\" attitude; Innovative thinker; Works well in teams; Works well under pressure\r\n\r\n Key Decision-Making Authority\r\n\r\n Operational\r\n Decision making on data science project delivery\r\n Value estimation and benefit tracking and realization for data science projects\r\n Peer review of code for data science solutions\r\n Contributing to internal data science training via hackathons and workshops\r\n Adheres to approved processes and best practices for delivery\r\n\r\n Strategic\r\n Provide input and recommendations on client Insight strategic objectives\r\n Provide input and recommendations on data science tools and partnerships to drive innovation and unlock value\r\n\r\n Key Metrics\r\n Delivery of data science projects: Time, budget, quality\r\n Contribution to data science best practices through reusable code and tools\r\n Contribution to training and development of data science competencies\r\n Reputational scoring with stakeholders"},{"JobTitle":" Data Analytics Manager","Url":"https://www.indeed.co.za/pagead/clk?mo=r&ad=-6NYlbfkN0AMOOo83f3x9FLd22RLK3YfFusStXJLn5R4tAT9NKF0tAvdVEybpYDI30GAsFF9juaiqG3zxw-cD_u2h33BgIs_gGgsMWGGcbyBZeFrkwaaRFXKodEJnKDDZL_X0fJYj3levsP2HvvMh99_pB9ieKSrjYMXFzxq4C12jWmXdnKSz57G5iLspDAHA2nznSNNgIhhI-oPKQlCJWfLPL5uPmRTq5IzAQiS4TSNmtC2XTTEOSl-lvcZN9SSa7SgrzoOKYuv-DbR2dmbVagJBnRrMQh0xkIMW8o_a1VbSpK5wPY8UhT7Mguq1sYIpi88yWbxsdAxacWC56UENT8FY0N_CdYy2MV_LfVnnKrlM4_pQeuQV5LmLp6pbstS72nzptrFa16W6Fg3C-JMoCJxIWvo-5F0AKJvC5c8PbIa8eg-GC0YVWsU4OSHN9PVtPTdEQcGAULPysvnMMDQtJI-hNk5TOBa-i-uXeK3exEpXTw9uztQTd55BWc_1szCQnTP3grWD_4QPeO47waNqJOi04FP4-cTLMT8uxjlUGlcTy2bDn9qwjgRNY2hTk-TnIujuM1jzG70EhWkW8tj7kOO4LW7J39F&p=2&fvj=0&vjs=3","Source":" ClarkHouse","Salary":null,"Age":null,"Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\nYou will be responsible for driving the Data Analytics Strategy within your business unit. You will develop sustainable and re-useable data analytics models, programs and dashboards to improve efficiencies and coverage.\r\n\r\nIdeal candidates will be adaptable and have solid management experience. You will have strong stakeholder engagement skills and the ability to build relationships with data warehouse stakeholders, data providers etc.\r\n\r\n Minimum requirements:\r\n Minimum of a Degree in Computer Science/Informatics/Statistics or similar\r\n Management experience is essential\r\n Extensive experience with advanced analytics (predictive and/or descriptive)\r\n Experience with Python, R, Hadoop and/or Machine Learning will be highly advantageous"},{"JobTitle":" Senior Data Engineer, Centurion, R1.1mill","Url":"https://www.indeed.co.za/pagead/clk?mo=r&ad=-6NYlbfkN0AMOOo83f3x9FLd22RLK3YfFusStXJLn5R4tAT9NKF0tAvdVEybpYDI30GAsFF9jubutPs3PbEcmtmLrFChIT3R5PcSW-K3vOaXfM1TVIq9vqIzmVs4Y-78rX3KNlwRKAcj0hbBwlEoCTRyXdIIeZwKKz94t0G_cuvyNvzAhj_FI9IRXEpfGEOZ59mncsO2rapy95t2oRLUoG5vmXham87kjs3JFEmCPE2fwOH2pH0MVqLtLUalvJQsqXI4Pgdf4KAaestwFSdktbqVyVIkKQyxyTE5aEGkjyjLFOS_JZ1DoaCe8SM_rMFOd2uoEYNJfUz8Q3biNuQ13ooOPxhJfLvsT-Ha38GvO5O9mS-6yCNc3et1TnDJwTeoFVufA-A1Fjz5nPQuJLg6w4GE_bT8Lccnjoat6TPdMYoXN6UKHvgRrxxoYcOR1e28Q-NM53WWkxMV3lsI7RNKu4Tx1TWLlAQkVCJOdqEmUH4DAJoJ8nxpObG7XjuMA9LT1edKu3yUSX5iqxtIPyzHW2038llBk4lgwNplnodi60MJdi4Cp8bmnJsAOqMsSpXz9TNYsaUZVqNm4f97H5aYZn9AMuCDiLitpE3A7YR6NMc=&p=3&fvj=0&vjs=3","Source":" E-Merge","Salary":null,"Age":null,"Location":"Pretoria, Gauteng","Description":"\r\n\r\n\r\nPretoria, Gauteng\r\n\r\n\r\nOne of the fastest growing telecommunications providers in South Africa, that operate in more than 38 countries across the African continent, is looking for high calibre Senior Data Engineers to join their team. They are looking for candidates that ideally have 5 years of work experience in the field of data engineering and at least 2 years lead/management/specialist level experience.\r\n\r\n Requirements:\r\n Relevant IT degree\r\n Database foundation; Data engineering foundation; Programming foundation; Cloud computing; Relational SQL and NoSQL databases\r\n Big data engineering (e.g. Cloudera, Hadoop, Spark)\r\n Programming (e.g. Python, SQL, Git, Shell, JavaScript)\r\n Cloud computing and platform management (e.g. GCP, Azure)\r\n Stakeholder management\r\n\r\nReference Number for this position is MH46188. This is permanent role based in Centurion offering up to R1.1mill per annum based on experience, skillset and current level. Contact michelle on -Please upload your CV here-\r\n\r\nAre you ready for a change of scenery? e-Merge IT recruitment is a niche recruitment agency. We offer our candidates options so that we can successfully place the right people with the right companies, in the right roles. Check out the e-Merge IT website for more great positions.\r\n\r\nDo you have a friend who is a developer or technology specialist? We pay cash for successful referrals!"},{"JobTitle":" BIG Data Architect","Url":"https://www.indeed.co.za/rc/clk?jk=4b5fc168693f01f6&fccid=a4e4e2eaf26690c9&vjs=3","Source":" Accenture","Salary":null,"Age":"30+ days ago","Location":"South Africa","Description":"\r\n\r\n\r\nSouth Africa\r\n\r\n\r\nAligning technology with business strategy and goals they work directly with the client gathering requirements to analyze, design and/or implement technology best practice business changes. They are sought out as experts internally and externally for their deep functional or industry expertise, domain knowledge, or offering expertise. They enhance Accenture's marketplace reputation.\r\n\r\n\r\n\r\n Innovate with the newest technologies. \r\n\r\nBe part of the New. Now.\r\n\r\nUnleash your skills and transform the world around you. Shape the technology of tomorrow, with the latest digital methodologies and design thinking, like cloud, AI, intelligent automation, DevOps and Agile. Implement innovative solutions to help clients drive disruption and stay ahead of the digital curve. \r\n\r\nDeveloping, designing and maintaining technologies that improve the way our clients and the world works. Supporting the core of Accenture's Technology business, they use curiosity to solve Technology problems through developing, designing, and maintaining software products or systems that enable client strategies. Working in challenging and dynamic environments, they use their versatility to create and support technology solutions that meet client requirements from analysis to implementation. \r\n\r\nJoin Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements and the way we collaborate, operate and deliver value provides an unparalleled opportunity to grow and advance. Choose Accenture, and make delivering innovative work part of your extraordinary career. \r\n\r\nPeople in our Client Delivery & Operations career track drive delivery and capability excellence through the design, development and/or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward.\r\n\r\n\r\n\r\n Our offer\r\nUnparalleled opportunities to build a career \r\nComprehensive and specialized training covering business acumen, digital acumen, technical and professional skills development \r\nCareer development opportunities and perspective \r\nChallenging and exciting projects at some of the world's leading companies in all industries \r\nAccess to a global network of deeply skilled and experienced supply chain professionals\r\n\r\nJob Description \r\n\r\nWe are looking for a Big Data Architect and Team Lead who has a passion and interest to help organizations optimize their business performance by ingesting, processing, and managing big volumes of fast multi structured data as well as extracting meaningful value from these large volumes of data. You will have the knowledge and previous experience of using Big Data methodologies, solutions and platforms and tools to enable you to help our clients.\r\n\r\n\r\n\r\nYou will be expected to be able to work independently and, in a team, and have experience working in an agile environment. We are looking for someone who is a passionate architect and you must have the ability to articulate your ideas and work well with our clients at the architectural level. You will need to have strong communication skills and be comfortable and confident engaging and leading our team members and key client stakeholders. You will have also worked across multiple platforms such as Cloudera, Hortonworks, Google Cloud, Azure and AWS and have previous experience of building Enterprise Data Lakes. Additional experience in metadata driven data ingestion, Big data metadata management, governance and implementing data security controls would be advantageous.\r\n\r\n\r\n\r\nYour Experience\r\n\r\nAs a Big Data Architect, you will be responsible for guiding the full lifecycle of a Big Data solution, including:\r\nFocus on designing and implementing Big Data Pipelines \r\nManaging and engaging with key client stakeholders and leading an internal team of developers and engineers \r\nTake ownership for end to end solution integrity (including design, build, test and deploy) \r\nWork with and guiding clients to ensure the best application of big data solutions is chosen for their current situation \r\nEffectively communicate with clients to contribute throughout the end-to-end delivery lifecycle of complex and large-scale Big Data lakes \r\nMaintain and communicate the current-state architecture (where we are today) and the target-state architecture vision (where we are going) \r\nSupport in Proof of concept execution to prove the value of Big Data use cases \r\nHelp facilitate the full lifecycle implementation from requirements analysis, platform selection, technical architecture design, application design and development, testing, and deployment \r\nReview of all technical approaches for platform enhancements and customer solutions \r\nTrack and monitor progress of tasks and proactively raise issues which may impact delivery \r\nSupport the translation of the technical architecture into backlog generation, estimation exercises for sprint planning and future release planning and the review and signoff of all technical deliverables\r\n\r\n\r\n\r\nOur Expectations include the ability and experience to perform the following:\r\n3-5 years of hands on experience across at least 2 Big Data project implementations \r\nAbility to articulate technology choices in addressing architecture concerns and constraints \r\nAt least 5 years of consulting experience having successfully led large teams in delivering customer outcomes \r\nUnderstanding of DevOps pipelines and key Agile concepts \r\nKnowledge of cloud infrastructure (particularly AWS or Azure) \r\nKnowledge of security design, data management, data governance, lineage and audit. \r\nCan demonstrate an understanding across systems integration, information management, data management and architecture, and business analytics \r\nHas deep experience with Cloudera Hadoop (or similar stack such as Hortonworks) distributions and application programming (MapReduce, Pig, Cascading, Hive, Impala, Storm, Spark etc.) \r\nExposure to working in Agile projects with involvement in MVP definition, sprint planning, back-log grooming ad resolving blockers on technical solutions \r\nExperience leading large-scale, multi-release information centric projects and delivery experience leveraging multiple delivery locations (onshore + nearshore/offshore) \r\nFamiliar with designing high volume and fast big data solutions that have been successfully implemented into a production environment, both batch and stream processing using frameworks like Apache Nifi/Beam/Flink \r\nStrong understanding of data warehouse, data lake and associated ETL and data processing concepts \r\nAbility to articulate and hold solution discussion with key stakeholders Senior Enterprise Analytics Architects \r\nUniversity degree, preferably in Computer Science/IT/Engineering or in a related field \r\nDemonstrate a passion for innovation and new idea generation"},{"JobTitle":null,"Url":"https://www.indeed.co.za","Source":" Structureit","Salary":null,"Age":"30+ days ago","Location":null,"Description":null},{"JobTitle":" Big Data Platform Engineer(Hadoop)","Url":"https://www.indeed.co.za/rc/clk?jk=aca8b3c9b0a849a0&fccid=b54c24d0673e4b40&vjs=3","Source":" Praesignis","Salary":null,"Age":"30+ days ago","Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\nContract\r\nIntermediate Big Data Platform Engineer (Hadoop) responsible for the enterprise-wide administration and engineering of Hadoop and Data Science Workbench environments based in Gauteng. \r\n\r\n\r\n\r\n\r\n\r\nSystem and database Administration\r\nSolution and infrastructure, design, development, intergration, security, networking and automation\r\nData management & governance, user support and education\r\nCloud\r\nHadoop Environment\r\nLinux(Ubuntu,SLES,CentOS/RH)\r\nLog Debugging Enthusiast\r\nHive Maintanance\r\n\r\n\r\n\r\n\r\nAd visible until: 4 August 2019"},{"JobTitle":" MongoDB Database Administrator","Url":"https://www.indeed.co.za/company/eSoft-development-and-technologies/jobs/Mongodb-Database-Administrator-687fcb35c020be62?fccid=110acbcf0cf06798&vjs=3","Source":" eSoft development and technologies","Salary":null,"Age":"5 days ago","Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\nContract\r\n\r\nJOB DESCRIPTION: \r\n\r\nThe MongoDB Database Administrator will be actively involved in the evaluation, review, and management of database resources and services across the organization in order to ensure a high level of database integrity is reached and maintained.\r\n\r\nRESPONSIBILITIES: \r\nDeploys and maintains MongoDB databases/DB projects\r\nMaintains detailed documentation of database Design/Architecture and setup\r\nEstablishes procedures for backup/recovery and disaster recovery\r\nAdministers MongoDB to achieve maximum availability and performance\r\nDesigns and implements sharding and indexing strategies for MongoDB\r\nConfigures and monitors replica sets\r\nPerforms patch upgrades\r\nDesigns and builds operational infrastructure to support our databases, automating where possible\r\nEstablishes database security procedures\r\nCreates users, assign roles and manages permissions\r\nMaintains current knowledge of industry trends and standards\r\nProvides support to the user community using incident and problem management tools\r\n\r\nREQUIREMENTS: \r\nAt least 5 years experience with multiple database environments, preferably including SQL Server and Oracle\r\nStrong experience with MongoDB including at least 2 years of hands-on experience with\r\nMongoDB in an enterprise-scale architecture including replica sets and sharding\r\nExperience designing and optimizing strategies for inserting large amounts of data\r\nExperience with Microsoft Azure desirable\r\nUnderstanding of Big Data architecture like Hadoop and integration with NoSQL datastores\r\nMust have a strong problem research and resolution skills\r\nHighly self-motivated with the desire to embrace new database technologies and be able to work independently and within a team in a high demand and dynamic environment\r\n\r\nJob Types: Full-time, Contract"},{"JobTitle":" SENIOR DATA ENGINEER","Url":"https://www.indeed.co.za/company/PEPKOR/jobs/Senior-Data-Engineer-b151ab5a05b44e17?fccid=8fdbbfa32556ef52&vjs=3","Source":" Pepkor","Salary":null,"Age":"5 days ago","Location":"Tygervalley, Western Cape","Description":"\r\n\r\n\r\nTygervalley, Western Cape\r\n\r\nPURPOSE OF THE JOB\r\nWe are looking for a data/ML Engineer that will assist and work closely with the Data Science Team to develop and implement practical and realistic data modelling solutions within the business. These solutions must also be made to be long lasting, fail-safe and reusable, with a strong focus on automation.\r\n\r\nKEY RESPONSIBILITIES:\r\nEnsures that all production analytical products are working properly in terms of actual execution and requirements\r\nEnsures that output/products from the Data Science team is usable in production, maintainable, scalable and reusable\r\nAutomates and abstracts away different repeatable routines that are present in most machine learning tasks\r\nEnables the best product development practices are used within the team and helps them to speed up work from an advisory perspective\r\nIntegral part of choosing architectural environment and tool choices\r\nCollaborate with data engineers and IT teams to build data and model pipelines\r\nManage the infrastructure and data pipelines needed to bring code to production\r\nUnderstand and use computer science fundamentals, including data structures, algorithms, computability and complexity and computer architecture\r\nUse mathematical skills, in order to perform computations and work with the algorithms involved in this type of programming\r\nDemonstrate end-to-end understanding of applications (including, but not limited to, the machine learning algorithms) being created\r\nUnderstand algorithms based on statistical modelling procedures and build and maintain scalable machine learning solutions in production\r\nCommunicate and explain complex processes to people who are not programming experts\r\nLiaise with stakeholders to analyse business problems, clarify requirements and define the scope of the resolution needed\r\nResearch and implement best practices to improve the existing machine learning infrastructure\r\n\r\nJOB INCUMBENT REQUIREMENTS\r\nBachelor's degree in Computer Science, Engineering, Information Systems, or similar degrees.\r\n3 + years' of experience in data engineering or software development would be advantageous\r\nDeep understanding of predictive modelling, machine-learning, clustering and classification techniques, and algorithms such as k-NN, Naive Bayes, SVM, Decision Forests, etc.\r\nFluency in a programming language including but not limited to Python, SQL\r\nExperience in cloud technologies would be advantageous\r\nFamiliarity with Big Data frameworks (Cassandra, Hadoop, Spark)\r\nExperience with data visualisation tools, such as D3.js, GGplot, Shiny, etc.would be an advantage\r\nExperience with NoSQL databases, such as MongoDB, Cassandra, HBase would be an advantage\r\nGreat communication skills\r\nWorks well in a team\r\n\r\nJob Type: Full-time"},{"JobTitle":" Data Engineer","Url":"https://www.indeed.co.za/rc/clk?jk=70e886a89eaf1f63&fccid=714e147560da822f&vjs=3","Source":" Standard Bank","Salary":null,"Age":"4 days ago","Location":"Rosebank, Gauteng","Description":"\r\n\r\n\r\nRosebank, Gauteng\r\n\r\n\r\n\r\n\r\nRisk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank\r\n\r\nJob Purpose\r\n\r\nSupport in providing infrastructure, tools and frameworks used to deliver end-to-end solutions to business problems. Build scalable infrastructure for supporting the delivery of business insights from raw data sources with a focus on collecting, managing, analysing, visualising data and developing analytical solutions.\r\n\r\n Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.\r\n\r\nKey Responsibilities/Accountabilities\r\n\r\nAssist in creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases. Work alongside data scientists to help make use of the data they collect.\r\n Assemble large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.\r\n Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.\r\n Utilise data under supervision to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\r\n Designing and developing scalable ETL packages from the business source systems and the development of ETL routines in order to populate databases from sources and to create aggregates. Manager large-scale data Hadoop platforms and to support the fast-growing data within the business.\r\n Assist in enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.\r\n Assist in performing thorough testing and validation in order to support the accuracy of data transformations and data verification used in machine learning models.\r\n Perform ad-hoc analyses of data stored in Standard Banks databases and writes SQL scripts, stored procedures, functions, and views. Proactively analyses and evaluates the Standard Banks databases in order to identify and recommend improvements and optimisation. Deploy sophisticated analytics programs, machine learning and statistical methods.\r\n Analyse complex data elements and systems, data flow, dependencies, and relationships in order to contribute to conceptual physical and logical data models.\r\n Liaise and collaborate with the entire EDO team, providing support to the entire department for its data centric needs. Collaborate with subject matter experts to select the relevant sources of information and translates the business requirements into data mining/science outcomes. Presents findings and observations to team for development of recommendations.\r\n\r\n\r\nPreferred Qualification and Experience\r\n\r\nFirst Degree\r\n Honours Degree\r\n\r\n Experience:\r\n\r\n\r\n\r\n Years: 3-4 years\r\n Experience Description: Experience with big data tools: Hadoop, Spark, Kafka, etc. Experience with relational SQL and NoSQL databases, including Postgres and Cassandra. Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc. Experience with AWS cloud services: EC2, EMR, RDS, Redshift. Experience with stream-processing systems: Storm, Spark-Streaming, etc. Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.\r\n\r\n\r\n Years: 3-4 years\r\n Experience Description: Working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Experience building and optimizing ‘big data’ data pipelines, architectures and data sets. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.\r\n\r\n\r\n\r\n Years: 3-4 years\r\n Experience Description: Strong analytic skills related to working with unstructured datasets. Build processes supporting data transformation, data structures, metadata, dependency and workload management. A successful history of manipulating, processing and extracting value from large disconnected datasets. Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.\r\n 3 years\r\n\r\n\r\nKnowledge/Technical Skills/Expertise\r\n\r\nIT Architecture- Architectural methodologies used in the design and development of IT systems.\r\n Data Integrity- The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.\r\n IT Applications- Knowledge and understanding of IT applications and architecture.\r\n Data Analysis- Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.\r\n Knowledge Classification- The ability to apply metadata to information to make it easy for other people to find.\r\n Database Administration- Refers to the knowledge and experience required to manage the installation, configuration, upgrade, administration, monitoring and maintenance of physical databases."},{"JobTitle":" Data Engineer","Url":"https://www.indeed.co.za/rc/clk?jk=57e026e661271eea&fccid=879a62b6121692b6&vjs=3","Source":" OfferZen","Salary":null,"Age":"30+ days ago","Location":"Cape Town, Western Cape","Description":"\r\n\r\n\r\nCape Town, Western Cape\r\nWhy is now a good time to join OfferZen? \r\n\r\n Over the last 3 years, OfferZen ( https://www.offerzen.com/ ) has managed to make a large dent in the South African tech recruitment space – and we're speeding up. Our team has exploded from 4 to 60+. We're looking to add more smart people who want to contribute meaningfully. \r\nOfferZen was founded by Philip and Malan Joubert, along with other successful tech startups like SnapScan ( http://www.snapscan.co.za/ ), JourneyApps ( https://www.journeyapps.com/ ) and Luno ( https://www.luno.com/ ). \r\nOur mission is to improve the experience of finding work for makers – people involved in making software, from developers to designers and data scientists. OfferZen does that by flipping the traditional recruitment model on its head and getting companies to reach out to makers with upfront offers. \r\n\r\n The opportunity \r\n\r\n You'll be working in a Data squad as part of our Product Group, a talented group of developers, engineers and data scientists focussing on our data platform. You'll be joining a growing, data-centric organization with a culture of experimentation and analytical thinking. \r\n\r\n What you'll do \r\n\r\n At OfferZen, data is key to enabling teams, processes and our customer base to scale. You'll be helping create data products in three main areas: \r\n\r\nPersonalization – creating an excellent user experience for companies and candidates\r\nOperations – informing and assisting company level decision-making\r\nCustomer Growth – helping more people find an awesome tech job.\r\nThis creates an ideal opportunity for a Data Engineer to thrive and deliver high impact solutions. This position is well-suited to someone looking to grow their technical and collaboration skills. You'll work in a supportive environment, with outstanding teammates, and gain experience across the full range of responsibilities. \r\n\r\n What you'll need \r\n\r\n3+ years experience with data modelling and database technologies.\r\nA solid foundation in computer science in areas such as software architecture and data structures\r\nAbility to work both autonomously, and in a small team to solve complex problems\r\nCare about the quality and impact of your work\r\nA good knowledge of a high-level programming language (E.g. Ruby, Python, Go).\r\nExperience in using data processing for analytics or built data processing capabilities.\r\nExperience with database technologies and paradigms – relational, noSQL, warehousing\r\nBonus for experience with Hadoop based technologies (MapReduce, Hive, Pig)\r\nBEng or BSc CS degree, or equivalent working experience\r\nWhat it's like to work here \r\nWe are a fun loving and very driven team of 60+ people. We are transparent with our numbers and strategy and have weekly learning sessions where someone in the company presents something they do. We get lunch every day and have 20 days of leave a year. We do fun stuff together like going on picnics at Kirstenbosch, playing board games and having Sumo wrestling events! \r\n\r\n About OfferZen \r\nWe're helping makers – the people who design and build software products – to unlock their individual potential. We started with recruitment because helping someone find a job they love is one of the fastest ways of changing their life. Since then, we've started expanding to things like training, root ( https://root.co.za/ ) (programmable banking for developers) and building tools for the tech community. \r\n\r\nour team : )"},{"JobTitle":" Cloud Support Engineer (Analytics)","Url":"https://www.indeed.co.za/rc/clk?jk=b48b7b02f107a23d&fccid=fe2d21eef233e94a&vjs=3","Source":" Amazon Web Services SA Pvt Ltd","Salary":null,"Age":"30+ days ago","Location":"Cape Town, Western Cape","Description":"\r\n\r\n\r\nCape Town, Western Cape\r\n\r\nStrong Operating System administration experience (Linux or Windows)\r\nExperience in Networking (DNS, TCP/IP)Understanding of the concepts of Virtualization and Cloud Computing\r\nSelf-starter who is excited about learning new technology\r\nComfortable in an ambiguous, ever changing environment\r\n\r\n\r\nABOUT US\r\n Amazon has built a reputation for excellence and Amazon Web Services (AWS) is carrying on that tradition while leading the world in Cloud technologies. . AWS is seeking talented engineers who enjoy solving problems, working with customers, and have a technical background from a variety of different fields including Linux/Windows systems administration, big data analysis, and network administration. As a member of the AWS Support team you will be at the forefront of this transformational technology assisting a global list of companies that are taking advantage of a growing set of services and features to run their mission-critical applications. You will work with leading companies in this space and directly with the engineering teams within Amazon developing these new capabilities.\r\n\r\n Amazon has a fast-paced environment where we “Work Hard, Have Fun, Make History.” On a typical day, a Cloud Engineer might thoughtfully work with customers to dive deep into the root cause of an issue, investigate why a metric is trending the wrong way, consult with a diverse range of engineers at Amazon and discuss radical new approaches to automate operational issues. As an Analytics engineer our customers will depend on your knowledge in Elasticsearch, Managed Service Kafka or Kinesis.\r\n\r\n ABOUT YOU\r\n\r\n Apart from working on a broad spectrum of technical issues, an AWS Engineer may also coach/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools/script to help the team, or work with leadership on process improvement and strategic initiatives.\r\n\r\n Our Cloud Engineers are also the “voice of the customer” and have a strong voice into the development teams for recurring issues or feature requests.\r\n\r\n As we operate on a follow-the-sun model, with Premium Support sites located globally, there is no after hours on-call or mandated overtime in this role! Select a working week that works for you, working Sunday through to Thursday or Tuesday through to Saturday. Go forth and have the work-life balance you have always dreamed of!\r\n\r\n A suitable candidate would be someone who is extremely customer focused, who could multi-task and utilize both written & verbal communication skills to help our diverse range of customers resolve their complex technical issues.\r\n\r\n\r\nExpertise with Linux system administration in a virtual environment, file structure management, common Linux applications, system troubleshooting tools\r\nExperience working in Large Enterprise, Public Sector, or with vendor managing, and/or maintaining large scale Enterprise systems.\r\nExposure to security concepts / best practices\r\nExperience managing full application stacks from the Operating System up through Front End applications\r\nExperience analyzing, troubleshooting, and providing solutions for technical issues\r\nBusiness Analytics configuration, support, and troubleshooting\r\nExperience scripting or developing in Python or Java\r\nDESIRED QUALIFICATIONS\r\n\r\nDemonstrable Knowledge & experience in various Big Data or distributed systems. Such as Hadoop, NoSQL, Search and Streaming.\r\nKnowledge and experience maintaining large networks (Routers, Switches, Firewalls)\r\nBachelor’s degree in Information Science / Information Technology, Computer Science, Engineering, Mathematics, Physics; or relevant work experience\r\n\r\n The working hours for this role are: 6am-3pm OR 7am-4pm (including lunch)\r\n\r\n You will work 5 days per week but may be faced with a non-standard weekend. The working days are Mon-Fri OR Tues-Sat OR Sun-Thurs\r\n These shifts are dependent on team capacity, but flexibility is always open for discussion.\r\n\r\n‘’Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity and Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.’’"},{"JobTitle":" Senior Data Engineer","Url":"https://www.indeed.co.za/rc/clk?jk=2ac4dd802f3e65b3&fccid=745f50042cd32f08&vjs=3","Source":" Unique Personnel","Salary":null,"Age":"5 days ago","Location":"South Africa","Description":"\r\n\r\n\r\nSouth Africa\r\n\r\n\r\nContract\r\n\r\n\r\n\r\n\r\n\r\nJob Listing \r\n\r\n\r\n\r\n\r\n\r\nJob Number\r\n\r\n58073 \r\n\r\n\r\n\r\n\r\nJob Type\r\n\r\nContract \r\n\r\n\r\n\r\n\r\nJob Title\r\n\r\nSenior Data Engineer \r\n\r\n\r\n\r\n\r\nComputer Skills\r\n\r\nData Analytics,Database Administration,Java,MS Excel,MS Outlook,MS PowerPoint,MS SQL,MS Word,MySQL,Python,SQL,Windows 10 \r\n\r\n\r\n\r\n\r\nIndustry\r\n\r\nIT Development & Software \r\n\r\n\r\n\r\n\r\nCity\r\n\r\nPlease select city \r\n\r\n\r\n\r\n\r\nProvince\r\n\r\nGauteng \r\n\r\n\r\n\r\n\r\nJob Description\r\n\r\nThe Senior Data Engineer is responsible for overseeing junior data engineering activities and aiding in building the business’ data collection systems and processing pipelines. The role of the Senior Data Engineer is responsible for building and maintaining optimized and highly available data pipelines that facilitate deeper analysis and reporting by the Data and Analytics department. The Senior Data Engineer builds data processing frameworks that handle the business’s growing database. He works with senior data science leadership as well as other Data and Analytics teams in leveraging data with reporting and scientific tools, for example, Tableau, R, and Spark. The Senior Data Engineer strives to continuously develop new and improved data engineering capabilities. Management and Strategy: The managerial role of the Senior Data Engineer is primarily for overseeing activities of the junior data engineering teams, ensuring proper execution of their duties and alignment with business vision and objectives. He provides senior-level contribution to a team that is responsible for the design, deployment, and maintenance of the business’s data platforms. However, the Senior Data Analyst will also implement strategies directed at acquiring data and promoting the development of new insights across the business. The Senior Data Engineer owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets. It is his duty to monitor the existing metrics, analyze data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. The Senior Data Engineer will additionally develop queries for ad hoc business projects, as well as ongoing reporting. In this capacity, the Senior Data Engineer builds a metadata system where all available data is maintained and cataloged. The Senior Data Engineer also plays a major role in the development of reliable data pipelines that translate raw data into powerful features and signals. He designs, architects, implements, and supports key datasets that avail structured and timely access to actionable business insights. The Senior Data Engineer is additionally tasked with developing ETL processes that convert data into formats through a team of data analysts and dashboard charts. Collaboration and Support: The Senior Data Engineer plays a collaborative role where he works closely with the business’s Data and Analytics teams, gathering technical requirements for exceptional data governance across the department and the business at large. In this collaboration, the Senior Data Engineer works the data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large. The Senior Data Engineer will also work with senior data science management and departments beyond the Data and Analytics department in analyzing and understanding data sources, participating in design, and providing insights and guidance on database technology and data modeling best practices. In this capacity, the Senior Data Engineer will further be required to draw performance reports and strategic proposals form his gathered knowledge and analyses results for senior data science leadership. Analytics: The Senior Data Engineering plays an analytical role where he develops and manages scalable data processing platforms that he uses for exploratory data analysis and real-time analytics. It is also the role of the Senior Data Engineer to oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and efficient data acquisition. In this capacity, the Senior Data Engineer retrieves and analyzes data through the use of SQL, Excel, among other data management systems. He also builds data loading services for the purpose of importing data from numerous disparate data sources, inclusive of APIs, logs, relational, and non-relational databases. Knowledge and Opportunity: The Senior Data Engineer is tasked with the responsibility of contributing to the continual improvement of the business’s data platforms through his observations and well-researched knowledge. He keeps track of industry best practices and trends and through his acquired knowledge, takes advantage of process and system improvement opportunities. Other Duties: The Senior Data Engineer performs similar duties as he deems fit for the proper execution of his duties and duties as delegated by the Head of Data Science, Director Data Science, Chief Data Officer, or the Employer. Experience: A candidate for this position must have had at least 5 years of working experience working in a data engineering department, preferably as a Data Engineer in a fast-paced environment and complex business setting. The candidate must have a demonstrated experience in building and maintaining reliable and scalable ETL on big data platforms as well as experience working with varied forms of data infrastructure inclusive of relational databases such as SQL, Hadoop, Spark and column-oriented databases such as Redshift, MySQL, and Vertica. The candidate must also have had experience in data warehousing inclusive of dimensional modeling concepts and demonstrate proficiency in scripting languages, for example, Python, Perl, and so forth. A suitable candidate will also demonstrate machine learning experience and experience with big data infrastructure inclusive of MapReduce, Hive, HDFS, YARN, HBase, Oozie, etc. The candidate will additionally demonstrate substantial experience and a deep knowledge of data mining techniques, relational, and non-relational databases. Communication Skills: Communication Skills for the Senior Data Engineer are just as important as they are for the Data Engineer, both in verbal and written form. The Senior Data Engineer oversees and manages junior data engineering teams and to ensure effective management, he must be capable of conveying information and instructions clearly down the line to the junior team. Communication skills are also imperative for the Senior Data Engineer in his collaborative role where he will have to interact cross-functionally with non-technical departments. To enable effective collaborations, the Senior Data Engineer will have an exceptional ability to convey complex messages in a clear, simplified, and understandable manner. He will also be required to draft reports and prepare presentations for senior data science leadership. These reports and presentation must be clear, concise, unambiguous, engaging and convincing, which will demand exceptional communication skills on the Senior Data Engineer’s part. Ms Office/Software: A candidate for this position must be highly proficient in the use of Ms Word, Ms Excel, PowerPoint, and Outlook, which will all be necessary for the creation of both visually and verbally engaging reports and presentations, for senior data science leadership. The Senior Data Engineer must further have exceptional skills in SQL server reporting services, analysis services, Tableau, Salesforce, integration services, or any other data visualization tools. Technological Savvy/Analytical Skills: A candidate for this position will also demonstrate strong computer skills and a deep passion for analytics. The candidate for this position must possess an ability to perform complex data analyses with large data volumes. He will be an expert in SQL, Java, and have a keen understanding of data models and data warehouse concepts. The candidate will demonstrate an ability translate algorithms provided by senior data science management and implement them in as well as strong knowledge in Linux, OS tools, and file-system level troubleshooting. The candidate must have substantial experience working with big data infrastructure tools such as Python, SQS, and Redshift. A suitable candidate will also be proficient Scala, Spark, Spark Streaming, AWS, and EMR. Interpersonal Skills: The Senior Data Engineer must have certain preferable personal attributes that will make him that much more suited for the position. The Senior Data Engineer will be a result-driven individual, be passionate and a self-starter, be proactive requiring minimal supervision, be highly organized, have an ability to handle multiple tasks and meet tight deadlines, be a creative and strategic thinker, work comfortably work in a collaborative setting, work comfortably with senior departmental leadership, and demonstrate an ability to remain calm during times of uncertainty and stress, inspiring the same in his team. People Skill: The candidate must be a people person who is able to form strong, meaningful, and lasting connections with others, enabling smooth and continued collaborative relationships, earning him the trust of his juniors who will readily follow in his directives, and gaining the confidence of senior data science leadership \r\n\r\nTo apply immediately for this position click here: http://www.unique.co.za/candidate_registration_1.aspx?JobID=58073&referrer=Unique\r\n\r\n\r\n\r\n\r\nInherent Requirements\r\n\r\nThe Senior Data Engineer must have a bachelor’s degree (masters’ preferred) in Computer Science, Applied Mathematics, Engineering, or any other technology related field. An equivalent of this educational requirement in working experience is also acceptable. \r\n\r\n\r\n\r\n\r\nWhat Qualification\r\n\r\nRelated to Industry \r\n\r\n\r\n\r\n\r\nMinimum Qualification\r\n\r\nMasters \r\n\r\n\r\n\r\n\r\nStatus\r\n\r\nAvailable"},{"JobTitle":" Specialist: Data Science","Url":"https://www.indeed.co.za/pagead/clk?mo=r&ad=-6NYlbfkN0AMOOo83f3x9FLd22RLK3YfFusStXJLn5R4tAT9NKF0tAvdVEybpYDI30GAsFF9jua4gMfYLZDENtf3Ry_6p2Dvk0RiaYC6ED3udZsJcMRYZVQeo-XSX9ubo1UJG7T64aS4CnKiIwjQjx2DkRpehIexxnpyQ4DuTrYpuG_AA54gnkqqJvx7dwVAc4-WKH4WUXuXLbF9uX0j_IEqqnCm9H83M8GmMDuMxDryBge5TSKH-REQNKZQbBkxgNE7p9bLGcvY1bHsBdF-eCIGy6NpD95KFftz3aOWOajeYwJ5elmeDEiCZlD6KCEbYGQEBEmQnzg6a1naaaoS8FY9byv0HoZClyk5cf674JI27siNZ1l3XZhJW29bemkOoQ3ChGN-O8g5s6turevj0boVfiMVzWfDEk3giNpgRC-w91X1cL1D3Yetvf79SG6gkOoSSr8AtzvXlsia5Hdc34RoRpZ1ozI0etTq-iQI1GmxsF2pR-7qoss4vFdk6BjkbXoVFacc7OFwOywbvwUaLhD8YJFllS85rZlJAz2bWtcxbk4BgPgGpi3R7KbCGTg0cjQY1-lzyJvhKY4wDj-mbFerhCFOTyA_&p=13&fvj=0&vjs=3","Source":" Zeal HR","Salary":null,"Age":null,"Location":"Cape Town, Western Cape","Description":"\r\n\r\n\r\nCape Town, Western Cape\r\n\r\n\r\nA well-known telecommunications company is currently seeking to employ an experienced Specialist – Data Scientist. The position will be based in Cape Town and the main role will be to participate in and to lead data science projects, solving a variety of use cases across the group.\r\n\r\n\r\n\r\nRequirements:\r\n Matric/ Grade 12 Certificate\r\n 3-year degree (NQF level 7) preferably in Computer Science, Mathematics, Statistics, Engineering or a related field; OR Actuarial Science with data science experience. A relevant post graduate degree will be an added advantage.\r\n 5 years relevant experience, at least 2 years of which must have been in a data science environment. Experience in ICT will be an advantage.\r\n Strong statistical & mathematical foundations.\r\n Programming experience (Python, R, Git, Linux).\r\n Cloud computing experience (GCP preferable).\r\n Statistical foundations; Mathematical foundations; Data science and analytics frameworks; Programming (Python, R, Git, Linux); Cloud computing (GCP preferable); Big Data (preferably Hadoop, PySpark)\r\n Problem Solving; Coding capability (specifically Python, R, Git, Linux); Cloud computing (GCP preferable); Machine learning; Research &\r\n development ability; Communication (written and verbal); Stakeholder management\r\n\r\n\r\n\r\nResponsibilities\r\n Engage with stakeholders to support and in some cases to lead data science project delivery solving business problems or developing solutions\r\n Using mathematical, statistical and machine learning techniques to solve problems\r\n Programming solutions using data science programming languages (Python, R etc.)\r\n Executing end to end exploratory data analysis and product development processes\r\n Implementing visualization (Tableau, PowerBI), advanced analytics and data science solutions for customers\r\n Participate in the development of junior data scientists\r\n Strong support to the lead and senior data scientists\r\n Contribute to our agile way of work and our culture of innovation\r\n Input on most appropriate data science tools and/or approaches for specific projects\r\n Contribute to our ML/DL codebase through reusable modules\r\n Developing & peer reviewing code\r\n Input into best practice standards\r\n\r\n\r\n\r\nKindly note, should you not hear from us within one week, please consider your application unsuccessful."},{"JobTitle":" Data Scientist, Johannesburg North, R600k","Url":"https://www.indeed.co.za/pagead/clk?mo=r&ad=-6NYlbfkN0AMOOo83f3x9FLd22RLK3YfFusStXJLn5R4tAT9NKF0tCpHzgZ9ffqffL_dRgSAAfwMQlwp5sa0OEtPEqXmSknLc0YMCILjY7S8tiMhVxsv4Ibm9quP1tx3gK6sYFvIIIA8qtsjED3QeP7Fl3ZrXZocA87bp5j4TnqaR5xQQiJFan-NghEcojSF0jIVnyCYyU3QYTtOEsa7qdRyoS5wsxoI_q_fdSFaPa73SyvFMMC_ATbevMOfEVikIVNzlWBwfwbdytb8DrBQxatZfHe11RV_wm1LnYi8G6MqZQaldXF6JD7OXIvEbdEv2vQ8c3clgZXcfVV8R0yPRdmjHIeQIxiDHWzqoilyt9osggnPFJzy9MA7B0QxmobVm4XWk4uqIc3AJ5ubLJD4WVfm-kcBI2IBUaCaw9syuR8jvk_bNmb1qtSQ0pclhGmflKEW_yJBN_urV6KE1UANdECe5NnFCyRxUGAnuoRmkuDj5wyFprgcDNrFT7MZYjn07lc2zTZuTsV1mKnvfTO_HOrICydDUspXXqVaO-0UQEjV1UPSBXAKi1t3ZOP5NFBlix6mF_THX_fMYM6N7sXk8mcgrmmKRj7DeCJ2xa1cHfI=&p=14&fvj=0&vjs=3","Source":" E-Merge","Salary":" R600 000 a year","Age":null,"Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\nR600 000 a year\r\n\r\n\r\nA very nice tech shop is looking for driven, intelligent Data Scientists to join their business. They offer no dress-codes, flexible working hours, the latest workstation of your choice, and occasional remote work.\r\n\r\n Requirements:\r\n Top achievers when it comes to their degree results\r\n Honours degrees and higher are preferred in Computer Science / Physical Sciences / Statistics / Mathematics / Engineering / Big Data\r\n 2+ years’ experience in the capacity of Data Scientist\r\n Experience in R, Python, Hadoop, machine learning algorithms, Spark (Pyspark) and more.\r\n\r\nReference Number for this position is MH45892. This is permanent role based in Illovo offering up to R600k per annum based on experience, skillset and current level. Contact Michelle on -Please upload your CV here-, at www.e-merger.co.za.\r\n\r\nAre you ready for a change of scenery? e-Merge IT recruitment is a niche recruitment agency. We offer our candidates options so that we can successfully place the right people with the right companies, in the right roles. Check out the e-Merge IT website for more great positions.\r\n\r\nDo you have a friend who is a developer or technology specialist? We pay cash for successful referrals!"},{"JobTitle":" Database Administrator - AWS/ Azure","Url":"https://www.indeed.co.za/pagead/clk?mo=r&ad=-6NYlbfkN0AMOOo83f3x9FLd22RLK3YfFusStXJLn5R4tAT9NKF0tAvdVEybpYDI30GAsFF9juak1s8CYOn1JDC3CkKQ6iRkDSYPSYKX8Z_3q9xm6EmXHSho3kZ5oQQvAxDJ7VjGusL9dCuPoPkG5JyAouMriJ2tQO5aySVTTEuDIjWAyP08R5KTkt7IoDWi9JnOIIt8R_c-zj7w4FAfAKmHZ_r9MwL9-GZAGRC-cu3zZF25OyMjyQoLVHh5C4H_j1UdvOCCVZ0Gtx4x2u441IAVtl1_lk-yACM5YXfHFT_la63TUyO4-23tFyrm_4vwpKppOgyDiW0bCr4th3cEnegICKSrbBcsziEsS3e320-jefyyFk76CGA84G8uxPxIOhBT3tjqtj2jIGKN7FzQd-bbKKvdw5HF9HiHQw84pFY3ajel8mu5sCBrnCuTPLjUnBLc0M8g5iRJr2EKwvGm8mgDFXQHZrBDLn6RXD8K84VzvGHbdEId0I0vqmmbub1VJCnhEuTYNHh9Lr6gQ00-_yvVyxBndituxkubkTpPamO9XIb3Cl5OKOg4ky-IwS0FOyqw9ZjrkcPJ7-aBpu91eP8Tmf3JZ_OXB2IWA4wPM57m7p3RSOYpYA==&p=0&fvj=0&vjs=3","Source":" Data Centrix","Salary":null,"Age":null,"Location":"Cape Town, Western Cape","Description":"\r\n\r\n\r\nCape Town, Western Cape\r\n\r\n\r\nResponsibilities\r\n To research, evaluate and recommend NoSQL products\r\n Evaluate pros and cons of NoSQL products\r\n Produce documentation to be used in solution architecture decision making\r\n Rank ease of setup and management effort required for each product\r\n Rank monitoring and alerting capabilities for each product\r\n Determine best use cases for each product\r\n Conduct system performance testing for each product\r\n Perform daily database operational tasks ensuring databases are backed up and running optimally.\r\n Assist Development Teams in designing, modelling and validating NoSQL solutions for their applications\r\n Liaise closely with development teams gathering their requirements.\r\n Propose appropriate NoSQL database management system\r\n Ensure cloud based solutions are built optimally, keeping maximum cost saving in mind\r\n To ensure information security and regulatory compliance:\r\n Ensuring system security meets regulatory compliance\r\n Manage server security remediation activities which will include conducting vulnerability scans and patching\r\n To carry out database administration tasks ensuring data is available, protected and recoverable\r\n Perform daily health checks for databases and resolve any issues identified\r\n Ensure database backups are scheduled and completing successfully\r\n Verify backups are valid by testing restore process regularly.\r\n Monitor databases so that capacity constraints can be mitigated by timeous provisioning of resources.\r\n Close incidents within SLA\r\n Execute database changes according to change management process\r\n Assist developers with any database issues\r\n\r\n Qualifications and Experience\r\n Grade 12 \r\nIndustry Certification: AWS Associate Architect and Developer certificate (advantageous)\r\n 3+ years Managing all aspects of NoSQL database management systems from installation , configuration , backup management and security\r\n 3+ years Managing all aspects of NoSQL database management systems from installation , configuration , backup management and security\r\n 3+ years Experience working with services in AWS\r\n 3+ years Exposure to one or more Apache Software Foundation Big Data & Database projects such as Cassandra, Hadoop, Hbase, MongoDB\r\n 3+ years Proficient with some of the common developer tool sets such as Java, XML, JSON, REST, Shell, Perl and Python\r\n 4+ years General understanding of database management concepts\r\n 3+ years Basic familiarity with Linux operating system\r\n 3+ years Some experience engineering and/or administering NoSQL infrastructure\r\n 3+ years Proficient with one or more Apache Software Foundation Big Data & Database projects such as Cassandra, Hadoop, Hbase, MongoDB\r\n 2+ years Knowledgeable in designing, developing & documenting use cases.\r\n 3+ years Proficient with some of the common developer tool sets such as Java, XML, JSON, REST, Shell, Perl"},{"JobTitle":" Senior Java Developer","Url":"https://www.indeed.co.za/pagead/clk?mo=r&ad=-6NYlbfkN0AMOOo83f3x9FLd22RLK3YfFusStXJLn5R4tAT9NKF0tAvdVEybpYDI30GAsFF9jua4rEsjgAu-knqWIxLrTC8QK4xzpuEnPMKVbW9j3lBIzM0iDueSdLdzCHgjanMKhfgsnVAnQsqtRZhiqypQ0wxkgjxuWkTZVfQ-ELV65qUwYTa3avnrSpdDGlygqWZaLIzEvwoeVkgx38SaFGU2HPXug-zup1DBoPjSTihD4CSDG381_TVAYnaPCtA25smOGIKCZIvSPhf_cjhcCdg4lzqnytdwHqykAXXMIl0HVzOE58uS0veP6OwAcXokcJGTk_cZXzJ4SrPD_-E8OX5MAKMLL8NDIOpR97h2S69OlzpbKV5qXuoMfupk-i7MUyNGaVgZUUcI4ynypNGf-c_qQZIC6cQledO_nViylXaw7kiNP77rEhoELe2uRStACepxlTZ2Dpru4MKTQeqI38hRsp1nd5ac1B3B8RpgQoQq9JT_HABqa2ER9oA-WM5Sat82y_qrVyatDOp9cmeo75lzqMMMROoCbEjMJ6yHFQOhZJeqO1rv1FBLTrU29J7IELYKZLkc0r6m_vbYpDHrnk9WggzU&p=1&fvj=0&vjs=3","Source":" Communicate Recruitment: IT 2","Salary":" R800 000 a year","Age":null,"Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\nR800 000 a year\r\n\r\n\r\nEducation: \r\nBachelor degree in related field or comparable experience in the web development required. Substantial experience working with similar technologies and environment\r\n Minimum 6 years’ experience using Java\r\n Must have a good grasp of design principles (Solid, GOF Patterns and etc)\r\n Familiarity with various design and architectural patterns\r\n Familiarity with standard SDLC process and Agile/Scrum Methodology\r\n Implementing automated testing platforms and unit tests\r\n Familiarity with versioning control tools {{such as Git, TFS and etc}}\r\n Must be able to design, develop, troubleshoot, and debug systems and their various integration points\r\n Good knowledge in writing SQL scripts, stored procedures and database design\r\n Familiarity with Microsoft SQL Server 2008/12/14\r\n Knowledge of TeamCity a plus\r\n Knowledge of SSIS development a plus\r\n Exposure to Non-Microsoft DB technologies a plus (MySQL, MongoDB, Hadoop etc.)\r\n\r\n\r\n\r\n Skills:\r\n Display an attitude of innovation\r\n Dedicated and committed to achieving results\r\n Self-motivated\r\n Able to adapt to change quickly\r\n Convey a professional image\r\n Be able to work under pressure\r\n Strong analytical and problem solving\r\n Experience working in a team-oriented, collaborative environment\r\n Excellent written and oral communication skills\r\n Presenting & Communicating Information (Familiar with)\r\n\r\n\r\n\r\n Description:\r\n To translate, design, build bespoke applications given a set of requirements\r\n To assist business during QA testing, resolving bugs and issues as their being discovered Frequent communication with colleagues and management\r\n Collaborate with IT/Business for any technical assistance required Integrating data from various back-end services and databases\r\n Perform website analysis and diagnostics according to planned schedules or after any website or product revisions\r\n Diagnose production issues and provide assistance to production support staff (2nd level support) Stay plugged into emerging technologies/industry trends and apply them into operations and activities\r\n Ensure work done adheres to quality guidelines and standards for all activities (e.g. naming conventions, code comments) as agreed in the team Be responsible for maintaining, expanding, and scaling all Universal sites\r\n\r\n\r\n\r\n Please visit our website www.communicate.co.za to submit your CV directly or to view other I.T related jobs. If you have not had any response in two weeks, please consider your application unsuccessful. Your profile will be kept on our database for any other suitable positions.\r\n\r\n\r\n\r\nWe also invite you to contact us to discuss other exciting career opportunities in our niche area! For more information, please call Thato Kekana on - or email on -Please upload your CV here->"},{"JobTitle":" C# Developer","Url":"https://www.indeed.co.za/pagead/clk?mo=r&ad=-6NYlbfkN0AMOOo83f3x9FLd22RLK3YfFusStXJLn5R4tAT9NKF0tCpHzgZ9ffqffL_dRgSAAfxzQ8WE4uhd3jRNFQgKO_6Z4hJ5NyQRxf-6e_1cLD6BA1ZPwYHRR4OKI3Xr3Ynf9X8UdvWJCzaW5AVNdyarwiDKmfzmW22H7GTPIuggHMNZyhF9J_6AHpZXS3j9SYWKyv0aZN70VX-NZt53U-SFyiA3M62tbYqZAUTDYd8X4kcq-ASjNnxivR8aiMTgZBtfAfUyhn7Wf9i_FtHpCztXjaWrzFUHZK35HDzvAjvXI6DyMeW6w66lMF12zDhmnO-iid-Bp-GFmnjPtq3o16PRNyQ9TPkLpXny8Phjc3tS-JxgRNtpZcGEDHEnnVxfFjBvhPyB0CUdCeAFkaPfZ01m-ZfL2avpLyMnBB-8fliuLRoT6SWyJPhS8zOpiLjwfOjxRueGnExWdcq0QIeRvOeTu0hNZf1tVE-FXHIs3ExXSrSih8zBp9OrNG5MZw7dDENSigqQo8lKkwUbOAhTkGeVRmptlG9u2yR5QQpk37eiiL-q83sKmTCowp5WMOQhymy_EnQ6pnaFVQBVhw==&p=2&fvj=0&vjs=3","Source":" Communicate Recruitment: IT 2","Salary":" R450 000 a year","Age":null,"Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\nR450 000 a year\r\n\r\n\r\nEducation: \r\nBachelor degree in related field or comparable experience in the web development required. Substantial experience working with similar technologies and environment\r\n Minimum 3 years experience using .NET technology stack such as (Web API, MVC, .NET4.5, .NET Core, WCF, Unity ,Angular)\r\n Must have a good grasp of design principles (Solid, GOF Patterns and etc)\r\n Familiarity with various design and architectural patterns\r\n Familiarity with standard SDLC process and Agile/Scrum Methodology\r\n Implementing automated testing platforms and unit tests\r\n Familiarity with versioning control tools {{such as Git, TFS and etc}}\r\n Must be able to design, develop, troubleshoot, and debug systems and their various integration points\r\n Good knowledge in writing SQL scripts, stored procedures and database design\r\n Familiarity with Microsoft SQL Server 2008/12/14\r\n Knowledge of TeamCity a plus\r\n Knowledge of SSIS development a plus\r\n Exposure to Non-Microsoft DB technologies a plus (MySQL, MongoDB, Hadoop etc.)\r\n\r\n\r\n\r\n Skills:\r\n Display an attitude of innovation\r\n Dedicated and committed to achieving results\r\n Self-motivated\r\n Able to adapt to change quickly\r\n Convey a professional image\r\n Be able to work under pressure\r\n Strong analytical and problem solving\r\n Experience working in a team-oriented, collaborative environment\r\n Excellent written and oral communication skills\r\n Presenting & Communicating Information (Familiar with)\r\n\r\n\r\n\r\n Description:\r\n To translate, design, build bespoke applications given a set of requirements\r\n To assist business during QA testing, resolving bugs and issues as their being discovered Frequent communication with colleagues and management\r\n Collaborate with IT/Business for any technical assistance required Integrating data from various back-end services and databases\r\n Perform website analysis and diagnostics according to planned schedules or after any website or product revisions\r\n Diagnose production issues and provide assistance to production support staff (2nd level support) Stay plugged into emerging technologies/industry trends and apply them into operations and activities\r\n Ensure work done adheres to quality guidelines and standards for all activities (e.g. naming conventions, code comments) as agreed in the team Be responsible for maintaining, expanding, and scaling all Universal sites\r\n\r\n\r\n\r\n Please visit our website www.communicate.co.za to submit your CV directly or to view other I.T related jobs. If you have not had any response in two weeks, please consider your application unsuccessful. Your profile will be kept on our database for any other suitable positions.\r\n\r\n\r\n\r\nWe also invite you to contact us to discuss other exciting career opportunities in our niche area! For more information, please call Thato Kekana on - or email on -Please upload your CV here->"},{"JobTitle":" Big Data Consultant, Professional Services","Url":"https://www.indeed.co.za/rc/clk?jk=45df79475347e641&fccid=fe2d21eef233e94a&vjs=3","Source":" Amazon Web Services SA Pvt Ltd","Salary":null,"Age":"30+ days ago","Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\nBA/BS degree or equivalent experience; Computer Science or Math background preferred.\r\n7+ years’ experience of Big Data solutions implementation in a highly technical and analytical role.\r\nCustomer facing skills to represent AWS within the customer’s environment and drive discussions with senior personnel regarding trade-offs, best practices, project management and risk mitigation. Ability to interact with Executive level stakeholders, as well as the people within their organizations.\r\nProven track record of thinking strategically about business, product, and technical challenges whilst designing and delivering innovating solutions in an enterprise environment.\r\nExperience with massively-parallel-processing (MPP) models, real-time processing and analytics, data ingestion (batched and streamed) and data storage solutions.\r\nFamiliarity with Hadoop ecosystem and associated technologies and processes.\r\nExperience developing software code in one or more programming languages (Java, JavaScript, Python, etc).\r\nAbility to travel to client locations when needed.\r\n\r\n\r\nAre you a Big Data specialist? Do you have Data Warehousing and/or Hadoop experience? Do you like to solve the most complex and high scale (billion + records) data challenges in the world today? Would you like a career that gives you opportunities to help customers and partners use cloud computing to do big new things faster and at lower cost? Do you want to be part of history and transform businesses through cloud computing adoption? Do you like to work on-site in a variety of business environments, leading teams through high impact projects that use the newest data analytic technologies? Would you like a career path that enables you to progress with the rapid adoption of cloud computing?\r\n\r\n At Amazon Web Services (AWS), we’re hiring highly technical cloud computing consultants to collaborate with our customers and partners derive business value from Big Data in the cloud. Our consultants will develop and deliver proof-of-concept projects, technical workshops, and support implementation projects. These professional services engagements will focus on customer solutions such as batch and real-time data capture and analysis, driving data driven decisions and delivery desired customer outcomes.\r\n Responsibilities include:\r\nExpertise - Collaborate with AWS field sales, pre-sales, training and support teams to help partners and customers learn and use AWS services such as Amazon Elastic Compute Cloud (EC2), Amazon Data Pipeline, AWS Glue, Amazon S3, Amazon DynamoDB, Amazon Relational Database Service (RDS), Amazon Elastic Map Reduce (EMR), Amazon Kinesis, and Amazon Redshift.\r\nSolutions - Deliver on-site technical engagements with partners and customers. This includes participating in pre-sales on-site visits, understanding customer requirements, creating consulting proposals and creating packaged Big Data service offerings.\r\nDelivery - Engagements include short on-site projects proving the use of AWS services to support new distributed computing solutions that often span private cloud and public cloud services. Engagements will include migration of existing applications and development of new applications using AWS cloud services.\r\nInsights - Work with AWS engineering and support teams to convey partner and customer needs and feedback as input to technology roadmaps. Share real world implementation challenges and recommend new capabilities that would simplify adoption and drive greater value from use of AWS cloud services.\r\nPush the envelope – Cloud computing is reducing the historical “IT constraint” on businesses. Imagine bold possibilities and work with our clients and partners to find innovative new ways to satisfy business needs through Big Data / Business Intelligence cloud computing.\r\nAmazon aims to be the most customer centric company on earth. Amazon Web Services (AWS) provides a highly reliable, scalable, low-cost infrastructure platform in the cloud that powers critical applications for hundreds of thousands of businesses in 190 countries around the world.\r\n\r\nMaster in Computer Science\r\nHands on experience leading large-scale global data warehousing and analytics projects.\r\nDeep understanding of database and analytical technologies in the industry including MPP and NoSQL databases, Data Warehouse design, BI reporting and Dashboard development.\r\nDemonstrated industry leadership in the fields of database, data warehousing or data sciences.\r\nImplementation and tuning experience of Big Data solutions specifically using Amazon Web Services.\r\nTrack record of implementing AWS services in a variety of distributed computing, enterprise environments.\r\n\r\n aws-proserv-ea\r\n ** AWS_PROFESSIONAL_SERVICES **\r\n\r\n Amazon aims to be the most customer centric company on earth. Amazon Web Services (AWS) provides a highly reliable, scalable, low-cost infrastructure platform in the cloud that powers critical applications for hundreds of thousands of businesses in 190 countries around the world."},{"JobTitle":" Director, Big Data Engineer, Sub-Saharan Africa Data Science...","Url":"https://www.indeed.co.za/rc/clk?jk=cbe24468bc5354dc&fccid=a3f737e511d9fc8c&vjs=3","Source":" Visa","Salary":null,"Age":"30+ days ago","Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\nJob Description\r\n\r\n\r\nPosition Summary\r\n\r\nThe Director of Data Science is a lead Data Engineer role in the Sub-Saharan Africa (SSA) team. We are looking for an expert with deep expertise in data warehousing and can build large-scale data processing systems by using the latest database technologies. This is a Pan-regional position and plays a critical role in enabling the data platforms through which Data Scientists, Analysts, and BI Users drive solutions for our Visa clients. Also, the role provides a bridge between our local end-users and our Visa Technology colleagues in San Francisco, influencing the development of our global data platforms whilst provisioning local tools and technologies as required. The Data Engineer takes responsibility for building and running data pipelines, designing our local data warehouse and data frameworks, and catering for different data presentation techniques.\r\n\r\n\r\n Principal Responsibilities\r\nDesign local modifications to our global data architecture, including new tools and technologies where necessary to meet regional use-cases\r\n Provide direction to the development of bespoke, client-specific data sandboxes\r\n Create and maintain optimal data pipeline architecture(s), based on our Global Technology Stack\r\n Identify, design, and implement internal process improvements to provide greater scalability to our existing client solutions\r\n Develop custom-built packages and “glue code” to support the needs of Data Scientists across the region\r\n Work with broader business stakeholders to assist clients and consultants with their data and infrastructure needs\r\n\r\nDesign architecture\r\n Work with Visa’s Global Technology team to leverage our existing architecture to best effect, whilst identifying new and complementary tools and technology that will better enable our local solutions; serve as key contact and subject matter expert in working with the Visa Technology functions around the world (both global and regional)\r\n\r\n\r\n\r\nDesign sandbox architecture\r\n\r\nProvide SME support to the design and build of client-specific data sandboxes that may leverage the advantages of cloud technologies whilst ensuring strong security and privacy controls\r\n\r\nBuild data pipelines\r\n Build and operate stable, scalable data pipelines that cleanse, structure and integrate data sets into accessible formats for Data Scientists and other end-users, ensuring that testing and monitoring functions are performed appropriately\r\n\r\nSupporting external clients’ data architecture\r\n Provide Data Engineering expertise support to Visa’s select top-level clients, advising on how to implement, acquire, and improve their existing and planned data solutions. Such solutions can involve complex data integration from various sources (from an internal data warehouse, applicable VisaNet transaction data or third-party data) within the constraints of the client’s legal and regulatory limitations.\r\n\r\n\r\n\r\nImplement for scale\r\n Co-create and contribute to the design and deployment of scalable, high volume and real-time data solutions (dashboards, data feeds, and algorithms) running in production systems to ensure optimal functioning and sustainability of solutions built\r\n\r\n\r\n\r\nSupport Data Scientists\r\n Provide advisory and hands-on support to Data Scientists by providing quality assurance to teams writing poor-quality data queries on our queue, and developing custom-built packages and “glue code” that take algorithms into production\r\n\r\n\r\n\r\nServe as subject matter expert\r\n Provide support and advisory assistance to business stakeholders (client relationship managers, consultants, and other internal stakeholders) in framing potential use-cases, client engagements, and internal initiatives\r\n\r\n\r\nQualifications\r\n\r\n\r\nProfessional Experience\r\n\r\n\r\n 5 - 7 years' application development and support experience.\r\n Deep knowledge of distributed data architecture, commonly-used BI tools, and approaches/packages deployed for machine learning build\r\n Experience creating production software/systems and a proven track record of identifying and resolving performance bottlenecks for production systems.\r\n Experience in machine learning algorithm design, feature engineering, validation, prediction, recommendation, and measurement.\r\n Experience with complex, high volume, multi-dimensional data, as well as machine learning models based on unstructured, structured, and streaming datasets.\r\n Good understanding of the Payments and Banking Industry including aspects such as consumer credit, consumer debit, prepaid, small business, commercial, co-branded and merchant\r\n Experience planning, organising, and managing multiple large projects with diverse cross-functional teams\r\n Demonstrated ability to incorporate new techniques to solve business problems\r\n Demonstrated resource planning and delivery skills\r\n\r\n\r\n\r\n Technical Expertise\r\n\r\n\r\n Post Graduate Degree in Information Technology\r\n Qualification in Computer Science or Engineering ideal.\r\n Certification in Hadoop (Cloudera or Hortonworks) and Apache Spark.\r\n Working knowledge of Hadoop ecosystem and associated technologies, e.g., Apache Spark, MLlib, GraphX, iPython, sci-kit, and Pandas\r\n Advanced experience in writing and optimizing efficient SQL queries and Python scripts; Scala and C++ experience is ideal\r\n Deliver results within committed scope, timeline and budget\r\n Very strong people/project management skills and experience\r\n Ability to travel within CEMEA on short notice\r\n\r\n\r\n\r\n Business Experience\r\n Ability to travel within CEMEA on short notice\r\n Results-oriented with strong problem solving skills and demonstrated intellectual and analytical rigor\r\n Good business acumen with a track record in solving business problems through data-driven quantitative methodologies. Experience in payment, retail banking, or retail merchant industries is preferred\r\n Team oriented, collaborative, diplomatic, and flexible style\r\n Very detailed oriented, is expected to ensure highest level of quality/rigor in reports and data analysis\r\n Proven skills in translating analytics output to actionable recommendations and delivery\r\n Experience in presenting ideas and analysis to stakeholders whilst tailoring data-driven results to various audience levels\r\n Exhibits intellectual curiosity and a desire for continuous learning\r\n\r\n\r\n\r\n Leadership Competencies\r\n Exhibits intellectual curiosity and a desire for continuous learning\r\n Demonstrates integrity, maturity and a constructive approach to business challenges\r\n Role model for the organization and implementing core Visa Values\r\n Respect for the Individuals at all levels in the workplace\r\n Strive for Excellence and extraordinary results\r\n Use sound insights and judgments to make informed decisions in line with business strategy and needs\r\n Leadership skills include an ability to allocate tasks and resources across multiple lines of businesses and geographies. Leadership extends to ability to influence senior management within and outside Analytics groups\r\n Ability to successfully persuade/influence internal stakeholders for building best-in-class solutions\r\n Change management leadership\r\n\r\n Additional Information\r\n\r\n null"},{"JobTitle":" Big data and analytics developer","Url":"https://www.indeed.co.za/rc/clk?jk=dfd3570023b7229e&fccid=e59782cd0b7da8a0&vjs=3","Source":" Insource IT Edge","Salary":" R400 000 - R550 000 a year","Age":"10 days ago","Location":"Centurion, Gauteng","Description":"\r\n\r\n\r\nCenturion, Gauteng\r\n\r\n\r\nR400 000 - R550 000 a year\r\nJob & Company Description:\r\n Insurance giant has a superb opportunity for a Big Data Analytics Developer, offering you the chance to work with a well-respected development team and provides the prospect of further internal progression to either become an expert in big data or to become a data scientist. \r\n\r\nEducation:\r\n Relevant degree \r\n\r\nJob Experience & Skills Required:\r\n Worked on different database platforms like MS SQL, DB/2, Oracle and Non-SQL like MangoDB \r\nExperience in Python/Scala/R or Java languages \r\nMust have solid experience with Hadoop, Spark and other Data/Analytics tools \r\nAdvantage to have experience with Machine Learning and Data Mining \r\nExperience with visualization tools such as PowerBI and Tableau. \r\nExamine and evaluate Operational and Strategic reporting requirements for various stakeholders across the business unit. \r\nThe analysis of reporting requirements as defined by business, and documenting the desired solution and/or recommendations \r\nTranslation of reporting requirements between business and the technology and tools necessary to deliver on those requirements. \r\nThe development of reports, and underlying scripts and procedures, according to business requirements. \r\nEnsure a high level of quality is achieved by performing constant testing and reviews of reports implemented. This includes doing performance optimisation of existing SQL code in order to make it execute faster whilst proving the integrity of the report is still intact. \r\nInteract with existing reporting resources and ensure a single reporting strategy is maintained. \r\nEnsure signoff on all reporting deliverables according to business specifications. \r\nWork in partnership with the business analysts, product owners, and other IT and business personnel to maximize project delivery success. \r\nContinually improve the reporting writing process by investigating and implementing new and innovative reporting writing methods \r\n\r\n If you have not had any response in two weeks, please consider the vacancy application unsuccessful. Your profile will be kept on our database for any other suitable roles / positions. \r\n\r\nFor more information contact:\r\n Anietha Little \r\n\r\n Senior Recruitment IT Consultant \r\n\r\n 012 348 7559"},{"JobTitle":" NoSQL Database Administrator II","Url":"https://www.indeed.co.za/rc/clk?jk=948122757574f2a9&fccid=26d01f64c124ba71&vjs=3","Source":" Datafin IT Recruitment","Salary":null,"Age":"13 days ago","Location":"Cape Town, Western Cape","Description":"\r\n\r\n\r\nCape Town, Western Cape\r\n\r\n\r\nPermanent\r\n\r\n\r\n\r\n–\r\n4+ Years –\r\nGeneral understanding of database management concepts.\r\n 3+ Years –\r\nManaging all aspects of NoSQL database management systems from installation, configuration, backup management and security.\r\n Working with services in AWS.\r\n Exposure to one or more Apache Software Foundation Big Data & Database projects such as Cassandra, Hadoop, Hbase, MongoDB.\r\n Proficient with some of the common developer tool sets such as Java, XML, JSON, REST, Shell, Perl and Python.\r\n Installing, configuring, administering, using and benchmarking NoSQL solutions.\r\n Basic familiarity with Linux operating system.\r\n 2+ Years –\r\nKnowledgeable in designing, developing & documenting use cases.\r\n\r\nWhile we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.\r\n\r\nCOMMENTS:\r\n When applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence. Please e-mail a word copy of your CV to taryn@datafin.com and mention the reference numbers of the jobs."},{"JobTitle":" Data Engineer","Url":"https://www.indeed.co.za/rc/clk?jk=fb1110db122115d3&fccid=77748257c144323d&vjs=3","Source":" e-Merge IT Recruitment","Salary":" R900 000 a year","Age":"10 days ago","Location":"Johannesburg North, Gauteng","Description":"\r\n\r\n\r\nJohannesburg North, Gauteng\r\n\r\n\r\nR900 000 a year\r\n\r\n\r\nDescription\r\n\r\n\r\nA data centered business is on the lookout for a Data Engineer to join their team. This is an opportunity to work on cutting edge of tech and cloud computing. They are a fun environment with a quality team that is working with some of the biggest and best datasets in the country.\r\n\r\nYou will be building world-class, scalable data pipelines and warehouses to add real value to customers and drive new product development, both internally and externally.\r\n\r\n Requirements:\r\n Completed BSc (Computer Science) degree or similar (Software Engineering, Data Science etc. with experience in software)\r\n 2-5 years’ experience in Data Engineering (Hadoop and Spark)\r\n Data Processing products - Big Query, Redshift, Spectrum, S3, Athena, Kafka, Spark, Storm, Flink, Beam, Presto, Hive\r\n ETL processes and transformations\r\n Cloud experience ideally with Google Cloud Platform\r\n DevOps Stack development experience\r\n Apache-Airflow or other data pipeline tools\r\n Exposure to Scala or Java in context of data processing\r\n Experience and proficiency with Python\r\n Experience in the design and implementation of data flows\r\n Advanced SQL/PostgreSQL/Redshift knowledge\r\n\r\n Responsibilities:\r\n Support sophisticated predictive data products by maintaining data science production environments (cloud-based, python), ensuring that the outputs from Data Science models are available and integrated into the system and integrate, coordinate and maintain data flows between various sources of data\r\n Manage and maintain cloud service integrations that perform key data functions by working towards replacing third-party elements of the data pipeline by using open-source tools\r\n Make decisions around the infrastructure, layout and processes of the data warehouse, including:\r\n working with the engineering team on how to best track and record data\r\n following up on data inconsistencies to ensure that it is corrected\r\n Transforming, standardizing and collecting data from various sources\r\n\r\n Reference Number for this position is LV46312 which is a permanent position based in Johannesburg North offering a salary of up to R900k per annum highly negotiable on experience and ability. Contact Liza on lizavdb@e-merge.co.za or call her on 011 463 3633 to discuss this and other opportunities.\r\n\r\nAre you ready for a change of scenery? The e-Merge IT recruitment is a specialist niche recruitment agency. We offer our candidates options so that we can successfully place the right developers with the right companies in the right roles.\r\n\r\nDo you have a friend who is a developer or technology specialist? We pay cash for successful referrals!"},{"JobTitle":"Hadoop developer","Url":"https://www.indeed.co.za/company/Prorek/jobs/Hadoop-Developer-002d963619151341?fccid=6c17122040c57e81&vjs=3","Source":" Prorek Solutions","Salary":null,"Age":"12 days ago","Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\nContract\r\n\r\nCandidate should have hands on experience in Hadoop along with ecosystem (including HDFS, Spark, Sqoop, Flume, Hive, Impala, PIG, MapReduce/YARN)\r\n\r\n- Experience working on Unix / Linux environment, as well as Windows environment\r\nMinimum 3 - 5 years required.\r\nPlease send resume to hr@prorek dot net\r\n\r\nJob Type: Contract\r\n\r\nExperience:\r\nHadoop: 3 years (Preferred)"},{"JobTitle":" Data Engineer","Url":"https://www.indeed.co.za/company/vito-solutions/jobs/Data-Engineer-f53aef7dbce5cdfb?fccid=01e7a61c66d0697f&vjs=3","Source":" VITO Solutions","Salary":null,"Age":"3 days ago","Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\nJob Purpose\r\n\r\nResponsible for overseeing junior data engineering activities and aiding in building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.\r\n\r\nResponsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.\r\n\r\nKey Responsibilities/Accountability\r\n\r\nProvide a service to them\r\n\r\nDescription or examples: Provide Data engineering guidance, information services and ensure an effective data engineering capability, works closely with data analysts and data scientists to ensure and effective data team. Collaborate with technology and project teams.\r\n\r\nExternal contact: Vendors\r\n\r\nDescription or examples: Manage SLA’s and technical service delivery of vendors in the development, implementation and customer service requirements for all Data Engineering requirements.\r\n\r\nNature of relationship: Manage the relationship\r\n\r\nPreferred Qualification And Experience\r\n\r\nPost Graduate Degree\r\n\r\nHonours Degree\r\n\r\nExperience\r\n\r\nYears: 3-4 years\r\n\r\nExperience Description: Experience with big data tools: Hadoop, Spark, Kafka, etc. Experience with relational SQL and NoSQL databases, including Postgres and Cassandra. Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc. Experience with AWS cloud services: EC2, EMR, RDS, Redshift. Experience with stream-processing systems: Storm, Spark-Streaming, etc. Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.\r\n\r\nYears: 3-4 years\r\n\r\nExperience Description: Working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Experience building and optimizing ‘big data’ data pipelines, architectures and data sets. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.\r\n\r\nYears: 3-4 years\r\n\r\nExperience Description: Strong analytic skills related to working with unstructured datasets. Build processes supporting data transformation, data structures, metadata, dependency and workload management. A successful history of manipulating, processing and extracting value from large disconnected datasets. Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.\r\n\r\n3 years\r\n\r\nKnowledge/Technical Skills/Expertise\r\nIT Architecture- Architectural methodologies used in the design and development of IT systems.\r\nData Integrity- The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.\r\nIT Applications- Knowledge and understanding of IT applications and architecture.\r\nData Analysis- Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.\r\nKnowledge Classification- The ability to apply metadata to information to make it easy for other people to find.\r\nDatabase Administration- Refers to the knowledge and experience required to manage the installation, configuration, upgrade, administration, monitoring and maintenance of physical databases.\r\n\r\nJob Type: Full-time"},{"JobTitle":" BIG DATA DEVELOPER","Url":"https://www.indeed.co.za/rc/clk?jk=18680d22d246ddf2&fccid=36b7d079d13b5af5&vjs=3","Source":" Acuity Consultants","Salary":" R900 000 - R1 000 000 a year","Age":"18 days ago","Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\nPermanent\r\n\r\n\r\nR900 000 - R1 000 000 a year\r\n\r\n\r\n\r\nThis is an excellent opportunity for a BIG DATA DEVELOPER to join an international SOFTWARE COMPANY and create DATA SOLUTIONS for Major Global CAPITAL MARKETS FINANCIAL INSTITUTIONS.\r\n This role is with an established Data Solutions & Software company operating in South Africa, UK, USA, New Zealand, Thailand, & Mauritius.\r\n\r\nBased in JOHANNESBURG this BIG DATA DEVELOPER role offers a salary of R900K – R1M/annum, with benefits on top.\r\n\r\nTHE COMPANY:\r\n Over their 15 year history this DATA SOLUTIONS SOFTWARE COMPANY has provided CAPITAL MARKETS Financial Institutions with BIG DATA ENGINEERING and CUSTOM DEVELOPMENT aligned to deploying technology and unlocking the potential of data - to gather, process, compare and analyse data from multiple sources, and uncover hidden insights to drive business advantage.\r\n This is a fast-growing international business using technology to solve complex financial data challenges in a simple way. Having grown across 5 continents, this business continues to enjoy success and is a recognised specialist in CAPITAL MARKETS.\r\n\r\nTHE ROLE:\r\n As BIG DATA DEVELOPER, your role will involve building and operating a content management platform for high profile big data projects that revolutionise an area of finance by providing unprecedented market insight in a timely manner.\r\n You'll be working closely within a team of developers distributed in London, South Africa and New Zealand.\r\n The role will involve building and operating an ingestion and analytics platform that collects frequently changing data and exposing the normalised and aggregated data via APIs. This includes data cleansing, aggregation, financial computations.\r\n\r\nTHE TEAM are diverse, smart, agile but laid-back who are passionate about technology, open-minded and open to new ideas. In this business you’ll find serious hardware, and no red tape or unnecessary process. Not only will you get to work with a great team, you’ll also enjoy flexible hours, the flexibility to work from home when needed, private medical and a relaxed dress code.\r\n\r\nREQUIRED SKILLS:\r\n Ability to pick up a new technology quickly and deliver features in a highly agile manner.\r\n Experience writing functional Scala in a production grade system. (Not a Java developer writing OO in Scala).\r\n To have used Apache Spark SQL in a production system using Scala with YARN as the resource manager.\r\n A clear and practical understanding of how Hive works, which includes running Hive on Tez.\r\n Practical experience using Debian flavoured Linux distributions.\r\n Familiarity with event driven development and architecture.\r\n Used Docker containers to deploy your systems.\r\n Ability to navigate the administration of an HDP cluster on AWS.\r\n Able to index millions of documents from Hadoop into Elasticsearch.\r\n Work with various messaging systems, such as Kafka and RabbitMQ.\r\n Able to aggregate data using Apache Kylin Cube.\r\n Can pick up Python if you have not used it previously.\r\n Operate and deploy to a Kubernetes cluster on AWS.\r\n Understand basic concepts about mortgage backed securities.\r\n\r\nIf you qualify for this role, please email your CV directly to:\r\n Gary Silbermann\r\n gary@acuityconsultants.co.za\r\n 021 801 5001\r\n\r\nIf you have not had a response to your application within 14 days please consider your application to be unsuccessful."},{"JobTitle":" NoSQL Database Administrator","Url":"https://www.indeed.co.za/company/Recru--IT/jobs/Nosql-Database-Administrator-7a50e8e07ac04416?fccid=7ce178ce4d9efe7d&vjs=3","Source":" Recru-IT","Salary":null,"Age":"12 days ago","Location":"Brackenfell, Western Cape","Description":"\r\n\r\n\r\nBrackenfell, Western Cape\r\n\r\nPosition Purpose: \r\n\r\nThis position involves researching, evaluating and recommending NoSQL database management products available in AWS, Azure and Google cloud platforms.\r\n\r\nThe person will also have to do daily operational support of these databases as well as engage with developers to gain an understanding of their requirements and propose appropriate database management technologies.\r\n\r\nQualifications: \r\n\r\nGrade 12\r\n\r\nIndustry Certification: AWS Associate Architect and Developer certificate (Advantageous)\r\n3+ years Managing all aspects of NoSQL database management systems from installation , configuration , backup management and security\r\n3+ years Experience working with services in AWS\r\n3+ years Exposure to one or more Apache Software Foundation Big Data & Database projects such as Cassandra, Hadoop, Hbase, MongoDB\r\n3+ years Proficient with some of the common developer tool sets such as Java, XML, JSON, REST, Shell, Perl and Python.\r\n\r\nKnowledge: \r\n4+ years General understanding of database management concepts\r\n\r\nSkills: \r\n3+ years Proficient with installing, configuring, administering, using and benchmarking NoSQL solutions.\r\n3+ years Basic familiarity with Linux operating system\r\n3+ years Some experience engineering and/or administering NoSQL infrastructure\r\n3+ years Proficient with one or more Apache Software Foundation Big Data & Database projects such as Cassandra, Hadoop, Hbase, MongoDB\r\n2+ years Knowledgeable in designing, developing & documenting use cases.\r\n3+ years Proficient with some of the common developer tool sets such as Java, XML, JSON, REST, Shell, Perl and etc.\r\n\r\nJob objectives: \r\n\r\nTo research, evaluate and recommend NoSQL products: \r\nEvaluate pros and cons of NoSQL products\r\nProduce documentation to be used in solution architecture decision making\r\nRank ease of setup and management effort required for each product\r\nRank monitoring and alerting capabilities for each product\r\nDetermine best use cases for each product\r\nConduct system performance testing for each product\r\nPerform daily database operational tasks ensuring databases are backed up and running optimally.\r\n\r\nAssist Development Teams in designing, modelling and validating NoSQL solutions for their applications: \r\nLiaise closely with development teams gathering their requirements.\r\nPropose appropriate NoSQL database management system\r\nEnsure cloud based solutions are built optimally, keeping maximum cost saving in mind\r\n\r\nTo ensure information security and regulatory compliance: \r\nEnsuring system security meets regulatory compliance\r\nManage server security remediation activities which will include conducting vulnerability scans and patching\r\n\r\nTo carry out database administration tasks ensuring data is available, protected and recoverable: \r\nPerform daily health checks for databases and resolve any issues identified\r\nEnsure database backups are scheduled and completing successfully\r\nVerify backups are valid by testing restore process regularly.\r\nMonitor databases so that capacity constraints can be mitigated by timeous provisioning of resources.\r\nClose incidents within SLA\r\nExecute database changes according to change management process\r\nAssist developers with any database issues\r\n\r\nSend a detailed copy of your CV to Bonita (bonita AT recru-it.co.za – replace the AT with @)\r\n\r\nShould you not be contacted within 7 days, please consider your application as unsuccessful.\r\n\r\nJob Type: Full-time"},{"JobTitle":" Big data and analytics developer","Url":"https://www.indeed.co.za/rc/clk?jk=ed55744f7c446100&fccid=50a816ef18fe262a&vjs=3","Source":" Network Recruitment","Salary":" R400 000 - R550 000 a year","Age":"10 days ago","Location":"Centurion, Gauteng","Description":"\r\n\r\n\r\nCenturion, Gauteng\r\n\r\n\r\nR400 000 - R550 000 a year\r\n\r\n\r\n\r\n\r\nJob Description:\r\n\r\n\r\n\r\n\r\nInsurance giant has a superb opportunity for a Big Data Analytics Developer, offering you the chance to work with a well-respected development team and provides the prospect of further internal progression to either become an expert in big data or to become a data scientist.\r\n\r\n\r\n\r\n Education:\r\nRelevant degree\r\n\r\n\r\n\r\n\r\n\r\nJob Experience & Skills Required:\r\nWorked on different database platforms like MS SQL, DB/2, Oracle and Non-SQL like MangoDB\r\nExperience in Python/Scala/R or Java languages\r\nMust have solid experience with Hadoop, Spark and other Data/Analytics tools\r\nAdvantage to have experience with Machine Learning and Data Mining\r\nExperience with visualization tools such as PowerBI and Tableau.\r\nExamine and evaluate Operational and Strategic reporting requirements for various stakeholders across the business unit.\r\nThe analysis of reporting requirements as defined by business, and documenting the desired solution and/or recommendations\r\nTranslation of reporting requirements between business and the technology and tools necessary to deliver on those requirements.\r\nThe development of reports, and underlying scripts and procedures, according to business requirements.\r\nEnsure a high level of quality is achieved by performing constant testing and reviews of reports implemented. This includes doing performance optimisation of existing SQL code in order to make it execute faster whilst proving the integrity of the report is still intact.\r\nInteract with existing reporting resources and ensure a single reporting strategy is maintained.\r\nEnsure signoff on all reporting deliverables according to business specifications.\r\nWork in partnership with the business analysts, product owners, and other IT and business personnel to maximize project delivery success.\r\nContinually improve the reporting writing process by investigating and implementing new and innovative reporting writing methods\r\n\r\n\r\n\r\n\r\nApply now!\r\n\r\n\r\n\r\nFor more IT jobs, please visit www.networkrecruitment.co.za\r\n\r\n\r\n\r\nIf you have not had any response in two weeks, please consider the vacancy application unsuccessful. Your profile will be kept on our database for any other suitable roles / positions.\r\n\r\n\r\n\r\nFor more information contact:\r\n\r\nAnietha Little\r\n\r\nSenior Recruitment IT Consultant\r\n\r\n012 348 7559"},{"JobTitle":" Data Engineer â€† BIG DATA - Johannesburg North â€† Up to R9...","Url":"https://www.indeed.co.za/pagead/clk?mo=r&ad=-6NYlbfkN0AMOOo83f3x9FLd22RLK3YfFusStXJLn5R4tAT9NKF0tAvdVEybpYDI30GAsFF9juayDBn6dJZ1w7d_b9MOcJSkVRRGdkMPQ-sNKOrHOdXrZCKXveOIsZOyWD90376nitjkbe6LT7n1fzscVkLr1uLELMuG0Se7QPrUclFbtjUIn_iVdM1VpmRfy63BE4TTha1UmptDK15E0lY0FT-utGrwcwato06sJRP2TOAEVTq55SPPwIgUOXoJNAWOUGOPvS6RIWZqt57FVasTHt4Wg7soA6MZ8sg43bl8tFlfeMu6XGybGKaD90nuIH6yuMqLBOBkgCwtDqd5SUTwhwcRQu_iUtKPrlRs9AORsbj0xNPnzMbL6RU4MdKqGz93hYZ7Wbu2MR-P2q9Z8jv7ftSeWz1KFh2eWVlOhz_Xu2bhPpnNElHSDib3VUZnF7Gdn83TPeyW_mux9nh0ma6ECSbwRL_W1rK85DHBGMzzkBembp4gCUpeDxjie0plLGLlOd2DookbkNlZVjiojvN82TC7ZNMf9DNsrkCN030HpgeatqWwg-_7CGih5hsBrWs-qE3nkEqUgZjnt435EIgzKUR_-L_-kHZEvYmpFzuxBu2DVUYHnQ==&p=13&fvj=0&vjs=3","Source":" E-Merge","Salary":" R900 000 a year","Age":null,"Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\nR900 000 a year\r\n\r\n\r\nThis is an opportunity to work on cutting edge of tech and cloud computing. They are a fun environment with a quality team that is working with some of the biggest and best datasets in the country.\r\n\r\nYou will be building world-class, scalable data pipelines and warehouses to add real value to customers and drive new product development, both internally and externally.\r\n\r\n Requirements:\r\n Completed BSc (Computer Science) degree or similar (Software Engineering, Data Science etc. with experience in software)\r\n 2-5 years’ experience in Data Engineering (Hadoop and Spark)\r\n Data Processing products - Big Query, Redshift, Spectrum, S3, Athena, Kafka, Spark, Storm, Flink, Beam, Presto, Hive\r\n ETL processes and transformations\r\n Cloud experience ideally with Google Cloud Platform\r\n DevOps Stack development experience\r\n Apache-Airflow or other data pipeline tools\r\n Exposure to Scala or Java in context of data processing\r\n Experience and proficiency with Python\r\n Experience in the design and implementation of data flows\r\n Advanced SQL/PostgreSQL/Redshift knowledge\r\n\r\n Responsibilities:\r\n Support sophisticated predictive data products by maintaining data science production environments (cloud-based, python), ensuring that the outputs from Data Science models are available and integrated into the system and integrate, coordinate and maintain data flows between various sources of data\r\n Manage and maintain cloud service integrations that perform key data functions by working towards replacing third-party elements of the data pipeline by using open-source tools\r\n Make decisions around the infrastructure, layout and processes of the data warehouse, including:\r\n working with the engineering team on how to best track and record data\r\n following up on data inconsistencies to ensure that it is corrected\r\n Transforming, standardizing and collecting data from various sources\r\n\r\n Reference Number for this position is LV46312 which is a permanent position based in Johannesburg North offering a salary of up to R900k per annum highly negotiable on experience and ability. Contact Liza on <-Please upload your CV here- or call her on<-Please upload your CV here- to discuss this and other opportunities.\r\n\r\nAre you ready for a change of scenery? The e-Merge IT recruitment is a specialist niche recruitment agency. We offer our candidates options so that we can successfully place the right developers with the right companies in the right roles.\r\n\r\nCheck out the e-Merge website <-Please upload your CV here- for more great positions\r\n\r\nDo you have a friend who is a developer or technology specialist? We pay cash for successful referrals!"},{"JobTitle":" Data Scientist","Url":"https://www.indeed.co.za/pagead/clk?mo=r&ad=-6NYlbfkN0AMOOo83f3x9FLd22RLK3YfFusStXJLn5R4tAT9NKF0tAvdVEybpYDI30GAsFF9juak1s8CYOn1JCPX_ro3KqEbOzPyAXMgmRnzm3Vx1TTwQ8BeCfQbmGJM4JdNnzL7SSbjLVpz2szeFsygGJjX2KbR9u3qq0heHpRlbWsx92eagCt2v7FF80x_HWuvGOVUqWNGoy0GmwTVgF4uTpHSvBqefwCTf2AOIEabcUQ6P9sRYBir6UYWaz6UJyiAH0wI3vvBqXp_p55vbiHUsLTUTTrt-oTTBikiNBb6nVbABOPDXYXUPtEk56OSqlwn4CGDQgIj5EMXClSFdFgQO1NIfC_ddYC7SyBeRCCuRQ2DMOARonilPbN3daR7ZtePuX9jFOd_MKEm_LYcuLiBzPckO9Ga-I0w7vBx6QscN35DwX0mIvfEs_Oo8SGV0APNc5Usys148A-hXv4T1G13c5fdMpUgjH3UQNgfXy9f5syRAMY8tuEJiBqUZQZx324IOW1jigekPOiWEqlLd5YKOCxK98jyh9Pw28z5mj0shEN5PKN84ffp4c1cD7IzPr2BJ73yhSL4ji9h0ivI2Q==&p=14&fvj=0&vjs=3","Source":" Set Consulting","Salary":" R700 000 - R800 000 a year","Age":null,"Location":"Sandton, Gauteng","Description":"\r\n\r\n\r\nSandton, Gauteng\r\n\r\n\r\nR700 000 - R800 000 a year\r\n\r\n\r\nFinance Group with extensive opportunities seeks a Data Scientist with exceptional ability to work with, analyse and communicate findings from data\r\n Degree or Diploma in Computer or Data Science, Statstics, or related\r\n 4 years min experience as a Data Scientist\r\n Predictive Modelling\r\n Good understanding of statistics and machine learning with practical experience applying these techniques\r\n Coding exposure - R or Python or similar - preferably more than one\r\n Hadoop a big advantage\r\n Advanced SQL and Excel skills\r\n Ideally experience with BI/DataViz tools (Qlikview, Power BI etc.)"},{"JobTitle":" Big Data Engineer/Architect - Hadoop","Url":"https://www.indeed.co.za/rc/clk?jk=b3019bf9b207599c&fccid=2d1a4a3e36fdc9e5&vjs=3","Source":" SET Consulting","Salary":" R850 000 - R950 000 a year","Age":"12 days ago","Location":"Randburg, Gauteng","Description":"\r\n\r\n\r\nRandburg, Gauteng\r\n\r\n\r\nPermanent\r\n\r\n\r\nR850 000 - R950 000 a year\r\n\r\n\r\n\r\nTop Financial Services group needs a Big Data Architect with experience in Hadoop - exposure to banking a big plus.\r\nDegree or related Tertiary Qualifications\r\n5+ Years min in Big Data ideally in Banking or Financial Services\r\nSolid experience in the management of Hadoop and Hadoop cluster and accompanying services\r\nExp in the integration of data from multiple data sources.\r\nKnowledge of various ETL techniques."},{"JobTitle":" Data Scientist","Url":"https://www.indeed.co.za/company/FletchSys-Technologies/jobs/Data-Scientist-d5af1d22799a5dec?fccid=e3fced02ca80240f&vjs=3","Source":" FletchSys Technologies","Salary":null,"Age":"4 days ago","Location":"Cape Town, Western Cape","Description":"\r\n\r\n\r\nCape Town, Western Cape\r\n\r\nJob Summary\r\nThe position is for Kenya Location - No bar fro Right candidate. Housing , Car and Secured Job from Kenya's top most company .\r\n\r\nWe are looking for a 5 to 7 Years experienced candidate into data science.\r\nResponsibilities and Duties\r\n\r\nQualifications\r\nBSC. or MS. in Computer Science, Statistics, Mathematics or equivalent practical experience\r\n2 – 4 years data science working experience and with a leadership role.\r\nExcellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests\r\n\r\nExperience with common data science toolkits, such as R, Weka, NumPy, MatLab\r\nExperience with data visualization tools, such as D3.js, GGplot\r\nExperience with NoSQL databases, such as MongoDB, Cassandra, HBase\r\nGood applied statistics skills, such as distributions, statistical testing, regression\r\nGood scripting and programming skills\r\nGood understanding of big data technologies like Hadoop\r\nStrong communications and interpersonal skills and quick grasps to understand business problems\r\n\r\nRequired Experience, Skills and Qualifications\r\n\r\nReporting to the Head of Big Data & Business Analytics, the position holder will lead the data science team to create value from Safaricom’s vast amount and variety of data using advance analytical and statistical methods and models to answer complex business questions. This will serve to aid in decision making, unlock new revenue opportunities and areas to create efficiency through deep insights.\r\nThe role requires deployment of Artificial Intelligence driven by Companies data to create Machine learning models and solutions to deliver specific business relevant use cases. Safaricom is investing heavily in big data and this will be a truly exciting role in view of the organizations unique data set and position in this region.\r\n\r\nResponsibilities\r\nData mining using state-of-the-art methods\r\nSelecting features, building and optimizing classifiers using machine learning techniques\r\nProcessing, cleansing, and verifying the integrity of data used for analysis\r\nCollaborate with business units and engineering teams to understand and prioritize company needs and devise possible solutions based on business use cases\r\nCreate various machine learning-based tools or processes within the company, such as recommendation engines or automated lead scoring systems to drive revenue or create cost efficiencies\r\nCreate visualizations using state of the art visualization tools\r\nLead and manage data science team\r\nQualifications\r\nBenefits\r\nBest in Market Salary Package\r\nCar and House in Kenya.\r\n\r\nThis opportunity is for our client in Kenya Location.\r\n\r\nJob Type: Full-time\r\n\r\nSalary: R500,000.00 to R600,000.00 /month\r\n\r\nExperience:\r\nData Science: 4 years (Preferred)"},{"JobTitle":" Specialist: Data Science","Url":"https://www.indeed.co.za/rc/clk?jk=cc22549128827db0&fccid=8261b039bc53c151&vjs=3","Source":" ZealHR","Salary":null,"Age":"16 days ago","Location":"Cape Town, Western Cape","Description":"\r\n\r\n\r\nCape Town, Western Cape\r\n\r\n\r\nPermanent\r\n\r\n\r\n\r\nA well-known telecommunications company is currently seeking to employ an experienced Specialist – Data Scientist. The position will be based in Cape Town and the main role will be to participate in and to lead data science projects, solving a variety of use cases across the group.\r\n\r\n\r\n\r\nRequirements:\r\nMatric/ Grade 12 Certificate\r\n3-year degree (NQF level 7) preferably in Computer Science, Mathematics, Statistics, Engineering or a related field; OR Actuarial Science with data science experience. A relevant post graduate degree will be an added advantage.\r\n5 years relevant experience, at least 2 years of which must have been in a data science environment. Experience in ICT will be an advantage.\r\nStrong statistical & mathematical foundations.\r\nProgramming experience (Python, R, Git, Linux).\r\nCloud computing experience (GCP preferable).\r\nStatistical foundations; Mathematical foundations; Data science and analytics frameworks; Programming (Python, R, Git, Linux); Cloud computing (GCP preferable); Big Data (preferably Hadoop, PySpark)\r\nProblem Solving; Coding capability (specifically Python, R, Git, Linux); Cloud computing (GCP preferable); Machine learning; Research &\r\ndevelopment ability; Communication (written and verbal); Stakeholder management\r\n\r\n\r\n\r\n\r\nResponsibilities\r\nEngage with stakeholders to support and in some cases to lead data science project delivery solving business problems or developing solutions\r\nUsing mathematical, statistical and machine learning techniques to solve problems\r\nProgramming solutions using data science programming languages (Python, R etc.)\r\nExecuting end to end exploratory data analysis and product development processes\r\nImplementing visualization (Tableau, PowerBI), advanced analytics and data science solutions for customers\r\nParticipate in the development of junior data scientists\r\nStrong support to the lead and senior data scientists\r\nContribute to our agile way of work and our culture of innovation\r\nInput on most appropriate data science tools and/or approaches for specific projects\r\nContribute to our ML/DL codebase through reusable modules\r\nDeveloping & peer reviewing code\r\nInput into best practice standards\r\n\r\n\r\n\r\n\r\nKindly note, should you not hear from us within one week, please consider your application unsuccessful."},{"JobTitle":" Database Administrator II","Url":"https://www.indeed.co.za/rc/clk?jk=7719004d783bd87f&fccid=cfba5d68db1b7af1&vjs=3","Source":" GoldenRule","Salary":null,"Age":"11 days ago","Location":"Cape Town, Western Cape","Description":"\r\n\r\n\r\nCape Town, Western Cape\r\n\r\n\r\nPermanent\r\n\r\n\r\n\r\nThe Role\r\n\r\nThis position involves researching, evaluating and recommending NoSQL database management products available in AWS, Azure and Google cloud platforms. The person will also have to do daily operational support of these databases as well as engage with developers to gain an understanding of their requirements and propose appropriate database management technologies.\r\n\r\n\r\n\r\n1. RTO RESEARCH, EVALUATE AND RECOMMEND NoSQL PRODUCTS:\r\nEvaluate the pros and cons of NoSQL products\r\nProduce documentation to be used in solution architecture decision making\r\nRank ease of setup and management effort required for each product\r\nRank monitoring and alerting capabilities for each product\r\nDetermine the best use cases for each product\r\nConduct system performance testing for each product\r\nPerform daily database operational tasks ensuring databases are backed up and running optimally\r\n2. ASSIST DEVELOPMENT TEAM IN DESIGNING, MODELING AND VALIDATING NoSQL SOLUTIONS FOR THEIR APPLICATIONS:\r\nLiaise closely with development teams gathering their requirements\r\nPropose appropriate NoSQL database management system\r\nEnsure cloud-based solutions are built optimally, keeping maximum cost saving in mind\r\n3. TO ENSURE INFORMATION SECURITY AND REGULATORY COMPLIANCE:\r\nEnsuring system security meets regulatory compliance\r\nManage server security remediation activities which will include conducting vulnerability scans and patching\r\n4. TO CARRY OUT DATABASE ADMINISTRATION TASKS ENSURING DATA IS AVAILABLE, PROTECTED AND RECOVERABLE:\r\nPerform daily health checks for databases and resolve any issues identified\r\nEnsure database backups are scheduled and completing successfully\r\nVerify backups are valid by testing to restore process regularly\r\nMonitor databases so that capacity constraints can be mitigated by timeous provisioning of resources\r\nClose incidents within SLA\r\nExecute database changes according to the change management process\r\nAssist developers with any database issues\r\n\r\n\r\nSkills and Experience\r\n\r\nQUALIFICATIONS:\r\nGrade 12\r\nIndustry Certification:\r\no AWS Associate Architect and Developer certificate (advantageous)\r\n\r\nEXPERIENCE:\r\n Essential:\r\n3 + years managing all aspects of NoSQL database management systems from installation, configuration, backup management, and security\r\n3 + years’ Experience working with services in AWS\r\n3 + years Exposure to one or more Apache Software Foundation Big Data & Database projects such as Cassandra, Hadoop, Hbase, MongoDB\r\n3 + years Proficient with some of the common developer toolsets such as Java, XML, JSON, REST, Shell, Perl, and Python\r\n\r\n KNOWLEDGE:\r\n4 + years General understanding of database management concepts\r\n\r\n\r\nSKILLS:\r\n Essential:\r\n3 + years Proficient with installing, configuring, administering, using and benchmarking NoSQL solutions\r\n3 + years Basic familiarity with Linux operating system\r\n3 + years Some experience engineering and/or administering NoSQL infrastructure\r\n3 + years Proficient with one or more Apache Software Foundation Big Data and Database projects such as Cassandra, Hadoop, Hbase, MongoDB\r\n2 + years Knowledgeable in designing, developing and documenting use cases.\r\n3 + years Proficient with some of the common developer toolsets such as Java, XML, JSON, REST, Shell, Perl and etc."},{"JobTitle":" Data Engineer","Url":"https://www.indeed.co.za/rc/clk?jk=657265099fad384a&fccid=77a92c42089607f3&vjs=3","Source":" Prodigy Finance","Salary":null,"Age":"30+ days ago","Location":"Cape Town, Western Cape","Description":"\r\n\r\n\r\nCape Town, Western Cape\r\nProdigy Finance - who we are \r\n\r\n Prodigy Finance is a platform that enables financing for international postgraduate students at the world's best universities, whilst delivering competitive financial and social returns to alumni, institutional and private investors. \r\n\r\n This borderless and innovative model enables education loan financing to students from across the globe, whilst using predicted post-degree affordability rather than present-day salary. Since 2007, Prodigy Finance has extended almost US$1 billion through the platform to fund over 20,000 students from over 150 countries. \r\n\r\n Our team of over 170 (and growing) is already truly global. Our head office is in London with much of the team being based in beautiful Cape Town. We also have an office in New York plus team members based across Europe and Asia. \r\n\r\n We are funded by some of the best, pre-eminent institutions in the world including Index Ventures, Balderton Capital, RMIH, Credit Suisse and Deutsche Bank. \r\n\r\n Why this is an amazing opportunity \r\n\r\n This role is perfect for an experienced Data Engineer who wants to supercharge their career by experiencing first-hand what it is like to be part of an energetic, extremely fast growing company. \r\n\r\n The sense of impact and reward will be huge. You will help to build a product which makes a very real difference in the world. Be a part of delivering socially responsible financial services to the masses; make it possible for students from more than 150 countries to obtain the finance to fulfil their dream of studying at the world's top universities and schools. \r\n\r\n We are a non-hierarchical team; this means that you are going to get exposure to all aspects of our business immediately. You'll gain as much accountability as you can handle and have a huge influence on scaling the company. \r\n\r\n Our team is very international and very sociable; you will interact with the broader business on a regular basis. The position will be based in Cape Town. \r\n\r\n One of our goals is to build one of the top FinTech teams and cultures anywhere in the world. This means putting a lot of time into ensuring we only hire people with exceptional potential and creating the best working environment possible. If you want to work somewhere where you're learning from some of the best brains in FinTech, this would be a good fit. \r\n\r\n Why join Prodigy Finance \r\n\r\nBe a part of a pioneering global growth company\r\nExperience the excitement and learn from being part of an incredibly fast-growing young company. No kidding – exponential growth. Happening right now\r\nBe pivotal in continuing to scale the business by identifying smart solutions and partners with Technology at the heart of it\r\nEnjoy the agility and flexibility offered by our culture. We're still a start-up at heart, so you can expect a sociable, relaxed and friendly work environment (with a serious coffee culture where you can wear shorts to work)\r\nWe will help you make your mark. Make a real impact on the business and experience a steep learning curve with huge opportunities to grow and develop\r\nGain an inside perspective on the functioning of a venture-backed FinTech company with successful start-up roots, backed by top VCs, learn day-to-day management and build functional expertise\r\nBuild a platform that helps to make a very real difference in the world\r\nWhat you will do in the role \r\n\r\n Get to grips with data engineering by working in the data engineering team helping to get data into our systems as well as provide access to that data for different stakeholders. \r\n\r\nBe an integral and trusted member of the data engineering team\r\nBe a mentor to new team members\r\nHands on coding / implementation to enable data to flow to our data systems from both internal and external sources\r\nEstablish good working relationships across the tech team in order to better understand the data being created and help mould our data practices and standards\r\nEstablish good working relationships with data consumers in order to better how they use the data and advocate how we enable them to use data more effectively and efficiently\r\nYou take responsibility for the data and systems you both inherit and produce. Be passionate about data engineering and make our data solutions better\r\nResearch and stay abreast of key technical developments and trends\r\nWhat you will be measured on \r\n\r\nThe integration of data sources via API, Flat File or other mechanisms into our data warehouse\r\nThe timely delivery of quality data to our business teams\r\nThe quality of the data we store within our data warehouse\r\nThe adherence to target architecture guidelines, or your influence in changing how we architect for data integration, transformation and access\r\nHelping our data engineering team focus on value in order for it to be a valuable asset to the business\r\nMindfulness; become aware of how your work and your behaviour impacts the wider result and the impact, not only on the platform build, but on the whole Prodigy Finance team\r\nWhat you need to be great at \r\n\r\nTechnical competence; love coding, able to learn new paradigms quickly and look to continuously improve and find better ways of doing things\r\nExcellent critical judgement; able to make good decisions, be trusted, respected and dependable, be proactive and responsive, ask the right questions, raise flags at the right time, able to prioritize and plan your own individual tasks\r\nMindfulness; be considerate of the implications of your work, really care about what you are doing and the impact of your contribution\r\nTeamwork and team spirit; we are all contributing to the same platform, so you need to not only be a great individual contributor but be more motivated by the achievements of the whole team - we only win if the team wins, see the impact of your own work and positively influence and help the work of others\r\nGetting up to the front of the bus; get stuck in, execute, generate ideas, have an impact, don't just sit back and be a passenger\r\nWho we are looking for; track record must haves \r\n\r\n3+ years experience within software engineering\r\nExperience with relational database administration\r\nExperience working with data pipelines and messaging systems (e.g. RabbitMQ, SQS)\r\nExperience working with Cloud Platforms such as AWS or Azure\r\nExperience with software application development in a production environment\r\nUnderstand software design principles and best practices (TDD, continuous deployment, etc.)\r\nExperience that would be nice to have (but we'll trade off if everything else fits) \r\n\r\nExperience working in a data engineering team\r\nSolid foundational knowledge of Data Science and Business Intelligence\r\nExperience with Data Warehousing and ETLs\r\nExperience working with Amazon RedShift\r\nExperience working with Postgres\r\nExperience with NoSQL database platform (e.g. Hadoop)\r\nExperience with AWS data processing tools (e.g. DMS)\r\nPython, Ruby and SQL experience will be highly beneficial\r\nThe Prodigy Finance fit; attributes which run true in everyone at Team Prodigy \r\n\r\n To be an A player at Prodigy Finance, you need to possess – in spades - the following attributes: \r\n\r\n Innovative + Smart \r\n\r\n Be curious enough to want to know more, think out the box, maybe even break the box, show initiative and be smart about it to find implementable, impactful solutions. \r\n\r\n International + Accountable \r\n\r\n Push yourself to be better every day. Work with others across the world, be resilient, add value and then hold yourself accountable. Encourage and celebrate each other. \r\n\r\n Energetic + Fun \r\n\r\n Sense of humour = survival. Bring energy and fun. Wear your heart on your sleeve. Work hard and find the time to play. We're in this together. \r\n\r\n Do you want to be our next Data Engineer? Here's what to do now: \r\n\r\n If this sounds exciting and you'd like to have an informal chat, get in touch below and tell us why you want to work at Prodigy Finance."},{"JobTitle":" Cloud Support Engineer (Big Data)","Url":"https://www.indeed.co.za/rc/clk?jk=85bccad6424a54b9&fccid=fe2d21eef233e94a&vjs=3","Source":" Amazon Dev Centre South Africa","Salary":null,"Age":"30+ days ago","Location":"Cape Town, Western Cape","Description":"\r\n\r\n\r\nCape Town, Western Cape\r\n\r\nTo qualify for this role, you should have the following experience:\r\n\r\nStrong Linux/Unix system administrator skills\r\nIntermediate programming/scripting skills. Ideally in Java or Python, but will consider experience in other Object Oriented and Functional languages\r\nUnderstanding of networking principles and ability to troubleshoot (DNS, TCP/IP, HTTP)\r\nFoundational knowledge of databases and Structured Query Language (SQL)\r\nUnderstanding of Virtualization and/or cloud computing\r\nGood understanding of security best practices\r\nImpeccable written and oral communication skills\r\nExceptional customer focus / Customer service experience\r\nGood understanding of distributed computing environments and methodologies\r\nAbility to work a staggered week, either Sun-Thu or Tue-Sat (no on-call)\r\n\r\n\r\nAmazon has built a reputation for excellence with recent examples of being named #1 in customer service, #1 most trusted, and #2 most innovative. Amazon Web Services (AWS) is carrying on that tradition while leading the world in Cloud technologies. AWS Support provides global technical support to a wide range of external customers as they build mission-critical applications on top of AWS services.\r\n\r\n Our Big Data Support team specialises in helping customers with streaming, storing and processing vast amounts of data in the Cloud. We also help our customers to leverage this data to produce business insights, which may include using Machine Learning/Artificial Intelligence (ML/AI). Our engineers focus on helping customers use and integrate services in what is arguably our industry’s most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), ElasticSearch, Kinesis, Athena, ML/AI & more. With a global presence in eight countries. Our follow the sun support and shift model mean you will not be on-call.\r\n\r\n We are seeking talented Systems engineers well versed in maintaining infrastructure of large complex systems/clusters. You will also be able to write code to automate maintenance, monitor performance or crunch data to solve business problems. We invest heavily in knowledge acquisition and skills development providing unlimited opportunities for technical and career development. If you have a spark for knowledge – we have the fuel for the fire.\r\n\r\n Typical Day\r\n Every day will bring new and exciting challenges on the job while you: · Apply advanced troubleshooting techniques to provide tailored solutions for our customers · Drive customer interactions. Phone, Chat, Emails, Screen shares and conference calls · Leverage your customer support experience to provide feedback to internal AWS teams on how to improve our services · Interact with leading technologists around the world\r\n\r\n\r\nThese qualifications are optional, but please highlight them on your resume if you have them:\r\n\r\nB.S. or M.S. degree in Computer Science, MIS, CIS, or a related field\r\n3+ years’ experience in either technical support or software development\r\nDemonstrable Knowledge & experience in various Big Data or distributed systems. Such as Hadoop, NoSQL, Search and Streaming\r\nExperience with Cloud Services and Cloud deployments. Exposure specifically to AWS a bonus\r\nExperience utilising data analysis techniques such as quantitative or qualitative analysis\r\n\r\n Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity and Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae."},{"JobTitle":" Big Data Developer (CPT)","Url":"https://www.indeed.co.za/rc/clk?jk=960548b153c061f5&fccid=6ab9a95a1ff7d948&vjs=3","Source":" Parvana Strategic Sourcing","Salary":null,"Age":"30+ days ago","Location":"Cape Town, Western Cape","Description":"\r\n\r\n\r\nCape Town, Western Cape\r\n\r\n\r\nPermanent\r\n\r\n\r\n\r\n\r\nResponsibilities: Building and operating a content management platform for a high-profile big data project that promises to revolutionise an area of finance by providing unprecedented market insight in a timely manner.\r\nWorking closely within a team of developers distributed in London, Johannesburg, Cape Town and New Zealand.\r\nBuilding and operating an ingestion and analytics platform that collects frequently changing data and exposing the normalised and aggregated data via APIs to our client’s customers. This will include data cleansing, aggregation, financial computations.\r\n\r\n\r\n\r\nSkills & Experience: Must be able to pick up a new technology quickly and deliver features in a highly agile manner.\r\nExperience writing functional Scala in a production grade system. You are not a Java developer writing OO in Scala.\r\nPrevious experience using Apache Spark SQL in a production system using Scala with YARN as the resource manager.\r\nClear and practical understanding of how Hive works, which includes running Hive on Tez.\r\nPractical experience using Debian flavoured Linux distributions.\r\nFamiliarity with event driven development and architectures.\r\nPrevious experience using Docker containers to deploy your systems.\r\nAbility to easily navigate the administration of an HDP cluster on AWS.\r\nMust be able to index millions of documents from Hadoop into Elasticsearch.\r\nAbility to work with various messaging systems, such as Kafka and RabbitMQ.\r\nMust be able to aggregate data using Apache Kylin Cube.\r\nMust be able to easily pick up Python if you have not used it previously.\r\nAbility to operate and deploy to a Kubernetes cluster on AWS.\r\nMust be able to understand basic concepts about mortgage backed securities.\r\n\r\n\r\n\r\nTo apply use the application tool or send us an email to recruitment@parvana.co.uk \r\n\r\n\r\n\r\nBig Data Developer (CPT) (New) | (1002333)\r\n\r\n[Permanent | Competitive Salary | Cape Town]\r\n\r\n\r\nClient Background: Our client develops and supports software and data solutions across a variety of industries. \r\n They want you to get ahead of the market and stay there. They offer a combination of plug and play products that can be integrated with existing systems and processes and can also be customised to client needs. \r\n Their capabilities extend to big data engineering and bespoke software development, solutions are available as both cloud-based and hosted.\r\n\r\n\r\nResponsibilities: Building and operating a content management platform for a high-profile big data project that promises to revolutionise an area of finance by providing unprecedented market insight in a timely manner.\r\nWorking closely within a team of developers distributed in London, Johannesburg, Cape Town and New Zealand.\r\nBuilding and operating an ingestion and analytics platform that collects frequently changing data and exposing the normalised and aggregated data via APIs to our client’s customers. This will include data cleansing, aggregation, financial computations.\r\n\r\nSkills & Experience: Must be able to pick up a new technology quickly and deliver features in a highly agile manner.\r\nExperience writing functional Scala in a production grade system. You are not a Java developer writing OO in Scala.\r\nPrevious experience using Apache Spark SQL in a production system using Scala with YARN as the resource manager.\r\nClear and practical understanding of how Hive works, which includes running Hive on Tez.\r\nPractical experience using Debian flavoured Linux distributions.\r\nFamiliarity with event driven development and architectures.\r\nPrevious experience using Docker containers to deploy your systems.\r\nAbility to easily navigate the administration of an HDP cluster on AWS.\r\nMust be able to index millions of documents from Hadoop into Elasticsearch.\r\nAbility to work with various messaging systems, such as Kafka and RabbitMQ.\r\nMust be able to aggregate data using Apache Kylin Cube.\r\nMust be able to easily pick up Python if you have not used it previously.\r\nAbility to operate and deploy to a Kubernetes cluster on AWS.\r\nMust be able to understand basic concepts about mortgage backed securities.\r\n\r\nTo apply use the application tool or send us an email to recruitment@parvana.co.uk"},{"JobTitle":" AI high potential (Data Scientist)","Url":"https://www.indeed.co.za/company/Cape-Town-AI/jobs/Ai-High-Potential-0e3c7a0fa9b8c2d3?fccid=d65a989c7c3f0b80&vjs=3","Source":" Cape Town AI","Salary":null,"Age":"30+ days ago","Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\nRequired entry level:\r\n\r\nUniversity Graduate.\r\n\r\nGood proficiency in at least one programming language (preferably Python). Hand-on experience with building machine learning models and handling SQL databases. Basic devops skills such as working with git / virtual machines in the cloud etc. Being able to understand and explainthe mathematics and statistics behind machine learning algorithms.\r\n\r\nIf you don't meet these criteria please apply for the internship instead\r\n\r\nInformation:\r\n\r\nDid you finish your BSc, MSc or PhD in Computer Science, Statistics or similar? At Cape Town AI we are creating an environment where high potentials learn together, get industry experience from day one and rapidly become senior AI experts.\r\n\r\nOur AI High Potential Program is a 2 years program. A development process in which you gain work experience and deepen your knowledge through intensive training.\r\n\r\nFOUR DAYS AT THE CLIENT\r\nAs our ‘lion’ you start to work at one of our clients’ projects for four days a week. We make sure the projects fit your skills and interests. Before you start at the client we design a preparation\r\nprogram to fill domain & technical knowledge gaps. The clients we work with strive with us to improve the world we live in through AI.\r\n\r\nSENIOR GUIDANCE AND TRAINING\r\nOn Friday all lions come together at the office and get senior guidance from our Technical Head of Lions and invited top experts. Friday projects exclusively focus on sustainability, conservation & social challenges such as unemployment & drought. After the Friday program, it is Hakuna Matata time.\r\n\r\nTraining subjects: Python, R, SQL, Databases, Text mining, Deep learning, Machine learning, Scala, Pipelines, Kafka, Kubernetes, Spark, Docker, Cloud (Aws, Google, Azure), API, Hadoop, Digital Transformation.\r\n\r\nJob Type: Full-time"},{"JobTitle":" Data Scientist - Banking","Url":"https://www.indeed.co.za/rc/clk?jk=9e14b6957a83caad&fccid=2d1a4a3e36fdc9e5&vjs=3","Source":" SET Consulting","Salary":null,"Age":"10 days ago","Location":"Fairland, Gauteng","Description":"\r\n\r\n\r\nFairland, Gauteng\r\n\r\n\r\nPermanent\r\n\r\n\r\n\r\nLeading, innovative financial services concern strongly entrenched in technical innovation and using this to deliver exceptional client service and leading-edge financial solutions.\r\n\r\nTheir digital footprint reflects their commitment to the latest solutions, having the best people on board, and a uniquely flexible and vibrant work culture.\r\n\r\nTo build on this success going forward, they are looking to appoint an experienced Data Scientist with Machine Learning to assist them to executive on their IT journey.\r\n\r\nNational Diploma – IT or Post graduate degree – perf. Computer Science / Engineering or Applied Maths very pref. 4 – 5 years Data Scientist experience with some Machine Learning or Robotics experience essential (Facial Recognition technology very pref.)\r\n\r\nSolid coding experience in Hadoop, R or Python and 5 -7 years application development and support experience, coupled with experience creating production software / systems and a proven track record of identifying and resolving performance bottlenecks for production systems and / or algorithms essential.\r\n\r\nIf this role is in line with your career aspirations, contract Karen Schmoor – SET Consulting -email karen@set.co.za or (011) 234 – 4313.\r\n\r\nPlease note, if you have not heard back from us within 2 weeks, please regard your application as unsuccessful."},{"JobTitle":" Senior Specialist: Support Analyst","Url":"https://www.indeed.co.za/rc/clk?jk=acbd902ab746d6c9&fccid=374d720d3973ca1c&vjs=3","Source":" Vodafone","Salary":null,"Age":"30+ days ago","Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\n\r\nVodacom is a Leading African Mobile communication company providing wider range of communication services including mobile voice, messaging, data and converged services to over 73.6 million customers. From our roots in South Africa, we have grown our mobile network business to include operations in Tanzania, DRC, Mozambique and Lesotho. The mobile networks cover a total population of approximately 200 million people. Through Vodacom Business Africa (VBA) we also offer business managed services to enterprises in over 40 countries across the continent. Vodafone is the majority shareholder of Vodacom and has a 65% share.\r\n\r\n\r\n\r\n\r\n\r\nWere at our best when we lead and over the past 20 years, as the Company that pioneered mobile in South Africa, Vodacom has achieved a remarkable list of firsts. Were immensely proud to be a leader in our field and are 100% committed to continue trailblazing.\r\n\r\n\r\n\r\n\r\nWe employ individuals who are as passionate about customers as we are. We are truly Customer Obsessed which means that we are passionate about exceeding customer expectations; work relentlessly to really understand the customer; look at decisions through the customers eyes and take personal accountability for the customer experience.\r\n\r\n\r\n\r\n\r\nWe have the below vacancy available in our Organisation:\r\n\r\n\r\n\r\n\r\n\r\nThe G Band Senior Specialist: Support Analyst role is based within Local Technology\r\n\r\n\r\n\r\n\r\n\r\nThe role of the Senior Specialist: Support Analyst is to be responsible for and ensuring of data import and processing into the BDP. Installation of CDH repository, OS level configuration, new type of I/O compression library cluster, and Hadoop installation &support including the Cloudera manager, adding new nodes and services to the cluster\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nYour responsibilities will include:\r\n\r\n\r\n Configure and Maintain Name Node/ Resource manager High Availability (HA), including Hive, Impala\r\n\r\n\r\n\r\n Manage cluster support by rebalancing the cluster, setting up alerting for disk fill, and YARN resource management;\r\n\r\n\r\n\r\nConfigure HDFS ACLs, Sentry, Hue user authorization and authentication;\r\n\r\n\r\n\r\nContinuous benchmarking of the cluster s operational metrics, test systems configuration for operational efficiency;\r\n\r\n\r\n\r\nResolve all logged incidences and service requests (SR) Troubleshoot and resolve errors/warnings in Cloudera Manager and application delays. Resolve performance problems/errors in operations\r\n\r\n\r\n Provide guidance and decisive technical leadership\r\n\r\n\r\n Ensure the BDP cluster is secured from potential vulnerabilities\r\n\r\n\r\n Provided a leadership role with key stakeholders for optimal deliverance of use cases\r\n\r\n\r\n Drive DevOps way of working\r\n\r\n\r\n Expert level experience with using Spark, Yarn, Hive and Oozie\r\n\r\n\r\n Python and Scala programming ability will be an advantage\r\n\r\n\r\n Working knowledge of HBase, Kafka, Cassandra and Flume\r\n\r\n\r\n Ability to work standby and overtime when required\r\n\r\n\r\n Expert knowledge of NiFi, Sqoop and Flume will be an added advantage.\r\n\r\n\r\n\r\n\r\n\r\n\r\nKey accountabilities and decision ownership:\r\n\r\n\r\n\r\nExtensive experience in designing, building and managing BDP applications in ingesting and storing large amounts of data in a Hadoop/HDFS ecosystem;\r\n Extensive experience with performance tuning applications on Hadoop/YARN and configuring Hadoop/YARN systems to maximise performance;\r\n Extensive experience in installing, testing, configuring BDP ecosystems\r\n Extensive experience is solving complex requests or service impacting incidents within the BDP cluster\r\n Experience working in a multi tenancy Hadoop environment\r\n\r\n\r\n\r\n\r\n\r\nCore competencies, knowledge and experience:\r\n\r\n Hadoop,\r\n\r\n YARN,\r\n Linux,\r\n HDFS\r\n CDH\r\n Scripting/Java/Python/R\r\n\r\n\r\n\r\n The ideal candidate for this role will have:\r\n Matric/ Grade 12 qualification\r\n 3 year completed Ndip/Degree in Information Technology or equivalent\r\n At least 5-8 years IT experience (Telecoms or Fixed mobile advantageous)\r\n CCA131 certification (desirable)\r\n Knowledge of Big Data (essential)\r\n Agile Methodology(desirable)\r\n Hadoop or YARN or Linux or HDFS or CDH or Scripting/Java/Python/R (essential)\r\n\r\n\r\n\r\nIn addition to the details listed above, the ideal candidate will have an in-depth knowledge and understanding\r\n\r\n\r\n\r\n Availability and optimal functioning of the BDP cluster ecosystems\r\n Servicing incidents and service requests in a timely manner\r\n Adjustment to the Agile environment\r\n\r\n\r\n\r\nThe base location for this role is Midrand, Commercial Park\r\n\r\n\r\n\r\nThe Companys approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply.\r\n\r\n\r\n\r\nVodacom is committed to an organisational culture that recognises, appreciates and values diversity inclusion."},{"JobTitle":" SENIOR JAVA SCALA BIG DATA DEVELOPER â€† Investment Banking...","Url":"https://www.indeed.co.za/pagead/clk?mo=r&ad=-6NYlbfkN0AMOOo83f3x9FLd22RLK3YfFusStXJLn5R4tAT9NKF0tAvdVEybpYDI30GAsFF9jubutPs3PbEcmvxKfbKa0-BgQwRIo3IgFX82C9jtZeko62JbbfDFl-bjVwV4kG_846TnzbebTwroYbwk_lOEqcnBHp0AlJHnPkrxPZ-QOE029kZToLUCyUNn7T2p7hYRBSsHCN4pRphkYqsS7K4K1nohIMydsFk2iXlIXD2ntzAkOCvn7sGDbqYYJlHd62RjdKqjDGm-tSowz2T_qcbZxVFtz2dV6bUyB6Hir3i3SwjvT0k3tU8ZMuBeGR2AfnUL49nIeStEWor8USrhj4mDsnyev0mqD9uXlMvVvPUNU0YjKTWYpUDS3zYSCtNvR_zjf9HYslV8JzIjVAuGtcidz1McQmop4QJiIT8DI6nw5aB4EiMuMVAEunbwCOM99xr1nrEjz7CxhuWOBm16-dAK2X7FoObHWWlkqnOBdpr1APm52NRvb0ZZgV_UQaJdnRhqwSTgRMTOg80n1O6_7K36hrMf1HKE1m8CEizmnG-F0LqMKtjy9yFjQDLepsICpp7k1ktbD5VjWUCbXKXSqckgMmzN5a6vKCSVYcIXeExKhMSGmlZvuTPISTrV&p=10&fvj=0&vjs=3","Source":" E-Merge","Salary":" R900 000 a year","Age":null,"Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\nR900 000 a year\r\n\r\n\r\nSENIOR JAVA SCALA BIG DATA DEVELOPER – Investment Banking – Sandton - R900K PA\r\n\r\nSandton based opportunity allowing you to enhance your Big Data skills whilst gaining experience in the investment banking sector. They are typically a cloud based, huge volume, low latency business, problem solving across Africa for Africans.\r\n\r\nThey are ideally looking for a Java, Scala, Big Data skilled person who will be involved in building software services for Big Data Teams. If you are a keen problem solver and a GURU in the Software Engineering space – this may be a great option to consider.\r\n\r\n Nice to haves:\r\n Relevant tertiary qualification in Engineering or Computer Science\r\n Java development - at least 5 years minimum.\r\n Spark development experience\r\n Scala development experience\r\n Big Data experience on the Hadoop and KAFKA technologies.\r\n\r\n Requirements:\r\n Hands on Delivery skills with strategic thinking\r\n Strong JAVA Dev experience\r\n Any OO Tech background – C# OR Java (J2EE OR JEE) OR C++ OR Functional OR Ruby OR Mean Stack\r\n Some Functional Programming experience and or motivation to be involved in Functional Programming\r\n Background in Designing and building Distributed systems\r\n Highly educated with strong technology opinions\r\n Agile – Scrum\r\n CI / CD / DevOps etc.\r\n\r\n Additional nice to have:\r\n Functional Dev – Scala / C# / Haskell / Clojure etc.\r\n Advanced JavaScript\r\n Micro Services Architecture\r\n Cloud – Amazon, Azure or similar\r\n\r\n Reference Number for this position is GZ42079 which is a permanent position based in Sandton offering a cost to company salary of up to R900k per annum, negotiable on experience and ability. Contact Garth on -Please upload your CV here- or call him on<-Please upload your CV here- to discuss this and other opportunities.\r\n\r\nAre you ready for a change of scenery? The e-Merge IT recruitment is a specialist niche recruitment agency. We offer our candidates options so that we can successfully place the right developers with the right companies in the right roles.\r\n\r\nCheck out the e-Merge website <-Please upload your CV here- for more great positions.\r\n\r\nDo you have a friend who is a developer or technology specialist? We pay cash for successful referrals!"},{"JobTitle":" Senior Data Scientist - Advanced Analytics","Url":"https://www.indeed.co.za/rc/clk?jk=4a8d202c8820b1d7&fccid=6576e7250aa78c3c&vjs=3","Source":" McKinsey & Company","Salary":null,"Age":"30+ days ago","Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\n\r\n\r\n\r\nQualifications\r\n\r\nBachelor’s degree in quantitative field like Computer Science, Engineering, Statistics, Mathematics or related field required; Advanced degree is a plus\r\n 3-5 years of hands-on mathematical modelling experience in business environment\r\n Programming (focus on Machine Learning) in R and/or Python (must), SPSS, SAS, Ruby, Hadoop (valued)\r\n Data treatment/Data mining SQL, AWK, Access, Spark, Excel (valued\r\n Advanced knowledge of statistical and machine learning techniques (regression, decision trees, clustering, neural networks, etc.)\r\n Proven experience in working with large datasets and relational databases (SQL)\r\n Distinctive communications skills and ability to communicate analytical and technical content in an easy to understand way\r\n Intellectual curiosity, along with excellent problem-solving and quantitative skills, including the ability to disaggregate issues, identify root causes and recommend solutions\r\n Proven leadership with the ability to inspire others, build strong relationships, and create true followership, result-driven achievers\r\n Strong people skills, team-orientation, and a professional attitude\r\n Experience and interest in RDBMS systems (MySQL, IBM DB2, Oracle Database, etc.), cloud (AWS, Azure, Google Cloud Platform) and big data technologies (e.g. Hadoop, Hive, Impala, Spark, NoSQL DBs) is preferable (reword?)\r\n Experience in data extraction, transformation, cleaning, and validation\r\n Experience implementing advanced analytics / data science models into a production environment is a plus\r\n\r\n\r\n\r\nWho You'll Work With\r\n\r\nYou will join McKinsey’s Africa Analytics Practice, based in Johannesburg. Our Advanced Analytics teams bring the latest analytical techniques plus a deep understanding of industry dynamics and corporate functions to help clients create the most value from data in order to unlock the strategic CEO agenda.\r\n\r\nYour role will entail extensive interactions with our global analytics community; partnering with generalist consultants, clients and other colleagues. \r\n\r\n\r\n\r\nWhat You'll Do\r\n\r\nYou will be involved in specific engagements involving the building of new and bespoke advanced analytics solutions for clients.\r\n\r\nLeveraging your advanced data and analytics skills, you will create innovative approaches to answer our clients’ most relevant questions. You will prepare complex data analyses and models that help solve client problems and deliver significant measurable impact. You will have a strong understanding of the design and development process of data analytics tools and experience working with data engineers and other data scientists, both from McKinsey and clients."},{"JobTitle":" BIG DATA ENGINEER","Url":"https://www.indeed.co.za/rc/clk?jk=b1b5c09e5add6635&fccid=36b7d079d13b5af5&vjs=3","Source":" Acuity Consultants","Salary":" R900 000 - R950 000 a year","Age":"30+ days ago","Location":"Sandton, Gauteng","Description":"\r\n\r\n\r\nSandton, Gauteng\r\n\r\n\r\nPermanent\r\n\r\n\r\nR900 000 - R950 000 a year\r\n\r\n\r\n\r\nChallenging opportunity awaits a BIG DATA ENGINEER who seeks to HANDLE DATA THAT RANGES FROM 100GB TO PETABYTE SIZES using an AI Platform that helps its clients out predict their competitors and improve overall customer satisfaction and efficiency.\r\n\r\nThis role is based in Sandton and paying between R900 000 and R950 000 PA.\r\n\r\nCompany:\r\n\r\nHaving made great strides in the field of AI, this South African based company has created a revolutionary AI Platform that can deliver industry leading automated consumer behaviour predictions for companies by using their raw unstructured data. By using deep learning algorithms this platform has provided clients with better business insights, improved customer satisfaction and overall efficiency by matching people with products, matching inventory with business opportunities and spending with propensity.\r\n\r\nWith a $2 Million venture backing, this AI platform has superseded expectations and is in the process of expanding its team to meet the high demand for their platform and produce even better results which usually only takes 2 weeks.\r\n\r\nJob Description:\r\n\r\nAs part of a team of extraordinary engineers you will be expected to deliver automated consumer behaviour prediction platforms to companies that produces results multiply better than traditional statistical methods. The company in question automates and commoditizes cutting edge AI results directly from client data, as a result you will need to help the platform handle data at the massive scale required.\r\n\r\nDuties Include:\r\nSelecting and integrating any Big Data tools and frameworks required to provide capabilities.\r\nImplementing ETL process.\r\nPart of ETL is analysing and understanding the data well enough to integrate into the API.\r\nPropose, design and implement Big Data Architecture including infrastructure.\r\nMonitoring performance and advising any necessary infrastructure changes.\r\nDefining data retention policies.\r\n\r\nRequirements:\r\nAt least 6 months Hadoop experience (or knowledge thereof)\r\nexperience in NoSql databases (Cassandra preferred) OR MongoDB\r\nExperience with building stream-processing systems, using solutions such as Storm or Spark-Streaming.\r\nExperience with integration of data from multiple data sources.\r\nKnowledge of various ETL techniques."},{"JobTitle":" Senior Data Engineer, Centurion, R1.1mill","Url":"https://www.indeed.co.za/rc/clk?jk=8e8ff29442e769cf&fccid=77748257c144323d&vjs=3","Source":" e-Merge IT Recruitment","Salary":null,"Age":"11 days ago","Location":"Centurion, Gauteng","Description":"\r\n\r\n\r\nCenturion, Gauteng\r\n\r\n\r\nDescription\r\n\r\n\r\nOne of the fastest growing telecommunications providers in South Africa, that operate in more than 38 countries across the African continent, is looking for high calibre Senior Data Engineers to join their team. They are looking for candidates that ideally have 5 years of work experience in the field of data engineering and at least 2 years lead/management/specialist level experience.\r\n\r\n Requirements:\r\n Relevant IT degree\r\n Database foundation; Data engineering foundation; Programming foundation; Cloud computing; Relational SQL and NoSQL databases\r\n Big data engineering (e.g. Cloudera, Hadoop, Spark)\r\n Programming (e.g. Python, SQL, Git, Shell, JavaScript)\r\n Cloud computing and platform management (e.g. GCP, Azure)\r\n Stakeholder management\r\n\r\nReference Number for this position is MH46188. This is permanent role based in Centurion offering up to R1.1mill per annum based on experience, skillset and current level. Contact michelle on michelle@e-merge.co.za\r\n\r\nAre you ready for a change of scenery? e-Merge IT recruitment is a niche recruitment agency. We offer our candidates options so that we can successfully place the right people with the right companies, in the right roles. Do you have a friend who is a developer or technology specialist? We pay cash for successful referrals!"},{"JobTitle":" Data Scientist, Johannesburg North, R600k","Url":"https://www.indeed.co.za/rc/clk?jk=78cb6cc4acc7954e&fccid=77748257c144323d&vjs=3","Source":" e-Merge IT Recruitment","Salary":" R600 000 a year","Age":"24 days ago","Location":"Johannesburg North, Gauteng","Description":"\r\n\r\n\r\nJohannesburg North, Gauteng\r\n\r\n\r\nR600 000 a year\r\n\r\n\r\nDescription\r\n\r\n\r\nA very nice tech shop is looking for driven, intelligent Data Scientists to join their business. They offer no dress-codes, flexible working hours, the latest workstation of your choice, and occasional remote work.\r\n\r\n Requirements:\r\n Top achievers when it comes to their degree results\r\n Honours degrees and higher are preferred in Computer Science / Physical Sciences / Statistics / Mathematics / Engineering / Big Data\r\n 2+ years’ experience in the capacity of Data Scientist\r\n Experience in R, Python, Hadoop, machine learning algorithms, Spark (Pyspark) and more.\r\n\r\nReference Number for this position is MH45892. This is permanent role based in Illovo offering up to R600k per annum based on experience, skillset and current level. Contact Michelle on michelle@e-merge.co.za\r\n\r\nAre you ready for a change of scenery? e-Merge IT recruitment is a niche recruitment agency. We offer our candidates options so that we can successfully place the right people with the right companies, in the right roles. Check out the e-Merge IT website for more great positions.\r\n\r\nDo you have a friend who is a developer or technology specialist? We pay cash for successful referrals!"},{"JobTitle":" Big Data Developer (JHB)","Url":"https://www.indeed.co.za/rc/clk?jk=dc2adc6e2281aaed&fccid=6ab9a95a1ff7d948&vjs=3","Source":" Parvana Strategic Sourcing","Salary":null,"Age":"30+ days ago","Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\nPermanent\r\n\r\n\r\n\r\n\r\nResponsibilities: Building and operating a content management platform for a high-profile big data project that promises to revolutionise an area of finance by providing unprecedented market insight in a timely manner.\r\nWorking closely within a team of developers distributed in London, Johannesburg, Cape Town and New Zealand.\r\nBuilding and operating an ingestion and analytics platform that collects frequently changing data and exposing the normalised and aggregated data via APIs to our client’s customers. This will include data cleansing, aggregation, financial computations.\r\n\r\n\r\n\r\nSkills & Experience: Must be able to pick up a new technology quickly and deliver features in a highly agile manner.\r\nExperience writing functional Scala in a production grade system. You are not a Java developer writing OO in Scala.\r\nPrevious experience using Apache Spark SQL in a production system using Scala with YARN as the resource manager.\r\nClear and practical understanding of how Hive works, which includes running Hive on Tez.\r\nPractical experience using Debian flavoured Linux distributions.\r\nFamiliarity with event driven development and architectures.\r\nPrevious experience using Docker containers to deploy your systems.\r\nAbility to easily navigate the administration of an HDP cluster on AWS.\r\nMust be able to index millions of documents from Hadoop into Elasticsearch.\r\nAbility to work with various messaging systems, such as Kafka and RabbitMQ.\r\nMust be able to aggregate data using Apache Kylin Cube.\r\nMust be able to easily pick up Python if you have not used it previously.\r\nAbility to operate and deploy to a Kubernetes cluster on AWS.\r\nMust be able to understand basic concepts about mortgage backed securities.\r\n\r\n\r\n\r\nTo apply use the application tool or send us an email to recruitment@parvana.co.uk \r\n\r\n\r\n\r\nBig Data Developer (JHB) (New) | (1002332)\r\n\r\n[Permanent | Competitive Salary | Johannesburg]\r\n\r\n\r\nClient Background: Our client develops and supports software and data solutions across a variety of industries. \r\n They want you to get ahead of the market and stay there. They offer a combination of plug and play products that can be integrated with existing systems and processes and can also be customised to client needs. \r\n Their capabilities extend to big data engineering and bespoke software development, solutions are available as both cloud-based and hosted.\r\n\r\n\r\nResponsibilities: Building and operating a content management platform for a high-profile big data project that promises to revolutionise an area of finance by providing unprecedented market insight in a timely manner.\r\nWorking closely within a team of developers distributed in London, Johannesburg, Cape Town and New Zealand.\r\nBuilding and operating an ingestion and analytics platform that collects frequently changing data and exposing the normalised and aggregated data via APIs to our client’s customers. This will include data cleansing, aggregation, financial computations.\r\n\r\nSkills & Experience: Must be able to pick up a new technology quickly and deliver features in a highly agile manner.\r\nExperience writing functional Scala in a production grade system. You are not a Java developer writing OO in Scala.\r\nPrevious experience using Apache Spark SQL in a production system using Scala with YARN as the resource manager.\r\nClear and practical understanding of how Hive works, which includes running Hive on Tez.\r\nPractical experience using Debian flavoured Linux distributions.\r\nFamiliarity with event driven development and architectures.\r\nPrevious experience using Docker containers to deploy your systems.\r\nAbility to easily navigate the administration of an HDP cluster on AWS.\r\nMust be able to index millions of documents from Hadoop into Elasticsearch.\r\nAbility to work with various messaging systems, such as Kafka and RabbitMQ.\r\nMust be able to aggregate data using Apache Kylin Cube.\r\nMust be able to easily pick up Python if you have not used it previously.\r\nAbility to operate and deploy to a Kubernetes cluster on AWS.\r\nMust be able to understand basic concepts about mortgage backed securities.\r\n\r\nTo apply use the application tool or send us an email to recruitment@parvana.co.uk"},{"JobTitle":" Data Scientists","Url":"https://www.indeed.co.za/company/vito-solutions/jobs/Data-Scientist-37c3e6ee9b7bb3fd?fccid=01e7a61c66d0697f&vjs=3","Source":" VITO Solutions","Salary":null,"Age":"5 days ago","Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\nSeniority Level\r\n\r\nMid-Senior level\r\n\r\nEmployment Type\r\n\r\nFull-time\r\n\r\nLocation\r\n\r\nJohannesburg, South Africa\r\n\r\nWe are looking for Data Scientists - both with specialist or leadership career paths, to join our collaborative, engaged and inspirational Data Science team. Are you are passionate about using data to lead problem solving and the positive impact it will have on the lives of people everywhere? Are you inspired to create and leverage the valuable insights contained in data solutions that empower positive transformation for clients and their customers? Do you have the skills and tenacity to contribute and grow towards a digital future where fact-based decisions makes a difference in the lives of others? Do you want to work with the most talented people in South Africa? Then you will love it here!\r\n\r\nMain Purpose of the Role:\r\n\r\nOur Data Science team provide critical data science and data analytics expertise and experience to help solve our clients most important business problems. You will work within multi-skilled delivery teams to design and deploy cutting edge solutions within client environments.\r\n\r\nMinimum Qualifications:\r\nHonours or Master’s Degree in Mathematical Statistics, Computer Science, Applied Mathematics, Physics, Engineering or a related field\r\nCertifications: e.g. SAS, any Big Data certifications, SCRUM / Prince2\r\n\r\nExperience:\r\n5-12 years of solving complex business and technology problems through applying data science techniques within a fast-paced project environment\r\nExperience in machine learning, deep learning, data mining, statistical methodology and demonstrated experience using these techniques to solve business problems\r\nExperience with analytics tools such as R, Python, SPSS, MATLAB and BI tools such as QlikView, PowerBI, Tableau is required\r\nExperience with deep learning tools (such as Keras, TensorFlow or Theano) and distributed computing frameworks (such as Hadoop and Spark) is a plus\r\nEvidence of leading and developing others whilst taking ownership for specific project outcomes\r\nMust possess basic project management skills such as estimation, planning and risk & issue management\r\nRelevant industries include (but are not limited to): Banking, Insurance/Assurance, Telcos, Oil & Gas, Retail, FMCG, Specialised Financial Services\r\n\r\nJob Objectives:\r\nTo help clients articulate and solve their most important business problems through the use of data, technology, domain knowledge, industry expertise and research\r\nUnderstand the impact of big data and machine data trends, as well as emerging data science technologies on our clients and their customers\r\nWork with our clients to create innovative solutions to business problems\r\nHelp clients innovate and create new business data models\r\nPersuade and influence business leaders to make the right decisions\r\nDrive the execution of key initiatives, through approach and knowledge, to support projects delivery and bring the science of data to life\r\nProfile the brand to attract talent and build further client opportunities\r\nCoach and mentor other consultants to grow skills and drive effective delivery\r\n\r\nSkills and Attributes:\r\nAble to shape the project delivery approach and lead the execution plan for designing and deploying cutting edge machine learning solutions in business environments.\r\nAble to work effectively as part of a multi-disciplinary project team, coaching and mentoring others to deliver end-to-end business solutions in a collaborative and professional manner.\r\nDeep understanding of statistical and predictive modelling concepts and machine learning approaches with practical experience assessing the accuracy of data sources and data gathering techniques. Experience working with various data architecture.\r\nAble to explain technical concepts and their real world advantages/disadvantages to a business audience.\r\nAble to build good working relationships with both internal and external stakeholders (at all levels).\r\nUnderstands and applies best practises for own work and able to influence others to improve delivery standards. Experience with Git and modern software development workflow will be a plus.\r\nExperience delivering project outcomes using design thinking, lean start-up and agile principles.\r\nNatural leadership and the ability to easily establish trust-based relationships.\r\nSkilled in gaining valuable insights through collaboration and communication.\r\nEnjoys challenging work and has the proven ability to adapt to manage change.\r\nHas an understanding of project-related commercial management for the engagement.\r\nContribute to the organisation's knowledge goals through the publication of knowledge-related articles, presentations at industry events or the advancement of knowledge management related initiatives within the organisation.\r\n\r\nJob Type: Full-time"},{"JobTitle":" PL/SQL Developer","Url":"https://www.indeed.co.za/company/iCore-Technologies/jobs/PL-SQL-Developer-2460ee6662c04b9f?fccid=ac82af8a1bb44a5d&vjs=3","Source":" iCore","Salary":null,"Age":"13 days ago","Location":"Gauteng, Gauteng","Description":"\r\n\r\n\r\nGauteng, Gauteng\r\n\r\n\r\nContract\r\n\r\nGood day\r\n\r\nWe looking for PL/SQL Developer with solid software development skills.\r\nDevelop, design, test and implement complex database programs using Oracle and third party tools.\r\nExperience with Oracle Version 10g, 11g, 12c\r\nGood knowledge in Hadoop Framework\r\nStrong experience with oracle functions, procedures, triggers, packages & performance tuning,\r\nEnsure that database programs are in compliance with V3 standards.\r\nHands on development using Oracle PL/SQL.\r\nPerformance tune SQL's, application programs and instances.\r\nEvaluation of new and upcoming technologies.\r\nProviding technical assistance, problem resolution and troubleshooting support.\r\nBanking and Telecom domain experience advantages.\r\n\r\nQualification :\r\n\r\nRelevant IT degree or Diploma.\r\n\r\nPosition Type: Contract.\r\n\r\nif you are interested suitable for this position please apply here with latest word format CV.\r\n\r\nif you not hear from iCore with in 3 weeks please consider your application for this position is unsuccessful.\r\n\r\nJob Type: Contract\r\n\r\nExperience:\r\nPL/SQL: 2 years (Preferred)"},{"JobTitle":" Qlikview Developer","Url":"https://www.indeed.co.za/company/Maheesa-Consulting/jobs/Qlikview-Developer-fbff75dbf0c67ce7?fccid=e100e3c672cb0db3&vjs=3","Source":" Maheesa Consulting","Salary":null,"Age":"30+ days ago","Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\nContract\r\n\r\nKey roles and responsibilities: \r\nParticipate in SDLC of projects\r\nDevelop models and dashboards for stakeholders\r\nStore extracted data in efficient and required formats\r\nDevelop logical data marts, cubes, reports and related data warehouse entities\r\nPerform tasks according to requirements from stakeholders\r\nEscalate project risks that arise\r\nAttend to adhoc requests for data extracts and reports\r\nRegular maintenance of existing models, dashboards and business rules\r\nAssist with operational systems support\r\nRespond promptly and professionally, placing emphasis on quality\r\nImplementation and utilization of business intelligence tools\r\n\r\nQualifications, experience and competencies required: \r\nBCom Informatics/Information Systems Degree and relevant work experience required.\r\nCertification within the BI discipline is advantageous\r\n+- 3 - 7 Years Business experience including: 3-5 years of SQL application programming\r\n3-5 years of Development SSAS, SSIS, SSRS, 3-5 years of Qlikview Development / Cube Development Skilled in: Microsoft Business Intelligence Tools QlikView / SSAS o ETL tools (Qlikview, Sagent Software, SQL, Object orientation & design, SSIS) Databases (MS SQL Server, ORACLE, HADOOP) Hardware/ Operating Systems (Windows & Linux)\r\n\r\n12 month contract\r\n\r\nJob Type: Contract\r\n\r\nExperience:\r\nQlikview: 3 years (Preferred)"},{"JobTitle":" ETL Developer","Url":"https://www.indeed.co.za/rc/clk?jk=3723d2f4ad7de8b5&fccid=456208dd78cb7bb1&vjs=3","Source":" Altron","Salary":null,"Age":"30+ days ago","Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\nContract\r\n\r\n\r\n\r\nThe ETL Developer is responsible for the design, build and deployment of a project's ETL components. A typical ETL effort usually involves multiple ETL Developers developing the Informatica mappings, executing them in native and/or pushdown mode and validating the results. These tasks involve data ingestion into Hadoop, Data Integration and Data Quality on Hadoop and Data extraction from Hadoop to external systems. \r\n\r\n\r\nJob Requirements:\r\n\r\n\r\nResponsibilities:\r\nUses the Informatica DI platform to extract data from external sources and ingest them into Hadoop.\r\nUses the Informatica Developer to perform DI operations on data within Hadoop.\r\nUses the Informatica Developer to perform DQ operations on data within Hadoop.\r\nIntegrates the Hadoop ecosystem (i.e., services such as HDFS, Hive and HBase) with other non Hadoop enterprise level technologies such as ERP and RDBMS.\r\nDevelops Data Integration workflows and load processes.\r\nEnsures adherence to locally defined standards for all developed components.\r\nPerforms data analysis for both Source and Target tables/columns including those on HDFS.\r\nProvides technical documentation of Source and Target mappings.\r\nParticipates in design and development reviews.\r\nWorks with System owners to resolve source data issues and refine transformation rules.\r\nEnsures performance metrics are met and tracked.\r\nWrites and maintains unit tests.\r\nConduct QA Reviews."},{"JobTitle":" Data Scientist","Url":"https://www.indeed.co.za/rc/clk?jk=603e9ba0015fd28e&fccid=e71cdee15c3e4b88&vjs=3","Source":" South African Monitoring and Evaluation Associatio...","Salary":null,"Age":"30+ days ago","Location":"Cape Town, Western Cape","Description":"\r\n\r\n\r\nCape Town, Western Cape\r\n\r\n\r\nOver the last two years, starting with structural changes in client management tools and the introduction of mHealth, m2m overhauled its entire routine M&E system that drives programme performance management. In order to drive optimal access to, and utilisation of m2m digital data among a broad range of internal stakeholders, m2m is looking to employ a full time Data Scientist. \r\n\r\nThe purpose of this position is to support m2m’s Research and Strategic Information function, situated within the Department of Programmes and Technical Support, through managing data and facilitating data access across multiple data sources and platforms; and through supporting data analytics and modelling as well as reporting, for improved programme management and optimal client outcomes. This position reports to the Research and Strategic Information Manager and is based at m2m Head Office in Cape Town. National / international travel may be required up to 10% of the time. \r\n\r\nKey Performance Areas \r\nUtilise multiple m2m internal data sources and identify valuable external data sources to extract and collate data for optimal programme performance analytics. \r\nUndertake pre-processing of structured and unstructured data.\r\n Automate data access processes for internal Operations Research and Routine M&E purposes. \r\nUse critical data analytics skills, as well as an ability to communicate findings, to mine vast amounts of data for useful programme performance management insights. \r\nSupport the development of / build predictive models and machine-learning algorithms.\r\n Combine models through ensemble modelling.\r\n In close collaboration with the broader RSI team - support the analysis of large amounts of information to discover trends and patterns; sift and analyse data from multiple angles, looking for trends that highlight programmatic problems or opportunities.\r\n In close collaboration with the broader RSI team and Senior Technical Advisors, propose solutions and strategies to programme enhancement challenges. \r\nPresent routine programme performance monitoring information and operations research outputs using data visualization techniques, tailored for multiple internal and external stakeholder groups.\r\n Collaborate with Senior Technical Advisors and programme development / programme management teams to improve programme delivery for optimal client outcomes and impact.\r\n\r\n Qualification and Experience\r\n A Master’s Degree in a relevant field such as Computer Science, Engineering, Data Science or other quantitative field is preferred. \r\nMinimum of 5 years’ experience as a Data Specialist / Data Analyst / Data Scientist \r\nExperience in working in a Health and Development context, in resource constrained settings – with special reference to HIV, RMNCH and ECD. • Proven experience in database querying, data mining, data analytics and data interpretation. \r\nProven understanding of machine-learning, routine M&E and Operations Research.\r\n Experience in using R, SQL and Python; familiarity with Scala, Java or C++ is an asset. \r\nExperience in using STATA is a strong recommendation. \r\nExperience using business intelligence tools (e.g. Tableau) and data frameworks (e.g. Hadoop).\r\n\r\n mothers2mothers is an equal opportunity employer. We particularly encourage applications from people living with HIV and AIDS (PLWHA), people with disabilities, women and previously disadvantaged people. Competitive salary packages will be negotiable in accordance with m2m’s remuneration policies. \r\n\r\nTo Apply: \r\nInterested applicants should apply for this position via https://www.m2m.org/careers/ by 08 July 2019"},{"JobTitle":null,"Url":"https://www.indeed.co.za","Source":" PRR Recruitment Services","Salary":" R80 000 - R90 000 a year","Age":"30+ days ago","Location":null,"Description":null},{"JobTitle":" Data Scientist","Url":"https://www.indeed.co.za/rc/clk?jk=f6374b02ed135713&fccid=2d1a4a3e36fdc9e5&vjs=3","Source":" SET Consulting","Salary":" R700 000 - R800 000 a year","Age":"6 days ago","Location":"Sandton, Gauteng","Description":"\r\n\r\n\r\nSandton, Gauteng\r\n\r\n\r\nPermanent\r\n\r\n\r\nR700 000 - R800 000 a year\r\n\r\n\r\n\r\nFinance Group with extensive opportunities seeks a Data Scientist with exceptional ability to work with, analyse and communicate findings from data\r\nDegree or Diploma in Computer or Data Science, Statstics, or related\r\n4 years min experience as a Data Scientist\r\nPredictive Modelling\r\nGood understanding of statistics and machine learning with practical experience applying these techniques\r\nCoding exposure - R or Python or similar - preferably more than one\r\nHadoop a big advantage\r\nAdvanced SQL and Excel skills\r\nIdeally experience with BI/DataViz tools (Qlikview, Power BI etc.)"},{"JobTitle":" Full Stack Developer","Url":"https://www.indeed.co.za/rc/clk?jk=6feec92ab84721e1&fccid=3549c41f3cdd1c48&vjs=3","Source":" Ntice Search Solutions","Salary":null,"Age":"30+ days ago","Location":"Durban, KwaZulu-Natal","Description":"\r\n\r\n\r\nDurban, KwaZulu-Natal\r\n\r\n\r\nPermanent\r\n\r\n\r\n\r\nOur client in Durban is looking for a Full Stack Developer to develop and maintain industry leading software systems. You’ll be working on all aspects of the product, from its core infrastructure and back-end, to its custom front-end as well as be required to see out a project from conception to final product, requiring good organizational skills and attention to detail.\r\n\r\n\r\nThe ideal person for this role is a problem-solver and creative programmer with a passion for software development and the ability to propose new technology, creative solutions and product ideas to solve business problems and drive the company forward. Applicants are accepted nationally should you want to relocate to Durban.\r\n\r\n\r\n\r\n Key duties include:\r\nDesign, build, develop and maintain software solutions\r\nDevelop server-side and client-side code\r\nDevelop mobile applications\r\nSystems analysis and design\r\nTechnical support\r\nDrive quality assurance\r\nWriting of technical documents\r\nSystems programming, testing and implementation\r\nOffering staff support and training\r\n\r\n\r\n\r\n\r\nRequirements:\r\nIT-related degree or diploma\r\n5 – 8 years software development experience\r\n\r\nTechnical skills:\r\nC#\r\nASP.NET MVC\r\nAzure\r\nJavaScript\r\nTypeScript\r\nReact, Redux, Webpack\r\nReact Native\r\nHTML5\r\nCSS / LESS\r\nSQL\r\nMongoDB\r\nHadoop\r\nDesign Patterns"},{"JobTitle":" Senior Engineer (Machine Learning)","Url":"https://www.indeed.co.za/rc/clk?jk=2e3b050b373de4a2&fccid=18e55bdd723f22a0&vjs=3","Source":" Recruit Digital","Salary":" R800 000 - R1 300 000 a year","Age":"30+ days ago","Location":"Cape Town, Western Cape","Description":"\r\n\r\n\r\nCape Town, Western Cape\r\n\r\n\r\nR800 000 - R1 300 000 a year\r\n\r\n\r\nWe are looking for talented developers to build out the best damn big data team in Africa.\r\n\r\n Note that this is not a data science position and that it requires building large-scale, production-grade software systems that applies machine learning in practice, including the training of machine learning models. \r\n\r\nYou will:\r\nWork with a firehose of data\r\nBuild state-of-the-art statistical models\r\nTouch all aspects of the business\r\nBrainstorm new ideas and concepts\r\nWork with teammates on design, and code reviews\r\nBuild real time systems that integrate with the rest of our stack\r\n\r\nWe expect you to:\r\nBe creative\r\nBe flexible\r\nUse the data, Luke\r\nAnd take pride in your work\r\n\r\nMinimum requirements\r\nComputer Science degree (alternatively a degree in a related field with work experience as a software engineer)\r\nStrong Mathematical or Statistical experience\r\n\r\nStandard requirements\r\nPython experience\r\nLinux experience\r\nCommercial software experience\r\nExperience with Hadoop/Spark/R\r\nMachine Learning / Data Mining / Big Data experience\r\nMSc (or even PhD) in a related field\r\n\r\nThe Environment:\r\ntakealot.com employees are entrepreneurial and dynamic, smart, customer-centric, fun and have the shared ambition of takealot.com being the leading e-commerce company in Africa\r\nWe have fun, work hard, take ownership, work in teams to create solutions, and are always open to direct feedback/new ideas on where we can improve\r\nWe are short on ego and high on output\r\nWe are doers and not only thinkers, its all in the execution after all\r\nWe love what we do and what we are creating\r\n\r\nThe Team:\r\nA small, highly skilled team (2x PhDs and 1x MSc-in-progress)\r\nA high degree of autonomy\r\nMaintains links with academia"},{"JobTitle":" Senior Developer (Hadoop)","Url":"https://www.indeed.co.za/rc/clk?jk=c7439fd2588f5ee6&fccid=8be9194f6737a183&vjs=3","Source":" Evolution Consulting","Salary":null,"Age":"30+ days ago","Location":"Randburg, Gauteng","Description":"\r\n\r\n\r\nRandburg, Gauteng\r\n\r\n\r\n\r\nJob No: 12547\r\nSenior Developer (Hadoop)\r\nType: Contract\r\nLocation: Randburg\r\n\r\n Description:\r\n\r\nDeveloper with 5-7 years’ experience of the following:\r\n Interaction with end users to gather requirements, Interpretation and write up of business requirements, technical documents and program specifications, Requirement analysis and component design including detailed design and resolving design issues, Impact analysis of change requests and issues/incidents, and identification of solutions, including creation of appropriate documentation. Planning and monitoring defect prevention activities. Implementing and managing quality assurance processes, Software development and configuration. Creation and validation of test plans. Providing direction and guidance to a team of developers, including allocation and management of workload. Conducting code reviews.\r\n Experience in Big Data (Hadoop)\r\n Have worked with Mainframe Development\r\n Have worked with ETL\r\n Understanding of the BCBS239/ RDARR"},{"JobTitle":" Data Architect","Url":"https://www.indeed.co.za/rc/clk?jk=711c8ad191e9f305&fccid=cbb2b0ca1f03a69c&vjs=3","Source":" Nambiti Technologies","Salary":null,"Age":"30+ days ago","Location":"Centurion, Gauteng","Description":"\r\n\r\n\r\nCenturion, Gauteng\r\n\r\n\r\nContract\r\nLooking for a Data Architect for one of our projects. \r\n\r\n\r\n\r\n\r\n\r\n\r\nBachelor’s degree\r\n equivalent experience.\r\n 5+ years of experience in Data Architecture, with emphasis on dimensional modelling\r\n Specific Expertise Required\r\n Strong problem solving and data modeling expertise.\r\n Solid coaching and listening skills.\r\n Strong communication skills.\r\n Excellent SQL development skills, ideally with more than one DBMS. Up to date on current SQL best practices, new features and capabilities, such as analytical functions and advanced\r\n capability such as partitioning features, etc.\r\n Knowledge of Big data ETL and Hadoop technologies\r\n Strong Linux skills\r\n Fair knowledge of database administration.\r\n Extensive experience at least with one ETL tool.\r\n Good understanding of Database scalability techniques and Parallel ETL flows.\r\n Good understanding of data warehouse life cycle, Software development life cycle\r\n\r\n\r\n\r\n\r\nAd visible until: 31 December 2019"},{"JobTitle":" Test Engineer","Url":"https://www.indeed.co.za/rc/clk?jk=97a45c06c9eeca81&fccid=870ac557f2faef88&vjs=3","Source":" iLAB (Pty) Ltd","Salary":null,"Age":"30+ days ago","Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\n\r\niLAB is looking for Informatica and Hadoop developers who are ready to assist in maturing a test strategy under the lead of a test manager.\r\n\r\nAssisting with the test strategy which involves Automation and Regression testing within an Agile team. The role also involves working alongside the Test Manager to define the test strategy.\r\n\r\n\r\n\r\nExperience required:\r\nExtensive experience working with Big Data\r\nExtensive Hadoop or Informatica development experience\r\nExtensive understanding and experience working with data and various formats i.e CSV, XML, JSON, AVRO, Parquet\r\nMainframe copybooks experience is beneficial\r\nSolid understanding of data flow, data query languages (TSQL and HIVESql)\r\nETL experience preferably Informatica, BDD or BDM\r\nSolid experience scripting on HDFS i.e Scala on Spark and Java"},{"JobTitle":" Data Scientist","Url":"https://www.indeed.co.za/rc/clk?jk=83aa4a1c5d4cd67f&fccid=dd616958bd9ddc12&vjs=3","Source":null,"Salary":" R600 000 a year","Age":"24 days ago","Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\nPermanent\r\n\r\n\r\nR600 000 a year\r\nA very nice tech shop is looking for driven, intelligent data scientists to join their business. They offer no dress-codes, flexible working hours, the latest workstation of your choice, and occasional remote work. \r\n\r\n Reference Number for this position is MH45892. This is permanent role based in Illovo offering up to R600k per annum based on experience, skillset and current level. Contact Michelle on michelle@e-merge.co.za , at www.e-merger.co.za . \r\n\r\n Are you ready for a change of scenery? e-Merge IT recruitment is a niche recruitment agency. We offer our candidates options so that we can successfully place the right people with the right companies, in the right roles. Check out the e-Merge IT website for more great positions. \r\n\r\n Do you have a friend who is a developer or technology specialist? We pay cash for successful referrals! \r\n\r\n REQUIREMENTS \r\n\r\n Top achievers when it comes to their degree results \r\nHonours degrees and higher are preferred in computer science/physical sciences/statistics/mathematics/engineering/big data \r\nTwo+ years’ experience in the capacity of data scientist \r\nExperience in R, Python, Hadoop, machine learning algorithms, Spark (Pyspark) and more"},{"JobTitle":" Data Scientist","Url":"https://www.indeed.co.za/rc/clk?jk=339d1d027a90ca5b&fccid=50a816ef18fe262a&vjs=3","Source":" Network Recruitment","Salary":" R600 000 - R800 000 a year","Age":"20 days ago","Location":"Johannesburg North, Gauteng","Description":"\r\n\r\n\r\nJohannesburg North, Gauteng\r\n\r\n\r\nR600 000 - R800 000 a year\r\n\r\n\r\n\r\n\r\nJob Description:\r\n\r\n\r\n\r\n\r\nYou will design, develop, maintain and support projects using a variety of Big Data/Data Science technologies. You will use machine learning techniques, data mining, do ad-hoc analysis and create automated anomaly detection systems as well as dashboards, reports and visualisations.\r\n\r\n\r\n\r\n Education:\r\nMatric\r\nBSc Honours Computer Science / Engineering is mandatory.\r\nMasters or Doctoral degree is preferred\r\n\r\n\r\n\r\n\r\nJob Experience & Skills Required:\r\n4-5 years’ experience in a comparable environment\r\nVery strong analytical, communication and negotiation skills\r\nData Science (essential)\r\nAI and ML experience (essential)\r\nR, Weka, NumPy, MatLab (essential)\r\nExcellent understanding of machine learning techniques and algorithms such as k-NN, Naïve, SVM\r\nJava\r\nPython\r\nHTML\r\nJavaScript\r\nLinux shell scripting\r\nNodeJS\r\nMSSQL\r\nMySQL\r\nMongoDB\r\nElasticSearch\r\nCassandra\r\nHDFS, Hadoop, Hbase\r\n\r\n\r\n\r\n\r\nApply now!\r\n\r\n\r\nEmail your cv to : Nbhana@networkrecruitment.co.za\r\n\r\n\r\nIf you have not had any response in two weeks, please consider the vacancy application unsuccessful. Your profile will be kept on our database for any other suitable roles / positions.\r\n\r\n\r\n\r\nFor more information contact:\r\n\r\nNikita Bhana\r\n\r\nIT Recruitment Consultant"},{"JobTitle":" Senior Java Developer","Url":"https://www.indeed.co.za/rc/clk?jk=98a2f703bfd60764&fccid=47dd9490344df939&vjs=3","Source":" Tumaini Consulting","Salary":" R600 000 - R720 000 a year","Age":"30+ days ago","Location":"Cape Town, Western Cape","Description":"\r\n\r\n\r\nCape Town, Western Cape\r\n\r\n\r\nR600 000 - R720 000 a year\r\nUrgently seeking a Senior Java Developer based in or willing to relocate to Cape Town \r\n\r\nRequirements:\r\nTechnologies\r\nJava\r\nSource Control\r\nMavin / Gradle etc\r\nJenkins / Hudson / Bamboo / Travis CI or similar\r\nOracle RDMS / PostgreSQL / MySQL / Hadoop\r\nExposure to cloud computing\r\nShould you meet the requirements for this position, please email your CV to it.jobs@tumaini.co.za . You can also contact Jaydene on 031 350 4018 or visit our website www.tumaini.co.za .Correspondence will only be conducted with short listed candidates. Should you not hear from us within 3 days, please consider your application unsuccessful."},{"JobTitle":" Senior Java Developer","Url":"https://www.indeed.co.za/rc/clk?jk=5783bb32aeb21f43&fccid=399f716a0307ef50&vjs=3","Source":" Communicate Recruitment","Salary":" R800 000 - R900 000 a year","Age":"2 days ago","Location":"Johannesburg North, Gauteng","Description":"\r\n\r\n\r\nJohannesburg North, Gauteng\r\n\r\n\r\nR800 000 - R900 000 a year\r\n\r\n\r\n\r\nSenior Java Developer\r\n\r\n\r\n\r\nRef. No:\r\n\r\nCER008247/TKE\r\n\r\n\r\n\r\nSalary Range:\r\n\r\nR800000 - R900000 Annually\r\n\r\n\r\n\r\nBrief Description:\r\n\r\nBeing a Specialist recruiter within the IT sector, my clients are always on the lookout for exceptionally talented. Your backend coding skills on the .net framework and Java skills together with a stable working track record will not go unnoticed within some of the top clients. \r\n\r\n\r\n\r\nJob Description:\r\n\r\n\r\nEducation: \r\nBachelor degree in related field or comparable experience in the web development required. Substantial experience working with similar technologies and environment\r\nMinimum 6 years’ experience using Java\r\nMust have a good grasp of design principles (Solid, GOF Patterns and etc)\r\nFamiliarity with various design and architectural patterns\r\nFamiliarity with standard SDLC process and Agile/Scrum Methodology\r\nImplementing automated testing platforms and unit tests\r\nFamiliarity with versioning control tools {{such as Git, TFS and etc}}\r\nMust be able to design, develop, troubleshoot, and debug systems and their various integration points\r\nGood knowledge in writing SQL scripts, stored procedures and database design\r\nFamiliarity with Microsoft SQL Server 2008/12/14\r\nKnowledge of TeamCity a plus\r\nKnowledge of SSIS development a plus\r\nExposure to Non-Microsoft DB technologies a plus (MySQL, MongoDB, Hadoop etc.)\r\n\r\n\r\n\r\n\r\nSkills:\r\nDisplay an attitude of innovation\r\nDedicated and committed to achieving results\r\nSelf-motivated\r\nAble to adapt to change quickly\r\nConvey a professional image\r\nBe able to work under pressure\r\nStrong analytical and problem solving\r\nExperience working in a team-oriented, collaborative environment\r\nExcellent written and oral communication skills\r\nPresenting & Communicating Information (Familiar with)\r\n\r\n\r\n\r\n\r\nDescription:\r\nTo translate, design, build bespoke applications given a set of requirements\r\nTo assist business during QA testing, resolving bugs and issues as their being discovered Frequent communication with colleagues and management\r\nCollaborate with IT/Business for any technical assistance required Integrating data from various back-end services and databases\r\nPerform website analysis and diagnostics according to planned schedules or after any website or product revisions\r\nDiagnose production issues and provide assistance to production support staff (2nd level support) Stay plugged into emerging technologies/industry trends and apply them into operations and activities\r\nEnsure work done adheres to quality guidelines and standards for all activities (e.g. naming conventions, code comments) as agreed in the team Be responsible for maintaining, expanding, and scaling all Universal sites\r\n\r\n\r\n\r\n\r\nPlease visit our website www.communicate.co.za to submit your CV directly or to view other I.T related jobs. If you have not had any response in two weeks, please consider your application unsuccessful. Your profile will be kept on our database for any other suitable positions.\r\n\r\n\r\n\r\nWe also invite you to contact us to discuss other exciting career opportunities in our niche area! For more information, please call Thato Kekana on 087 351 0711 or email on thkekana@communicate.co.za\r\n\r\n\r\nSector:\r\n\r\nDevelopment and Programming\r\n\r\n\r\nTown:\r\n\r\nJohannesburg North\r\n\r\n\r\nDate:\r\n\r\n01/08/2019\r\n\r\n\r\nExpiry Date:\r\n\r\n31/08/2019"},{"JobTitle":" Senior SQL Developer","Url":"https://www.indeed.co.za/rc/clk?jk=ea4e5be99559e9f3&fccid=8be9194f6737a183&vjs=3","Source":" Evolution Consulting","Salary":null,"Age":"30+ days ago","Location":"South Africa","Description":"\r\n\r\n\r\nSouth Africa\r\n\r\n\r\n\r\nJob No: 12409\r\nSenior SQL Database Administrator\r\nCape Town\r\nRate: Dependent upon experience\r\n12 month contract\r\n\r\nRole Purpose:\r\n\r\n Responsible for defining, maintaining, implementing and optimizing the architecture and processes of the product and platforms required to meet business goals and objectives.\r\n\r\nResponsibilities and work outputs:\r\n Operations:\r\n General DBA tasks\r\n Design and build for high availability; recoverability;\r\n Develop database processes and solutions as it pertains to IT architecture\r\n Performance tuning ; SQL; IO; CPU; Memory\r\n Maintain required documentation.\r\n Windows commands and scripting\r\n After hours standby support\r\n Service Excellence:\r\n Proactively manage the environment to honour required service levels\r\n Build and maintain healthy collaborative partnerships with relevant stakeholders\r\n\r\n Competencies required:\r\n Demonstrate the following skills:\r\n Action Orientation\r\n Attention to Detail\r\n Communicate effectively (Verbal & Written)\r\n Conflict handling\r\n Client service orientation\r\n Effective planning & Time management\r\n Show innovative thinking\r\n Able to:\r\n Understand existing systems and technology\r\n Understand business practices and approaches\r\n Apply procedures, tools and methods\r\n Design technical architecture\r\n Work effectively in a team\r\n\r\n Experience and Qualifications:\r\n Minimum of 5 years relevant experience.\r\n MS Certification in SQLServer or similar.\r\n Excellent working knowledge of SQLServer\r\n SQL performance tuning; Log Shipping; Backup/Recovery.\r\n Good knowledge of SSAS; SSRS; SSIS.\r\n Good knowledge of relational and document store databases.\r\n Excellent working knowledge of Windows OS.\r\n Good knowledge of storage sub-systems, identifying and resolving IO bottlenecks.\r\n Experience with configuring monitoring & automation tools, like CheckMK; Nagios; Jenkins; TICK; ELK; Grafana.\r\n Ability to support and liaise with business process owners to optimize their processes.\r\n Must be able to work collaboratively with other areas to advocate good application development techniques.\r\n Must possess a high degree of initiative, motivation, and problem-solving skills.\r\n Experience with design of high availability & recoverability environments.\r\n\r\n Product Specific Knowledge:\r\n Advanced SQL Server database administration.\r\n High Availability; Backup/Recovery; Performance Tuning.\r\n SSAS; SSRS; SSIS.\r\n Installation & configuration.\r\n Automation / monitoring tools configuration.\r\n Experience and Knowledge in PostgreSQL, Hadoop, MongoDB will be an added advantage."},{"JobTitle":" AI consultant","Url":"https://www.indeed.co.za/company/Cape-Town-AI/jobs/Ai-Consultant-481a17ada9be2acb?fccid=d65a989c7c3f0b80&vjs=3","Source":" Cape Town AI","Salary":null,"Age":"30+ days ago","Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\nExpertise fields:\r\nData science\r\nData engineering\r\nData strategist\r\n\r\nRequired entry level:\r\n\r\nUniversity Graduate with at least 2+ years experience as a data scientist/engineer/strategist.\r\n\r\nVery proficient in at least one programming language (preferably Python). Lots of hands-on experience with building machine learning models, handling SQL databases and scaling to big data sets (spark / hadoop etc). Devops skills such as working with git / virtual machines in the cloud etc. Being able to understand and explainthe mathematics and statistics behind machine learning algorithms. If you don't meet these criteria please consider applying for our AI High potential program instead.\r\n\r\nDo you have 2+ years of industry experience in one of the above expertise fields, a passion for AI and a drive to make an impact for society, we are looking for you! As a senior consultant you can work both on internal studies and client projects. We also stimulate you to participate in trainings, hackathons & conferences and to share your knowledge via articles and our Friday AI High Potentials training sessions. Please get in touch to discuss the possibilities!\r\n\r\nJob Type: Full-time"},{"JobTitle":" Technical Account Manager / Enterprise Engineer - Amazon Web...","Url":"https://www.indeed.co.za/rc/clk?jk=5fb69edae5ce5325&fccid=fe2d21eef233e94a&vjs=3","Source":" Amazon Dev Centre South Africa","Salary":null,"Age":"30+ days ago","Location":"Cape Town, Western Cape","Description":"\r\n\r\n\r\nCape Town, Western Cape\r\n\r\n5+ years design/implementation/operations/consulting experience of distributed applications or equivalent experience\r\n2+ years hands-on systems administration / networking / troubleshooting\r\nPrevious customer facing experience as a technical lead\r\nExceptional customer focus and bias for action\r\nCandidates must have excellent oral and written communication skills\r\nBachelor’s degree required; Computer Science or Math background highly desired; working knowledge of software development practices and technologies highly desired\r\nBe mobile and travel to client locations as needed\r\nDeep experience in one or more of the following areas:\r\no Software design or development\r\n o Content Distribution / CDN\r\n o Scripting / Automation\r\n o Database Architecture\r\n o IP Networking\r\n o IT Security\r\n o BigData / Hadoop\r\n o Systems Administration (Linux and/or Windows)\r\n o Operations Management\r\n o Service Oriented Architecture\r\n\r\nAs an increasing number of large enterprises move their critical systems to the cloud, we are in need of highly-skilled technical talent to help our largest customers navigate the operational challenges of cloud computing. You will work one-on-one with our top-tier customers, supporting both the software development lifecycle for cloud services and management of active services.\r\n\r\n In this role, you will have the opportunity to help shape and execute a strategy to build mindshare and broad use of Amazon Web Services (including Amazon EC2, Amazon S3, Amazon DynamoDB & RDS databases, Amazon CloudFront CDN, and many more) within organizations ranging from new start-ups to large enterprise customers.\r\n\r\n You must possess customer facing skills that enable you to represent AWS well within a customer’s environment and drive discussions with senior personnel regarding incidents, trade-offs, best practices, and risk management.\r\n You should also have a demonstrated ability to think strategically about business, product, and technical challenges as you help our customers take advantage of the efficiencies, cost savings and quick innovation available only in the cloud.\r\n\r\n As an Enterprise Support Engineer, you will be the primary technical point of contact for one or more customers helping to plan, debug, and oversee ongoing operations of business critical applications.\r\n You will get your hands dirty, troubleshooting application, network, database, and architectural challenges using a suite of internal AWS tools as well as your existing knowledge and toolkits.\r\n You will work hand-in-hand with senior executives on opportunities to improve your customers’ IT landscape. You will work across customer organizations to ensure customers’ applications are well designed and scale to the needs of the world’s largest events e.g., the Super Bowl, the World Cup and the Olympics. In this role, you will also act as the voice of the customer within AWS to escalate problems and to drive prioritization of business needs for our customers.\r\n\r\n Every day will bring new and exciting challenges on the job while you:\r\n\r\nEngage with Director and C-Level executives to understand business needs\r\nAssist in Design/Architecture of AWS and hybrid cloud solutions\r\nHelp Enterprises define IT and business processes that work well with cloud deployments\r\nWork hands-on with customer engineering teams to develop, migrate, and debug application issues\r\nTroubleshoot technical issues and drive issue escalation with AWS Service teams\r\nLeverage knowledge of your customers’ environments to assist support engineers and service teams in better serving your customers\r\nComplete analysis and present periodic reviews of operational performance to customer leadership\r\nProvide detailed reviews of service disruptions, metrics, detailed prelaunch planning\r\nMake recommendations on how new AWS offerings fit in the company architecture\r\nChampion and advocate for customer requirements within AWS (be their voice)\r\nParticipate in customer requested meetings (onsite or via phone)\r\nKnow and use all key customer resolution tools across all service groups to facilitate rapid resolution of customer concerns\r\nParticipate in deep architectural discussions to ensure solutions are designed for successful deployment in the cloud\r\nWork with some of the leading technologists around the world\r\nWork directly with Amazon Web Service engineers to ensure that customer issues are resolved as expediently as possible\r\n\r\n\r\n10+ years IT/Technical Industry experience\r\nExperience with AWS service offerings\r\nExperience working directly with Enterprise customers\r\nMBA or advanced degree\r\nTechnical Program or Project Management experience\r\nAbility to manage multiple tasks and projects in a fast-moving environment\r\nDemonstrated ability to adapt to new technologies and learn quickly\r\nPresentation skills; high degree of comfort with both large and small audiences\r\nStrong written communication skills; this role will require the creation of content such as whitepapers and other written deliverables\r\nHigh level of comfort communicating effectively across internal and external organizations\r\nWorking knowledge of development methodologies in one or more than of the following languages:\r\no .NET\r\n o C++\r\n o Java\r\n o PHP\r\n o Perl\r\n o Python\r\n o Ruby on Rails"},{"JobTitle":" Data Exchange: Platform Engineer (DBA/Site Reliability Engin...","Url":"https://www.indeed.co.za/rc/clk?jk=d2bc97b17b22210a&fccid=77748257c144323d&vjs=3","Source":" e-Merge IT Recruitment","Salary":" R900 000 a year","Age":"12 days ago","Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\nR900 000 a year\r\n\r\n\r\nDescription\r\n\r\n\r\nWe are on the lookout for a DBA/Site Reliability Engineer for a solid development team for one of our clients. Their belief in innovation drives them to deliver exceptional services and solutions for their clients.\r\n\r\nYou will be exposed to data Engineering, Data Curation, Data Management, API and Micro Services, helping the business shape their cloud journey and assist in building the data fabric in Group and across multiple African countries. APPLY NOW!\r\n\r\n Requirements:\r\n SQL Server 2016 and 2017 (ESSENTIAL)\r\n Senior SQL Server platform administration\r\n Strong DBA and development background in operational data platforms\r\n DevOps/SRE (Site Reliability Engineer) background\r\n Automation, DevOps, optimization of SQL queries and planning platform management.\r\n Cloud Data platforms/database background will be an advantage\r\n IT Architecture\r\n Data Integrity\r\n IT Application\r\n Data Analysis\r\n\r\n Responsibilities:\r\n Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases\r\n Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.\r\n Create data tools for analytics and data scientist team members that assist them in building and optimizing\r\n Monitor the existing metrics, analyze data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements.\r\n Developing ETL processes that convert data into formats through a team of data analysts and dashboard charts. Oversee large-scale data Hadoop platforms and to support the fast-growing data within the business.\r\n Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements\r\n\r\n Reference Number for this position is LV46375 which is a permanent position based in Johannesburg offering up to R900k per annum negotiable on experience and ability. Contact Liza on lizavdb@e-merge.co.za or call her on 011 463 3633 to discuss this and other opportunities.\r\n\r\nAre you ready for a change of scenery? The e-Merge IT recruitment is a specialist niche recruitment agency. We offer our candidates options so that we can successfully place the right developers with the right companies in the right roles.\r\n\r\nDo you have a friend who is a developer or technology specialist? We pay cash for successful referrals!"},{"JobTitle":" SENIOR JAVA SCALA BIG DATA DEVELOPER","Url":"https://www.indeed.co.za/rc/clk?jk=6c35dd7a0bd72a06&fccid=77748257c144323d&vjs=3","Source":" e-Merge IT Recruitment","Salary":null,"Age":"11 days ago","Location":"Sandton, Gauteng","Description":"\r\n\r\n\r\nSandton, Gauteng\r\n\r\n\r\nDescription\r\n\r\n\r\nSandton based opportunity allowing you to enhance your Big Data skills whilst gaining experience in the investment banking sector. They are typically a cloud based, huge volume, low latency business, problem solving across Africa for Africans.\r\n\r\nThey are ideally looking for a Java, Scala, Big Data skilled person who will be involved in building software services for Big Data Teams. If you are a keen problem solver and a GURU in the Software Engineering space – this may be a great option to consider.\r\n\r\n Nice to haves:\r\nRelevant tertiary qualification in Engineering or Computer Science\r\nJava development - at least 5 years minimum.\r\nSpark development experience\r\nScala development experience\r\nBig Data experience on the Hadoop and KAFKA technologies.\r\n\r\n Requirements:\r\nHands on Delivery skills with strategic thinking\r\nStrong JAVA Dev experience\r\nAny OO Tech background – C# OR Java (J2EE OR JEE) OR C++ OR Functional OR Ruby OR Mean Stack\r\nSome Functional Programming experience and or motivation to be involved in Functional Programming\r\nBackground in Designing and building Distributed systems\r\nHighly educated with strong technology opinions\r\nAgile – Scrum\r\nCI / CD / DevOps etc.\r\n\r\n Additional nice to have:\r\nFunctional Dev – Scala / C# / Haskell / Clojure etc.\r\nAdvanced JavaScript\r\nMicro Services Architecture\r\nCloud – Amazon, Azure or similar\r\n\r\nReference Number for this position is GZ42079 which is a permanent position based in Sandton offering a cost to company salary of up to R900k per annum, negotiable on experience and ability. Contact Garth on garthz@e-merge.co.za or call him on 011 463 3633 to discuss this and other opportunities.\r\n\r\nAre you ready for a change of scenery? The e-Merge IT recruitment is a specialist niche recruitment agency. We offer our candidates options so that we can successfully place the right developers with the right companies in the right roles.\r\n\r\nDo you have a friend who is a developer or technology specialist? We pay cash for successful referrals!"},{"JobTitle":" C# Developer","Url":"https://www.indeed.co.za/rc/clk?jk=9aa36fe51ce2c028&fccid=399f716a0307ef50&vjs=3","Source":" Communicate Recruitment","Salary":" R450 000 - R550 000 a year","Age":"6 days ago","Location":"Johannesburg North, Gauteng","Description":"\r\n\r\n\r\nJohannesburg North, Gauteng\r\n\r\n\r\nR450 000 - R550 000 a year\r\n\r\n\r\n\r\nC# Developer\r\n\r\n\r\n\r\nRef. No:\r\n\r\nCER008229/TKE\r\n\r\n\r\n\r\nSalary Range:\r\n\r\nR450000 - R550000 Annually\r\n\r\n\r\n\r\nBrief Description:\r\n\r\nAn exciting opportunity with one South Africa's leading banks Is looking for an individual who will be responsible for development, enhancement and maintenance of all Post Trade vendor and bespoke application suites that fall within the Markets business area \r\n\r\n\r\n\r\nJob Description:\r\n\r\n\r\nEducation: \r\nBachelor degree in related field or comparable experience in the web development required. Substantial experience working with similar technologies and environment\r\nMinimum 3 years experience using .NET technology stack such as (Web API, MVC, .NET4.5, .NET Core, WCF, Unity ,Angular)\r\nMust have a good grasp of design principles (Solid, GOF Patterns and etc)\r\nFamiliarity with various design and architectural patterns\r\nFamiliarity with standard SDLC process and Agile/Scrum Methodology\r\nImplementing automated testing platforms and unit tests\r\nFamiliarity with versioning control tools {{such as Git, TFS and etc}}\r\nMust be able to design, develop, troubleshoot, and debug systems and their various integration points\r\nGood knowledge in writing SQL scripts, stored procedures and database design\r\nFamiliarity with Microsoft SQL Server 2008/12/14\r\nKnowledge of TeamCity a plus\r\nKnowledge of SSIS development a plus\r\nExposure to Non-Microsoft DB technologies a plus (MySQL, MongoDB, Hadoop etc.)\r\n\r\n\r\n\r\n\r\nSkills:\r\nDisplay an attitude of innovation\r\nDedicated and committed to achieving results\r\nSelf-motivated\r\nAble to adapt to change quickly\r\nConvey a professional image\r\nBe able to work under pressure\r\nStrong analytical and problem solving\r\nExperience working in a team-oriented, collaborative environment\r\nExcellent written and oral communication skills\r\nPresenting & Communicating Information (Familiar with)\r\n\r\n\r\n\r\n\r\nDescription:\r\nTo translate, design, build bespoke applications given a set of requirements\r\nTo assist business during QA testing, resolving bugs and issues as their being discovered Frequent communication with colleagues and management\r\nCollaborate with IT/Business for any technical assistance required Integrating data from various back-end services and databases\r\nPerform website analysis and diagnostics according to planned schedules or after any website or product revisions\r\nDiagnose production issues and provide assistance to production support staff (2nd level support) Stay plugged into emerging technologies/industry trends and apply them into operations and activities\r\nEnsure work done adheres to quality guidelines and standards for all activities (e.g. naming conventions, code comments) as agreed in the team Be responsible for maintaining, expanding, and scaling all Universal sites\r\n\r\n\r\n\r\n\r\nPlease visit our website www.communicate.co.za to submit your CV directly or to view other I.T related jobs. If you have not had any response in two weeks, please consider your application unsuccessful. Your profile will be kept on our database for any other suitable positions.\r\n\r\n\r\n\r\nWe also invite you to contact us to discuss other exciting career opportunities in our niche area! For more information, please call Thato Kekana on 087 351 0711 or email on thkekana@communicate.co.za\r\n\r\n\r\nSector:\r\n\r\nDevelopment and Programming\r\n\r\n\r\nTown:\r\n\r\nJohannesburg North\r\n\r\n\r\nDate:\r\n\r\n28/07/2019\r\n\r\n\r\nExpiry Date:\r\n\r\n27/08/2019"},{"JobTitle":" Data Solutions Architect","Url":"https://www.indeed.co.za/rc/clk?jk=4092344e64d22a01&fccid=e88e1dbf2e5f2b6e&vjs=3","Source":" Tracking Talent","Salary":null,"Age":"30+ days ago","Location":"Cape Town, Western Cape","Description":"\r\n\r\n\r\nCape Town, Western Cape\r\n\r\n\r\nPermanent\r\n\r\n\r\n\r\nSOLUTIONS ARCHITECT\r\n\r\n\r\nA leading Asset Manager is looking for a data professional to join their team.\r\n\r\n What will you do?\r\nData and Information Asset Management\r\nDevelop, implement and manage the processes and mechanisms for classifying data and information assets in terms of its purpose, sensitivity and quality as well as the level of access control and protection applicable to it.\r\nData Profiling and Data Quality Management\r\nDevelop, implement and manage the processes to assess data quality and diagnose and report issues for correction. Using data profiling and data quality monitoring & reporting tools, measure completeness, timeliness, accuracy, consistency, relevance and integrity, ensuring data is fit for its intended uses on the BI platform.\r\nReference Data Management\r\nDevelop, implement and manage the processes for reference data on the BI platform as a special subset of master data that's used for classification throughout the organisation. This includes reference data that is externally mandated or internally authored.\r\nMetadata Management\r\nDevelop, implement and manage the processes for metadata (i.e. data about data) associated with the data on the BI platform. Develop and implement the end-to-end governance framework and model for creating, controlling and enhancing metadata on the BI platform.\r\nData Lineage Management\r\nDevelop, implement and manage the processes that track the life-cycle of data on the BI platform from ingestion through to consumption as well as how it changes over time (Data lineage tracking is required for master data, reference data, transactional data and metadata on the BI platform.)\r\nDevelop physical data management architectures, policies, and practices and oversee the execution of procedures to manage data across its lifecycle on the BI platform from acquisition to consumption.\r\n\r\nWhat will make you successful in this role?\r\n\r\nRelevant Data system experience in warehousing, ETL, Reporting, Management Reporting, Business Intelligence implementations, migrations and technology selection\r\nRelevant experience delivering business solutions using applicable technology\r\nUnderstanding of data flow from a technical and business perspective from source to output though Information management systems such as Data Warehouses and Data transformation hubs\r\nUnderstanding of Information Architecture domain (e,g DAMA / DMBOK)\r\nDefine data management policies for governance purposes\r\nAbility to balance agility with risk in policy setting\r\nUnderstanding of enterprise implications of data policy as it relates to other policy domains: Security, Regulatory, Legal, Tax and Channel conflict\r\nExperience in warehousing, ETL, Reporting, Management Reporting, Business Intelligence implementations, migrations and technology selection\r\nExperience with Cloudera, HANA, Teradata would be preferential\r\nDemonstrated competence in business domain analysis, data warehousing (design and operations), and database design\r\nDemonstrated competence with benefits, design and management of structured and unstructured content and databases / repositories (SQL, NoSQL, HDFS/Hadoop distributions, etc.) and hands-on experience with specific products\r\nDemonstrated competence with Microsoft SQL Server, Oracle DBMS, SAP Business Objects, and related tools is valued\r\nWorking knowledge and understanding of benefits and positioning of data virtualization\r\nWorking knowledge of data science, data mining, OLAP programming, database management and programming, business process modelling and analysis\r\nWorking knowledge of statistical computing and graphics programming languages (R, Python, etc.)\r\nWorking knowledge of open source or commercial data visualization tools (PowerBI, BobJ, Tableau, Qlikview)\r\nWorking knowledge of cloud-based offerings and vendor differentiation related to analytics and information processing capabilities (AWS, Azure)\r\n\r\nQualification and Experience\r\n\r\nDegree or Diploma with 8 to 10 years related experience.\r\n\r\nKnowledge and Skills\r\n\r\nData Analysis\r\nProject Management\r\nBusiness Requirements Definition\r\nNew Technology Research\r\nReporting and Administration"},{"JobTitle":" Data Scientist","Url":"https://www.indeed.co.za/rc/clk?jk=810352e1744ef4d8&fccid=75800947701c95ac&vjs=3","Source":" NETWORK IT BRUMA","Salary":" R600 000 a year","Age":"19 days ago","Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\nR600 000 a year\r\n\r\n\r\nJob & Company Description:\r\n\r\nYou will design, develop, maintain and support projects using a variety of Big Data/Data Science technologies. You will use machine learning techniques, data mining, do ad-hoc analysis and create automated anomaly detection systems as well as dashboards, reports and visualisations.\r\n\r\n\r\n\r\n Education:\r\n Matric\r\n BSc Honours Computer Science / Engineering is mandatory.\r\n Masters or Doctoral degree is preferred\r\n\r\n\r\n\r\n Job Experience & Skills Required:\r\n 4-5 years’ experience in a comparable environment\r\n Very strong analytical, communication and negotiation skills\r\n Data Science (essential)\r\n AI and ML experience (essential)\r\n R, Weka, NumPy, MatLab (essential)\r\n Excellent understanding of machine learning techniques and algorithms such as k-NN, Naïve, SVM\r\n Java\r\n Python\r\n HTML\r\n JavaScript\r\n Linux shell scripting\r\n NodeJS\r\n MSSQL\r\n MySQL\r\n MongoDB\r\n ElasticSearch\r\n Cassandra\r\n HDFS, Hadoop, Hbase\r\n\r\n\r\n\r\n Apply now!\r\n\r\n\r\n Email your cv to : Nbhana@-\r\n\r\n\r\nIf you have not had any response in two weeks, please consider the vacancy application unsuccessful. Your profile will be kept on our database for any other suitable roles / positions.\r\n\r\n\r\n\r\nFor more information contact:\r\n\r\nNikita Bhana\r\n\r\nIT Recruitment Consultant"},{"JobTitle":" Software Engineer (Platform & DevOps)","Url":"https://www.indeed.co.za/company/The-Hashtag-Element-(Pty)-Ltd/jobs/Software-Engineer-2cb7cf7a9f58135d?fccid=54b608f57b06085e&vjs=3","Source":" The Hashtag Element (Recruitment & Training Specia...","Salary":null,"Age":"10 days ago","Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\nPermanent\r\n\r\nA leading South African online retailer, is looking for highly talented Software Development\r\nEngineers to join their team.\r\n\r\nOur Client is a young, dynamic, hyper growth company looking for smart, creative, hardworking people to join us.\r\n\r\nWe seek to employ Exceptional Minds, people who are :\r\n\r\n* Experts at DOING, they can not only design but also execute\r\n\r\n* Analytical, able to use data to make decisions. Letting data decide but not consume;\r\n* Competitive. Although innovation is important, GREAT requires a lot of work. This does not\r\nhappen only in business hours….\r\n* Curious. Always questioning the status quo\r\n* Not averse to risk\r\n* Business smart. Able to think about problems from a business perspective using technical and\r\nproduct input\r\n* Self-directed, taking action based on own initiative\r\n* Collaborative\r\n* Thorough\r\n* User-focused, always trying to understand a product from the users’ perspective\r\n\r\n* Able to communicate clearly and not afraid to voice an opinion, no matter how unpopular\r\n\r\nAre you an Exceptional Mindif so come and join us !\r\nYou need to be strong in both root cause analysis and driving to action – in other words, you need\r\nto be a thinker and a doer, and doing doesn’t happen only during work hours\r\n\r\nYou need to be passionate about the potential of e-commerce and delivering a world-class customer experience. And, because we operate in a fast-growing, quick-moving environment, we’re looking for someone who is entrepreneurial, thrives under change, and always looks for solutions to do something better and faster. You will be at the cutting edge of developing new concepts for the Client. In short, we need you to think like an owner of the business.\r\n\r\nThe position reports to the Platform Team Lead\r\n\r\nKey requirements\r\n* 3-year computer science degree (or equivalent experience)\r\n* At least 2 years of professional experience\r\n* An understanding of computer science fundamentals, including Linux and operating systems,\r\nnetworking, and some development\r\n\r\nNice to have\r\n\r\n* Linux experience (Ubuntu/Debian)\r\n* Shell scripting\r\n* Python, ruby, or a similar language\r\n* Understanding of Linux and OS fundamentals (processes, signals, sysctl)\r\n* General debugging tools on Linux (tcpdump, vmstat, strace)\r\n* System administration (users, packages, ntp, smtp)\r\n* Network theory and administration (Linux)\r\n* Configuration management (chef, puppet)\r\n* Common web stack applications (nginx, apache, varnish, haproxy, memcache)\r\n* Database operations, query optimization, backup strategy\r\n* Hardware installation and configuration (raid, filesystems, lvm)\r\n* Metrics, monitoring (Nagios, Zabbix, sensu, graphite)\r\n* Security (iptables, selinux, ssh)\r\n* Cloud infrastructure (AWS, Google, Azure)\r\n* Virtualization technologies (xen, kvm)\r\n* Distributed systems\r\n* Capacity planning\r\n* Hadoop\r\n\r\nThe Environment\r\n* Our employees are entrepreneurial and dynamic, smart, customer-centric, fun and have the\r\nshared ambition\r\n* We have fun, work hard, take ownership, work in teams to create solutions and are always open to direct feedback/new ideas on where we can improve\r\n* We are short on ego and high on output\r\n* We are doers and not only thinkers, it’s all in the execution after all\r\n* We love what we do and what we are creating\r\n\r\nWe offer market related benefits, a great work environment and a promise that you won’t be bored as long as you are prepared for a challenge and want to build something great.\r\n\r\nOur Client is an Equal Opportunity Employer. Applicants from the previously disadvantaged groups and people with disabilities will be given preference.\r\n\r\nTo APPLY\r\n\r\nPlease forward your comprehensive CV including a letter of motivation in Word format to : \r\n\r\nClosing date : 29 July 2019\r\n\r\nJob Types: Full-time, Permanent"},{"JobTitle":" Sr. Manager, Solution Architecture","Url":"https://www.indeed.co.za/rc/clk?jk=6aa0404fb6f33f69&fccid=fe2d21eef233e94a&vjs=3","Source":" Amazon Web Services SA Pvt Ltd","Salary":null,"Age":"30+ days ago","Location":"Cape Town, Western Cape","Description":"\r\n\r\n\r\nCape Town, Western Cape\r\n\r\nBASIC QUALIFICATIONS· 10+ years experience in infrastructure architecture, database architecture and networking\r\n8+ years management of technical, customer facing resources\r\n7+ years design/implementation/consulting experience of distributed applications\r\n3+ years' experience managing large organizations through front-line managers and leaders\r\nTechnical degree required; Computer Science or Math background highly desired\r\n\r\n\r\nAmazon Web Services (AWS) is looking for a experienced and collaborative technical manager to coach, grow, and partner with technically skilled, customer-facing Solutions Architects in Sub-Sahara Africa. You will help develop the industry’s best cloud-based solutions architects by enabling and coaching them on best practices, solution selling, account planning, and influencing skills. Your team will help customers architect highly scalable and available workloads, cloud native applications, and innovative solutions in various technology domains such as Artificial Intelligence (AI), Big Data, Internet of Things (IoT), and Serverless computing. If you are someone who likes to tackle complex challenges, AWS is hiring a Manager for our Solutions Architects.\r\n\r\n We are looking for leaders who love learning and introducing new technology in order to help colleagues and customers embrace and adopt new technology. We need innovative leaders who can look beyond the technology and consider the value our technology creates for our customers, and can help change how our technology is viewed. This is critical for the role. You will help team members ramp-up on AWS as well as develop speaking, writing, presentation, and executive interaction skills. You will also need to be adept at interacting, communicating and partnering with other departments within AWS such as our services teams, marketing, and professional services teams, as well as representing your team to executive management.\r\n\r\n OTHER KEY CHARACTERISTICS\r\nIn this role, you will love what you do, and instinctively know how to make work fun, while maintaining a work-life balance.\r\nWe look for leaders who are creative and who are willing to take on any challenge and make a big impact for their team, for the company and for our customers.\r\nYou should enjoy developing technical talent to achieve great things.\r\nYou will have a passion for educating, training, and enabling cloud computing experts for a diverse and challenging set of Enterprise customers.\r\nYou should have a strong understanding of large scale computing solutions. The ideal candidate will have past experience working as a Solutions Architect or a similar role and experience managing a team of a Solution Architects.\r\nYou will have an ability to maintain your hands-on technical expertise as well as a passion for learning and developing new skills.\r\n\r\n ROLES AND RESPONSIBILITIES\r\n\r\nAs a key member of the business development and sales management teams, ensure success in building and migrating applications, software and services onto the AWS platform.\r\nEngage CxOs on high level technical vision and be able to develop long term trusted relationships.\r\n\r\nHire, on-board, coach, and develop new Solutions Architects from internal and external sources.\r\nEducate customers on the value proposition of AWS, build deep relationships with decision makers within customer accounts to enable them to be “Cloud advocates”.\r\nCapture and share best-practice knowledge amongst the AWS solutions architect community\r\nGuide and motivate the development of whitepapers, data sheets, and other high-value customer facing guidance and best practices.\r\nAct as a conduit and liaison between customers, service engineering teams and support.\r\nAmazon is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age\r\n\r\nPREFERRED QUALIFICATIONS· Working knowledge of software development tools and methodologies with knowledge of megatrend topics like containers, IoT, hadoop, machine learning and serverless.\r\nHistory of successful technical consulting and/or architecture engagements with large-scale customers or enterprises\r\nExperience migrating or transforming legacy customer solutions to the cloud\r\nFamiliarity with common enterprise services (Directory Services, Information Assurance, Virtual Desktop, etc.), products (i.e., Oracle, SAP) and frameworks (ITIL, TOGAF, etc.)\r\nProfessional experience architecting/operating solutions built on AWS\r\nDemonstrated presentation skills with a high degree of comfort speaking with executives, IT Management, and developers.\r\nHigh level of comfort communicating effectively across internal and external organizations\r\nDemonstrated written communication skills\r\nMeets/exceeds Amazon’s leadership principles requirements for this role\r\nMeets/exceeds Amazon’s functional/technical depth and complexity for this role"},{"JobTitle":" Snr Data science Engineer","Url":"https://www.indeed.co.za/rc/clk?jk=131728b75cc8ebdc&fccid=7854245953eb4df9&vjs=3","Source":" Gumtree.co.za","Salary":null,"Age":"1 day ago","Location":"Pretoria, Gauteng","Description":"\r\n\r\n\r\nPretoria, Gauteng\r\nLooking for a Senior Engineer within the Data Science sector. Must have one of these CLOUDERA , HADOOP, GCP , AZURE AND AWS5 years exp in DATA Engineering In ICT and Telecommunication / salary 1.1million Email cv to michelle@tause.co.za"},{"JobTitle":" Senior Software Developer","Url":"https://www.indeed.co.za/rc/clk?jk=7e62179e80c1ed5e&fccid=399f716a0307ef50&vjs=3","Source":" Communicate Recruitment","Salary":" R600 000 - R700 000 a year","Age":"27 days ago","Location":"Johannesburg North, Gauteng","Description":"\r\n\r\n\r\nJohannesburg North, Gauteng\r\n\r\n\r\nR600 000 - R700 000 a year\r\n\r\n\r\n\r\nSenior Software Developer\r\n\r\n\r\n\r\nRef. No:\r\n\r\nCER008136/TKE\r\n\r\n\r\n\r\nSalary Range:\r\n\r\nR600000 - R700000 Annually\r\n\r\n\r\n\r\nBrief Description:\r\n\r\nBeing a Specialist recruiter within the IT sector, my clients are always on the lookout for exceptionally talented. Your backend coding skills on the .net framework and C# skills together with a stable working track record will not go unnoticed within some of the top clients. \r\n\r\n\r\n\r\nJob Description:\r\n\r\n\r\nEducation: \r\nBachelor degree in related field or comparable experience in the web development required. Substantial experience working with similar technologies and environment\r\nMinimum 6 years’ experience using .NET technology stack such as (Web API, MVC, .NET4.5, .NET Core, WCF, Unity, Angular and Bootstrap\r\nMust have a good grasp of design principles (Solid, GOF Patterns and etc)\r\nFamiliarity with various design and architectural patterns\r\nFamiliarity with standard SDLC process and Agile/Scrum Methodology\r\nImplementing automated testing platforms and unit tests\r\nFamiliarity with versioning control tools {{such as Git, TFS and etc}}\r\nMust be able to design, develop, troubleshoot, and debug systems and their various integration points\r\nGood knowledge in writing SQL scripts, stored procedures and database design\r\nFamiliarity with Microsoft SQL Server 2008/12/14\r\nKnowledge of TeamCity a plus\r\nKnowledge of SSIS development a plus\r\nExposure to Non-Microsoft DB technologies a plus (MySQL, MongoDB, Hadoop etc.)\r\n\r\n\r\n\r\n\r\nSkills:\r\nDisplay an attitude of innovation\r\nDedicated and committed to achieving results\r\nSelf-motivated\r\nAble to adapt to change quickly\r\nConvey a professional image\r\nBe able to work under pressure\r\nStrong analytical and problem solving\r\nExperience working in a team-oriented, collaborative environment\r\nExcellent written and oral communication skills\r\nPresenting & Communicating Information (Familiar with)\r\n\r\n\r\n\r\n\r\nDescription:\r\nTo translate, design, build bespoke applications given a set of requirements\r\nTo assist business during QA testing, resolving bugs and issues as their being discovered Frequent communication with colleagues and management\r\nCollaborate with IT/Business for any technical assistance required Integrating data from various back-end services and databases\r\nPerform website analysis and diagnostics according to planned schedules or after any website or product revisions\r\nDiagnose production issues and provide assistance to production support staff (2nd level support) Stay plugged into emerging technologies/industry trends and apply them into operations and activities\r\nEnsure work done adheres to quality guidelines and standards for all activities (e.g. naming conventions, code comments) as agreed in the team Be responsible for maintaining, expanding, and scaling all Universal sites\r\n\r\n\r\n\r\n\r\nPlease visit our website www.communicate.co.za to submit your CV directly or to view other I.T related jobs. If you have not had any response in two weeks, please consider your application unsuccessful. Your profile will be kept on our database for any other suitable positions.\r\n\r\n\r\n\r\nWe also invite you to contact us to discuss other exciting career opportunities in our niche area! For more information, please call Thato Kekana on 087 351 0711 or email on thkekana@communicate.co.za\r\n\r\n\r\nSector:\r\n\r\nDevelopment and Programming\r\n\r\n\r\nTown:\r\n\r\nJohannesburg North\r\n\r\n\r\nDate:\r\n\r\n07/07/2019\r\n\r\n\r\nExpiry Date:\r\n\r\n06/08/2019"},{"JobTitle":" Senior Qlikview Developer","Url":"https://www.indeed.co.za/rc/clk?jk=c2c0b8c938fe5a16&fccid=01033342134bf9cb&vjs=3","Source":" MDK Appointments","Salary":null,"Age":"30+ days ago","Location":"Sandton, Gauteng","Description":"\r\n\r\n\r\nSandton, Gauteng\r\n\r\n\r\nOur client requires the services of a Senior Qlikview Developer in our Technology Department. The Business Intelligence Qlikview Developer is a member of the Business Intelligence Competency Centre (BICC) and will be responsible for developing and maintaining dashboards, models, data mining and analytics that are relevant to the organization.\r\n\r\n\r\n\r\n Key roles and responsibilities: \r\nParticipate in business requirements analysis and documentation\r\nDevelop models and dashboards that can be easily accessed and analysed\r\nStore extracted data in efficient and required formats\r\nDevelop logical data marts, cubes, reports and related data warehouse entities\r\nPerform tasks according to requirements from internal and external parties\r\nEscalate tasks where tasks deviate from project plan\r\nAttend to tickets and requests in a timely manner\r\nRegular maintenance of existing models, dashboards and business rules\r\nAssist with operational systems support\r\nRespond promptly and professionally to requests for reports and data requests\r\nMaintain and develop standard operating procedures and standards\r\nImplementation and utilization of business intelligence tools\r\nPreparation of required documentation: user training material; CCB documentation; requirements, SOP’\r\n\r\n\r\n\r\n\r\nQualifications, experience and competencies required: \r\nBCom Informatics/Information Systems Degree and relevant work experience required.\r\nCertification within the BI discipline is advantageous: such as Microsoft (BI tool stack) and/or Qlik and/or Data Warehousing BI & Project methodologies: Advanced Data warehousing Techniques & Modelling, including Industry specific / certification, Data Warehouse methodology)\r\n+- 3 - 5 Years Business experience including: 3-5 years of SQL application programming\r\n3-5 years of Development SSAS, SSIS, SSRS 3-5 years of Qlikview Development / Cube Development Skilled in: Microsoft Business Intelligence Tools QlikView / SSAS o ETL tools (Qlikview, Sagent Software, SQL, Object orientation & design, SSIS) Databases (MS SQL Server, ORACLE, HADOOP) Hardware/ Operating Systems (Windows & Linux)\r\n\r\nPlease note that, if your skills and experience do not match the requirements of this job, we will place your CV on our database and contact you as soon as a suitable position becomes available. It is not necessary for you to apply for more than one position as your CV will automatically be loaded onto our database where it will be available to all our consultants for future opportunities.\r\n\r\nBazil Mdaka Recruitment Manager| Executive Search Lead - Africa, Europe & Middle East Region"},{"JobTitle":" Software Engineer (Machine Learning)","Url":"https://www.indeed.co.za/rc/clk?jk=595ae5ba82fe9cba&fccid=26d01f64c124ba71&vjs=3","Source":" Datafin IT Recruitment","Salary":null,"Age":"30+ days ago","Location":"Cape Town, Western Cape","Description":"\r\n\r\n\r\nCape Town, Western Cape\r\n\r\n\r\nPermanent\r\n\r\n\r\n\r\nA fast-paced leading online retailer seeks an Software Engineer (Machine Learning) to join their team based in Stellenbosch\r\n\r\n\r\n\r\nDUTIES:\r\n\r\nWork with data.\r\n\r\nBuild state-of-the-art statistical models.\r\n\r\nTouch all aspects of the business.\r\n\r\nBrainstorm new ideas and concepts.\r\n\r\nWork with teammates on design, and code reviews.\r\n\r\nBuild real time systems that integrate with the rest of our stack.\r\n\r\n\r\n\r\nREQUIREMENTS:\r\n\r\nComputer Science degree (alternatively a degree in a related field with work experience as a software engineer).\r\n\r\nStrong Mathematical or Statistical experience.\r\n\r\nPython experience.\r\n\r\nLinux experience.\r\n\r\nCommercial software experience.\r\n\r\nExperience with Hadoop/Spark/R\r\n\r\nMachine Learning / Data Mining / Big Data experience.\r\n\r\nMSc (or even PhD) in a related field would be advantageous.\r\n\r\n\r\n\r\n While we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.\r\n\r\nCOMMENTS:\r\n\r\nWhen applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence. Please e-mail a word copy of your CV to loren@datafin.com and mention the reference numbers of the jobs."},{"JobTitle":" Software Engineer (Platform & DevOps) - Takealot","Url":"https://www.indeed.co.za/rc/clk?jk=b3c6a77d43260081&fccid=1a87b4c6f9946a15&vjs=3","Source":" takealot.com","Salary":null,"Age":"30+ days ago","Location":"Cape Town, Western Cape","Description":"\r\n\r\n\r\nCape Town, Western Cape\r\ntakealot.com, a leading South African online retailer, is looking for highly talented Software Development Engineers to join our team in Cape Town, Stellenbosch or Johannesburg. \r\n\r\n We are a young, dynamic, hyper growth company looking for smart, creative, hard-working people with integrity to join us. We offer a market related, Total Remuneration Package which allows full flexibility according to your needs, a great work environment and a promise that you won't be bored as long as you are prepared for a challenge and want to build something great. \r\n\r\n You need to be strong in both root cause analysis and driving to action – in other words, you need to be a thinker and a doer, and doing doesn't happen only during work hours….. You need to be passionate about the potential of e-commerce and delivering a world-class customer experience. And, because we operate in a fast-growing, quick-moving environment, we're looking for someone who is entrepreneurial, thrives under change, and always looks for solutions to do something better and faster. You will be at the cutting edge of developing new concepts for takealot.com. In short, we need you to think like an owner of the business. \r\n\r\n The position reports to the Platform Team Lead \r\n\r\n Requirements \r\n\r\n3 year computer science degree (or equivalent experience)\r\nAt least 2 years of professional experience\r\nAn understanding of computer science fundamentals, including linux and operating systems, networking\r\nSolid grasp of development fundamentals such as data structures and algorithms\r\nNice to have \r\n\r\nLinux experience (Ubuntu/Debian)\r\nShell scripting\r\nPython, ruby, or a similar language\r\nUnderstanding of linux and OS fundamentals (processes, signals, sysctl)\r\nGeneral debugging tools on linux (tcpdump, vmstat, strace)\r\nSystem administration (users, packages, ntp, smtp)\r\nNetwork theory and administration (linux)\r\nConfiguration management (chef, puppet)\r\nCommon web stack applications (nginx, apache, varnish, haproxy, memcache)\r\nDatabase operations, query optimization, backup strategy\r\nHardware installation and configuration (raid, filesystems, lvm)\r\nMetrics, monitoring (nagios, zabbix, sensu, graphite)\r\nSecurity (iptables, selinux, ssh)\r\nCloud infrastructure (AWS, Google, Azure)\r\nVirtualization technologies (xen, kvm)\r\nDistributed systems\r\nCapacity planning\r\nHadoop\r\nThe Environment:\r\ntakealot.com employees are entrepreneurial and dynamic, smart, customer-centric, fun and have the shared ambition of takealot.com being the leading e-commerce company in Africa.\r\nWe have fun, work hard, take ownership, work in teams to create solutions and are always open to direct feedback/new ideas on where we can improve.\r\nWe are short on ego and high on output.\r\nWe are doers and not only thinkers, its all in the execution after all.\r\nWe love what we do and what we are creating.\r\nWe seek to employ Extraordinary Minds, people who are:\r\nExperts at DOING, they can not only design but also execute\r\nAnalytical, able to use data to make decisions. Letting data decide but not consume\r\nAlthough innovation is important, GREAT requires a lot of work. This does not happen only in business hours\r\nAlways questioning the status quo\r\nNot averse to risk\r\nBusiness smart. Able to think about problems from a business perspective using technical and product input\r\nSelf-directed, taking action based on own initiative\r\nCollaborative\r\nThorough\r\nUser focused, always trying to understand a product from the users perspective\r\nAble to communicate clearly and not afraid to voice an opinion, no matter how unpopular\r\nWe seek to Employ an Extra Ordinary Mind who:\r\nis forthright but respectful\r\nis an expert at doing, who can not only design but also execute\r\nis analytical, able to use data to make decisions\r\nis competitive, self-directed and strive to be the BEST (GREAT requires a lot of work and does not only happen during business hours\r\nis passionate about the potential of e-commerce and delivering a world-class customer experience\r\nis entrepreneurial, thrives under change and accepts it is a constant and always looks for solutions to do something better and faster\r\nis able to think about problems from a business perspective using technical and product input\r\nis curious and challenge the status quo\r\nis innovative and enjoys iteration\r\nis collaborative\r\nwill be at the cutting edge of developing new concepts for takealot.com.\r\nthinks like an owner of the business.\r\nis SMART, has INTEGRITY and is HARDWORKING\r\nIf you meet the above you are an Extraordinary Mind so come and join us! \r\n\r\n Takealot is an Equal Opportunity Employer. Applicants from the previously disadvantaged groups and people with disabilities will be given preference"},{"JobTitle":" Data Scientist","Url":"https://www.indeed.co.za/rc/clk?jk=79b07c24bea88b88&fccid=8de4e5eeef794daa&vjs=3","Source":" Tipp Focus","Salary":" R550 - R650 a week","Age":"30+ days ago","Location":"Midrand, Gauteng","Description":"\r\n\r\n\r\nMidrand, Gauteng\r\n\r\n\r\nR550 - R650 a week\r\nThis position will provide complete application lifecycle development, deployment, and operations support for Big Data solutions and infrastructure. ? In this role, you will collaborate with product owners, data scientists, solutions engineers, and business analysts to facilitate the development, automation, and seamless delivery of analytics solutions into Big Data clusters. \r\n\r\n Strong background in mathematics and have very good analytical and problem solving skills. \r\n\r\n Languages Python, Scala, SQL, Java, PL/SQL Web Technologies Web Service, SOAP, Rest web services, JSP \r\nBig Data Eco System \r\nHDFS, Spark, Yarn, Map Reduce, Hive, Pig, Sqoop, ZooKeeper, Kafka, Oozie, Hue, Impala, Flume. Scripting Languages HTML, JavaScript, CSS, XML and Ajax Machine Learning R, SAS, Python, SKLearn, MATLAB, Octave, Spark ML No SQL Databases Cassandra, HBase, MongoDB, Vertica Cloud AWS, EC2, S3, EMR, Azure Operating System Windows, Linux and Unix \r\nBI/DWH/ETL Tools Informatica 9.5/9.1/8.6, Tableau, Cognos DBMS / RDBMS Oracle 12c/11g, SQL Server 2014, DB2, Teradata 14/12, AWS Redshift \r\nIDEs \r\nEclipse, Jupiter Notebooks, Microsoft Visual Studio, Flex Builder, Spyder, TOAD, NetBeans, PL/SQL Developer, Putty, Squirrel SQL Version Control SVN, CVS, Git, and Rational Clear Case \r\nTools FileZilla, JUnit, Splunk, HP ALM, Clear Quest, Rally, Jira \r\n\r\nActivities:\r\n Installing, configuring and using ecosystem components like Hadoop Map Reduce, Spark, Hive, Sqoop, Pig, HDFS, HBase, Cassandra, ZooKeeper, Oozie, Hue, Impala and Flume. ? Strong experience in Data Warehousing and ETL using Informatica Power Center. ? Very good experience in analyzing the data and reporting it using data visualization tools such as Tableau, Cognos, MicroStrategy. ? Good understanding of Hadoop architecture & various components of HDFS/ Yarn. ? Experience in Data Mining, Data Analysis, Data Migration, Data Validation, Data Cleansing, Data Verification and identifying Data Mismatch. ? Experience in Machine Learning solving classification and clustering \r\nproblems. ? Interpreting the results of statistical and predictive experiments and regression analysis. ? Importing and exporting data using Sqoop from HDFS to Relational Database Systems and vice-versa. ? Experience with CSV, JSON, Sequence files, AVRO, Parquet, RC file formats. ? Experience with Spark Context, SQL Context, Spark-SQL, Data Frames, Pair RDD's, transformations, actions in Spark. ? Expert in creating PIG and HIVE UDFs using java in order to analyze data sets. ? Experience using HBase, Cassandra, MongoDB No-SQL databases for real time low latency queries. ? Experience with Spark programs, Hive queries, pig Latin scripts, and MapReduce programs for data analysis and to process the data and loading into databases for visualization. ? Extensively worked on data extraction, Transformation and loading (ETL) data from various sources like Oracle, SQL Server and flat files and loaded into DWH for reporting and data analysis. ? Well versed in developing the complex SQL queries, multiple table joins, analytical functions, regular expressions etc. ? Experience in preparing and executing test plan and test cases after software development. ? In depth understanding of data structures and algorithms. ? Experience working with both the Waterfall and Agile methodologies. ? Experience in giving training and guiding new team members in the Project. ? Experience coding and testing the Standardization, Normalization, Load, Extract and AVRO models to filter/massage the data and its validation. ? Proficient in HealthCare, Education, Retail and Banking Domains. ? Very good experience in customer specification study, requirements gathering, system architectural design and turning the requirements into final product. ? Experience in interacting with customers and working at client locations for real time field testing of products and services. ? Ability to work effectively with associates at all levels within the organization."},{"JobTitle":"Hadoop Administrator","Url":"https://www.indeed.co.za/rc/clk?jk=5a0524ce4fc63e4a&fccid=baf8f1e7b7eec29f&vjs=3","Source":" JobScape","Salary":null,"Age":"30+ days ago","Location":"City of Johannesburg, Gauteng","Description":"\r\n\r\n\r\nCity of Johannesburg, Gauteng\r\nAs a Hadoop Administrator, you will responsible for supporting, configuring, upgrading, and maintaining multiple Hadoop clusters as well as contributing to building out additional clusters, adding nodescapacity to existing clusters, and implementing open source projects. \r\n\r\n Duties \r\nInstalling Hadoop in Linux environment. \r\nDeployment in a Hadoop cluster and its maintenance. \r\nHealth check of a Hadoop cluster monitoring whether it is up and running all the time. \r\nAnalyse the storage data volume and allocating the space in HDFS. \r\nResource management in a cluster environment. This involves new node creation and removal of unused ones. \r\nConfiguring NameNode to ensure its high availability \r\nImplementing and administering Hadoop infrastructure on an ongoing basis. \r\nRequired hardware and software deployment in Hadoop environment. Furthermore to expanding of existing environments. \r\nUser creation in Linux for Hadoop and its components in the ecosystem. Moreover, setting up Kerberos principals is a part of Hadoop administration. \r\nPerformance tuning and running jobs in Hadoop clusters. \r\nCapacity planning \r\nMonitoring connectivity and security of Hadoop cluster \r\nManaging and reviewing log files in Hadoop. \r\nManagement of HDFS file system and monitoring them. \r\nMaintaining HDFS and providing necessary supports. \r\nBackup and recovery tasks. \r\nCommunicating with other development, administrating and business teams. They include infrastructure, application, network, database, and business intelligence teams. Effective communication plays a key role in high quality and availability of data. \r\nCoordinating with application teams. Installing the operating system and Hadoop related updates as and when required. \r\nWorking as a key person for Vendor escalation \r\nTroubleshooting \r\n\r\n Experience \r\nGeneral operational excellence. This includes good troubleshooting skills, understanding of systems capacity and bottlenecks. Furthermore, you also need a basic understanding of memory management areas. \r\nProper knowledge and handson experience in Hadoop ecosystem components. \r\nHadoop administration demands ones deployment skill in Hadoop cluster. Moreover, the job needs adding and removing nodes. It may need tracking of jobs and monitor the important parts of the cluster. \r\nConfiguring high availability of namenode. \r\nScheduling and taking backups \r\nLinux cron is the running platform of Hadoop. Hence, a good handson experience of Linux, its commands and scripting are a must. \r\nConfiguration management and deployment exposure in Open source environment. \r\nKnowledge of Core Java is an added advantage in performing the job. \r\n\r\n Qualifications Certification \r\nA degree in Computer Science Information Systems Business Administration Commerce or equivalent \r\n\r\n To Apply \r\nWhatsapp the keyword JOB to"},{"JobTitle":" SQL Developer - Contract role","Url":"https://www.indeed.co.za/rc/clk?jk=171c3471a1b7ab6a&fccid=6cf6f033d6b2b045&vjs=3","Source":" GG Financial Recruitment","Salary":null,"Age":"30+ days ago","Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\nContract\r\n\r\n\r\nBusiness, Gauteng JHB - Western Suburbs \r\nadele@ggaccounting.co.z \r\n\r\nJoin this dyanmic Fin-Tech company as they expand into International countries by performing the full BI SQL Development. Applicants who are immediately available, with the following skills and experience are encouraged to apply:\r\n\r\n\r\nJoin this dyanmic Fin-Tech company as they expand into International terrotories by performing the full BI SQL Development. Applicants with the following skills and experience are encouraged to apply:\r\nComplted IT/BSc related degree\r\n3-5 years in Business Intellegence Development\r\n2-3 years experience in SQL Development and extensive SQL-Queries (Essential)a\r\nFull ETL development\r\nExtensive Database development (essential)\r\nExperience with cloud based platform, preferably Hadoop (preferable).\r\nAnalytics experience in classification and segmentation would be highly advantageous\r\n\r\nThis is an urgent position and applicants are encouraged to apply asap.\r\n\r\nDon't delay, send your CV today.\r\n\r\n\r\n\r\nAd Visible Until: 10 August 2019 \r\nRef: CPT000467/AA \r\n\r\nVacancy Type: Contract"},{"JobTitle":" BI Developer","Url":"https://www.indeed.co.za/rc/clk?jk=f892b7708270c06f&fccid=2429f7b96dfc0010&vjs=3","Source":" Dynamic Visual Technologies (DVT)","Salary":null,"Age":"30+ days ago","Location":"East London, Eastern Cape","Description":"\r\n\r\n\r\nEast London, Eastern Cape\r\n\r\n\r\n\r\n\r\n\r\nOur Data and Analytics Team\r\n\r\nWe are a growing team of passionate data and analytics professionals working at DVT in Pretoria, Johannesburg, Cape Town and Durban, focussed on building business value for our customers. Our consulting and project engagements, both locally and internationally, range across a wide variety of sectors including manufacturing, retail, marketing and financial services, providing challenging diversity of experience to our consultants.\r\n\r\n\r\nOur team includes junior, intermediate and senior consultants and developers as well as some of the best analytics strategists. If you are passionate about the power of data and analytics, Big Data, machine learning or data science we’re looking for you! Apply now.\r\n\r\n\r\nWe offer the opportunity for you to work in Agile teams on high-profile customer engagements where information is used to craft digital business. Work on solutions to take our enterprise customers on an analytics maturity journey, ranging from formulating foundational data capability, information connectivity to leveraging high order analytics in a dynamic fashion.\r\n\r\n\r\n\r\nThe skills we are seeking from applicants and developing in our team members include:\r\n\r\n\r\nMicrosoft SSIS, SSAS (Multidimensional and Tabular), SSRS \r\nMicrosoft PowerBI\r\nPowershell\r\nAzure SQL DB, Azure Datawarehouse, Azure Data Lake, Azure Data Factory, Revolution R, HD Insights, Polybase\r\nApache projects including SQOOP, HADOOP, HIVE, MAHOUT, SPARK \r\nGoogle Data Studio, Big Query\r\nBusiness consulting leveraging analytics\r\n\r\n\r\nYour skills will deepen as you work on our high-profile engagements enabling Digital Business. DVT Data and Analytics is where you can grow your career in data science - as you grow in seniority, become a Senior Data and Analytics Consultant or Analytics Solutions Specialist.\r\n\r\n\r\nWork with customers to enable solutions that transform business.\r\n\r\n\r\nIf you “get” the power of data and analytics in modern business and want to be one of our guru’s helping customers realize true digital capability, we want to talk to you about joining our team.\r\n\r\n\r\n\r\n\r\n\r\nWhy join our Data and Analytics Team\r\nLocal and International client projects \r\nAbove market remuneration and performance bonuses\r\nMaternity and paternity benefits\r\nCompany paid group life and disability cover\r\n20 days annual leave\r\nGenerous contribution towards training and certification\r\nHigh spec developer machines\r\nParticipate in the digital business revolution\r\nA true Data and Analytics culture in a dedicated division.\r\n\r\n\r\n\r\n\r\n\r\nAbout DVT\r\n\r\nIt all started with a passion for creating high-impact business software that we and customers can see working in production as quickly as possible.\r\n\r\n\r\nSince 1999 DVT has been on the forefront of bespoke business software solutions for some of the largest and most dynamic companies in South Africa and abroad. Starting out as custom business software developers in Cape Town, we’ve grown to become one of South Africa’s leading software and services providers with delivery centres in Johannesburg, Cape Town and Durban and have recently cut the ribbon on our office in London.\r\n\r\n\r\nDelivering great software requires much more than good programming, design and architecture. Today, with more than 700 staff, we help clients with everything needed to get quality software in production faster. This includes Agile and Lean consulting and training, cutting code, software testing, IT consulting and architecture, business and process analysis, project management, business intelligence as well as product implementation.\r\n\r\n\r\nWe also run the largest specialist software testing centre in Cape Town focused on testing automation.\r\n\r\n\r\n\r\n\r\nOur Culture\r\n\r\nWe are known for our people centric approach, unwavering business integrity and working in an Agile approach with high quality always top of mind.\r\n\r\n\r\n\r\nAt DVT we live by a set of values. Our values say who we are. They guide us in making a positive impact with our clients, business partners, the communities we operate in and amongst ourselves.\r\n\r\n\r\nOur Values\r\n\r\n\r\n\r\n\r\nHow we work\r\n\r\nAt DVT you will have the opportunity to work in an extraordinary wide range of business domains and technologies. Some of our projects happen in of our offices in Agile teams or on-site at clients in Agile teams. Either way, you will work with some of the best developers in South Africa working on software solutions for leading companies. Some of our team service international clients and utilise business communication technologies such as Skype stand-ups."},{"JobTitle":" LAMP Web Developer for SouthAfrica","Url":"https://www.indeed.co.za/rc/clk?jk=6060d089bc3d34fc&fccid=5ef4d3df18d56a80&vjs=3","Source":" itForte","Salary":null,"Age":"30+ days ago","Location":"Durban, KwaZulu-Natal","Description":"\r\n\r\n\r\nDurban, KwaZulu-Natal\r\n\r\n\r\nPermanent\r\n\r\n\r\nOur client is a leading multi-staged venture capital company in SouthAfrica committed to supporting and developing individuals and companies with the next blue chip ideas relating to the Quantitative Trading, Information Technology and the Online Media sectors. The company seeks talented and energetic LAMP Web Developers to assist in the development with their latest venture. As a developer you will have the chance to work in a highly energetic, multi-tasked and dynamic driven team that is based in the heart of Silicon Valley.\r\n\r\nThe company is building one of the most viral and engaging social media platform. The LAMP Web Developer will help pushing the boundaries of what is possible. We are looking for developers and engineers who love finding efficient and thoughtful solutions to a variety of technical and product challenges. You should strive to write efficient, maintainable code and enjoy pushing code everyday. Sample projects include: Search, API, Recommendation Engines, Measurement, Speed and Scale.\r\n\r\nYou will be an integral part of a highly focused and one of the best teams of developers and engineers in Silicon Valley.\r\n\r\n\r\nJob Responsibilities / Key Result Areas (KRAs)\r\n Proficient in PHP (Joomla and JomSocial)\r\n Proficient in HTML5, CSS3 and JQuery\r\n Proficient in MySql\r\n Proficient in Linux (CentOS & Fedora) and Apache\r\n Bachelors degree (CS or EE preferred)\r\n Fluency in English (reading and writing)\r\n Dynamic, positive and communicative team player, who is an expert at multi-tasking and takes initiative,\r\n You will be involved in all aspects of software development from architecture to coding to testing.\r\n You will be taking responsibility of some back-end modules, from internal business logic servers to public API servers\r\n Must be enthusiastic, energetic and have a great sense of humor.\r\n\r\n\r\nJob Requirements (Qualifications/Certifications/ Experience/Skills etc.)\r\n Experience with NoSql or Vertica database\r\n\r\n- Social App Development- experience in building social sites, apps or API’s\r\n Knowledge in Automation experience with tool\r\n Knowledge of Ruby-on-Rails\r\n Knowledge with Hadoop (HDFS)\r\n Agile methodology knowledge\r\n Scripting skills in Python, Perl and Java\r\n\r\n\r\nQualification: BE/MCA or any equivalent qualification.\r\n\r\n\r\nExperience: 3 + years of relevant experience\r\n\r\n\r\nContract Type: Permanent, Full Time\r\n\r\n\r\nLocation: Durban, SouthAfrica\r\n\r\n\r\nitForte is one of the leading International Recruittment Agencies in India specializing in the IT and Telecom sector recruitments with some of the top international technology companies as its clients."},{"JobTitle":" Solutions Architect","Url":"https://www.indeed.co.za/rc/clk?jk=f0eeb157f0705440&fccid=456208dd78cb7bb1&vjs=3","Source":" Altron","Salary":null,"Age":"30+ days ago","Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\nPermanent\r\n\r\n\r\n\r\n\r\nSolutions Architect\r\n The Solution Architect (SA) leverages broad technical knowledge of all Teradata products and services to promote sales of Teradata solutions within specific industries, by providing technical knowledge in sales support activities.\r\n The SA should have wide experience of Data Warehousing and Big Data Analytics generally with expert knowledge in many aspects of Teradata products and services within these areas.\r\n Successful SA’s have a broad working knowledge of Cloud architecture and services, Agile and DevOps delivery approaches, emerging technology and trends (i.e. Machine Learning, Deep Learning, Artificial Intelligence, Blockchain etc.) and the broader Analytics industry (including Open Source, partner and competitive solution offerings).\r\n The SA typically has established relationships within the industry from a Partner and Client perspective, and is well aligned and embedded within the community, its stakeholders and role-players.\r\n The SA will participate in the design and development of an architecture that will be aligned with the client’s business objectives based on business, information, application, and system requirements.\r\n The SA is able to articulate the benefits to the customer of the Teradata Analytic Architecture, Unified Data Architecture and Reference Information Architecture.\r\n The SA is highly consultative and always seeks to first understand the customer’s business, value proposition, information, and application requirements.\r\n The SA will thoroughly understand the client’s information technology infrastructure and serves as the key link between business needs and technology enablers.\r\n While continually analysing the customer’s ever changing business and technical requirements, the SA will take the lead in translating those requirements and strategies into, not only, Teradata, Teradata Aster, and Hadoop products, solutions, and services, but also third party partner products, where appropriate, as well as integration with the customer’s overall strategy and architecture.\r\n The Solution Architect ensures that the proposed solutions are business enabling and technically innovative, ensures improved ROI, and identifies additional uses for the client’s investment in the Teradata data warehouse, Teradata Aster, and Hadoop solutions, and services.\r\n The SA establishes or enhances mid-level customer relationships, provides technical guidance on engagements, and identifies new target application opportunities within customer and prospect accounts.\r\n The SA is responsible for identifying, establishing, and managing Proof of Concept (POC), Proof of Value and/or Benchmark engagements, in the customer environment, leading to sales of Teradata, Teradata Aster, Hadoop, and Teradata Application software, hardware, and services.\r\n The SA will be expected to deliver high-quality, customer billable consulting on Professional Services engagements and oversee the development of the customer engagement model for additional services.\r\n The SA plays an active role in both pre-sale and post-sale activity, ensuring a long-term partnership with Teradata customers.\r\n The SA has a great opportunity to make a significant contribution to the long term architecture and success of these accounts.\r\n The Solution Architect may take the role of Project Tech Lead, and/or Architecture Consultant, on some projects, and, in other cases, will liaise with these roles to ensure architectural consistency.\r\n SA’s typically contribute to the industry and community through participation and contribution to publications, case studies, round-table discussions, reference calls, seminar presentations and interviews.\r\n\r\n\r\n\r\nJob Requirements:\r\n\r\n\r\nKey Areas of Responsibility\r\n Provide direct and substantial support of the team's revenue and margin objectives by:\r\n Participating in the development and execution of winning sales strategies. Working with sales teams to generate new profitable business: articulate, demonstrate, and scope Teradata solution offers and services.\r\n Assisting with opportunity qualification utilising knowledge of the customer’s business and technical requirements plus industry solutions generally, data models & data volumes for the various business areas within the company, and applying this knowledge to determine applicability of Teradata, Teradata Aster, Teradata Applications, Teradata Open Source collaboration projects and Hadoop offerings.\r\n Understanding, documenting, and articulating the customer's current data warehouse / data mart and Big Data architecture. This includes maintaining an inventory of the customer's data warehouses, data marts and other Big Data stores, as well as their respective business functions.\r\n Gathering and documenting client requirements and translating them into process and system architecture designs and ready to order configurations.\r\n Understand the client’s business goals, information needs, application requirements, IT plans, and architecture, and articulate linkage to the proposed architecture and application designs.\r\n Define an enterprise blueprint and time-phased roadmap for enabling the business to realize their vision.\r\n Work with Teradata project managers to scope projects and develop statements of work, project plans, and risk analysis.\r\n Provide technical thought leadership and actively participate in the application design, implementation, and roll-out efforts.\r\n Understanding competitive products such as Oracle, IBM, Microsoft, SAP and Cloud Based Services, etc.\r\n Understanding partner products that complement the solution architecture such as Data Integration, Metadata, Masterdata, Data Governance, Data Quality, Analytics, Visualisation and Reporting vendor offerings.\r\n Understanding Open Source community solutions that either collaborate and compliment or compete with Teradata solution offering.\r\n Understanding mainframe, client/server and Hadoop computing environments.\r\n Design and manage winning PoC, PoV and competitive benchmark activities, based on customer requirements.\r\n Understanding SaaS and hosted solution offerings and computing environments.\r\n Demonstrating and utilizing knowledge of business problems of customers in their industry.\r\n Articulating Teradata's solutions to business problems using the full range of Product, Professional Services, and solution offerings, across the complete UDA.\r\n Being a trusted advisor to the customer's decision makers by establishing credibility and expertise in data warehouse technology and architecture, big data analytics, and other areas related to Teradata's solution offerings.\r\n Identifying new application opportunities that will lead to additional data being added to the customer's analytic ecosystem as well as potentially high margin Professional Services engagements.\r\n Generating interest with the decision-makers that leads to follow-on meetings and advancement of the sales process.\r\n Contributing to the financial objectives of the team through business development and demand-creation activities.\r\n Demonstrating the ability to relate business problems to the underlying data and the ability of Teradata solutions to solve the business problems.\r\n Participating in PS engagements that position Teradata as a trusted advisor to our customers.\r\n Timely and accurate administration and reporting (expenses, forecasts, etc.).\r\n Contributing Knowledge Assets to the Teradata Knowledge Management System.\r\n\r\n Skills\r\n Broad technical expertise combined with business acumen and strong consulting skills.\r\n Strong business and/or technical analysis background.\r\n Technical knowledge and in depth experience with building Data Warehouses, Data Marts, big data analytics, applications, enterprise architectures, solutions, and technologies.\r\n Expert technical knowledge in several areas of Teradata products and configurations including Teradata RDBMS, Teradata Aster, Hadoop, Teradata Applications, etc.\r\n Knowledge of Analytic Architecture, Architecture Principles, Advocated Positions, Design Patterns, and Implementation Alternatives.\r\n Understanding of the Teradata Reference Information Architecture - including all aspects of the Unified Data Architecture.\r\n Proven capabilities in relational database, and/or Hadoop, technologies in the application development environment (e.g. Teradata, DB2, Oracle, HortonWorks, Cloudera, Hana, etc.)\r\n Operational knowledge of third party DI, BI, Visualisation and Analytical tools (e.g. Informatica, DataStage, Cognos, Tableau, SAS, R, etc.)\r\n Understanding of Master Data Management concepts and principles\r\n Experience of successful PoC, PoV, Benchmark design, development and execution\r\n Analytical and problem solving skills\r\n Knowledge and understanding of \"Logical Data Sources\" and/or domain knowledge in industry-specific subject areas\r\n Understanding of the client’s business domain (e.g. Retail Banking, Telecommunications, Retail etc.)\r\n Experience of working with other customers and target accounts within the same industries\r\n Knowledge of future trends/changes and the ability to articulate the likely impact of these to customers\r\n Experience in consulting with senior level executives\r\n Client interfacing, relationship building, and consulting skills required\r\n Excellent oral and written communication, and presentation skills\r\n Strategic Planning and Thinking\r\n Consultative Selling\r\n Meeting Facilitation\r\n Proposal Development, Service Offer Scoping, and Project Definition\r\n Resource Management, Scheduling, and Project Management\r\n\r\n Technical Skill Category and Skill Mapping\r\n Service Offers (Primary Skill)\r\n Databases (Primary Skill)\r\n Hadoop (Primary Skill)\r\n Industry Knowledge (Knowledge)\r\n Project Mgmt: Data Warehousing Skills (Primary Skill)\r\n Project Mgmt: Foundation Skills (Primary Skill)\r\n Project Tech Lead (Primary Skill)\r\n Teradata Active Data Warehousing Knowledge (Primary Skill)\r\n Teradata Applications (Primary Skill)\r\n Teradata Architecture (Primary Skill)\r\n Teradata Platform family (Primary Skill)\r\n Teradata Aster (Knowledge)\r\n Tools – Advanced Analytics (Knowledge)\r\n Tools – Business Intelligence (Primary Skill)\r\n Tools – Development (Primary Skill)\r\n Tools – Enterprise Application Integration (Primary Skill)\r\n Tools – ERP Software (Knowledge)\r\n Tools – Data Integration (Knowledge)\r\n Tools – Job Control and Scheduling (Knowledge)\r\n Tools – Modeling (Knowledge)\r\n Tools – Monitoring and Control (Knowledge)\r\n Tools – Operating Systems (Knowledge)\r\n Tools – Security (Knowledge)\r\n Tools – Teradata (Primary Skill)\r\n Tools – Testing (Knowledge)\r\n Tools – Open Source (Knowledge)\r\n Tools – DevOps and Automation (Knowledge)"},{"JobTitle":" Data and Information Specialist","Url":"https://www.indeed.co.za/rc/clk?jk=5cb18cd734a555ab&fccid=baf8f1e7b7eec29f&vjs=3","Source":" JobScape","Salary":null,"Age":"30+ days ago","Location":"City of Johannesburg, Gauteng","Description":"\r\n\r\n\r\nCity of Johannesburg, Gauteng\r\nHaving 7 8 years of experience in design development of ETL packages using SSIS along with good knowledge of data warehousing concepts. \r\n\r\n o Able to quickly gain a working knowledge of the technical environments in which the system operates when joining a new projectteam \r\n\r\n o Should have the ability to create technicaldesign artifacts to demonstrate technical flows, specification, and interfaces of the system \r\n\r\n o Coordinate with various teams for migration of databases to newer versions and to newer infrastructure. \r\n\r\n o Data analysis \r\n\r\n o Support the existing ETL jobs SSIS packages \r\n\r\n o Mentor the team members and guide them to solve various complex challenges. \r\n\r\n Conduct solution reviews for the packages that will be productionized and provide expert commentssuggestions. \r\n\r\n Must Have \r\n\r\n SSIS using VS Data Tools 20132015 and BIDS \r\nExperience with SQL 2008 R2SQL 2014SQL 2016 \r\nExperience with Oracle \r\nUnderstanding of Data models \r\nStrong troubleshooting and problemsolving skills \r\nWell verse with SDLC, Agile and Quality processes \r\nExcellent verbal and written communication skills \r\nSound understanding of IT infrastructure and how data warehouse connects to the IT infrastructure \r\n\r\n Nice to have \r\n\r\n Exposure to Big Data Hadoop Horton Works \r\nExperience on Attunity Replicate tool. \r\nCertifications in the related areas. \r\nSalary \r\n\r\n To Apply \r\nWhatsapp the keyword JOB to"},{"JobTitle":" Senior .NET Developer","Url":"https://www.indeed.co.za/rc/clk?jk=16add4c850afe235&fccid=399f716a0307ef50&vjs=3","Source":" Communicate Recruitment","Salary":" R700 000 - R800 000 a year","Age":"27 days ago","Location":"Johannesburg North, Gauteng","Description":"\r\n\r\n\r\nJohannesburg North, Gauteng\r\n\r\n\r\nR700 000 - R800 000 a year\r\n\r\n\r\n\r\nSenior .NET Developer\r\n\r\n\r\n\r\nRef. No:\r\n\r\nCER008135/TKE\r\n\r\n\r\n\r\nSalary Range:\r\n\r\nR700000 - R800000 Annually\r\n\r\n\r\n\r\nBrief Description:\r\n\r\nMy client is looking for an individual who will be responsible for development, enhancement and maintenance of all Post Trade vendor and bespoke application suites that fall within the Markets business area.\r\n\r\n\r\n\r\nJob Description:\r\n\r\n\r\nEducation: \r\nBachelor degree in related field or comparable experience in the web development required. Substantial experience working with similar technologies and environment\r\nMinimum 6 years’ experience using .NET technology stack such as (Web API, MVC, .NET4.5, .NET Core, WCF, Unity)\r\nMust have a good grasp of design principles (Solid, GOF Patterns and etc)\r\nFamiliarity with various design and architectural patterns\r\nFamiliarity with standard SDLC process and Agile/Scrum Methodology\r\nImplementing automated testing platforms and unit tests\r\nFamiliarity with versioning control tools {{such as Git, TFS and etc}}\r\nMust be able to design, develop, troubleshoot, and debug systems and their various integration points\r\nGood knowledge in writing SQL scripts, stored procedures and database design\r\nFamiliarity with Microsoft SQL Server 2008/12/14\r\nKnowledge of TeamCity a plus\r\nKnowledge of SSIS development a plus\r\nExposure to Non-Microsoft DB technologies a plus (MySQL, MongoDB, Hadoop etc.)\r\n\r\nSkills:\r\nDisplay an attitude of innovation\r\nDedicated and committed to achieving results\r\nSelf-motivated\r\nAble to adapt to change quickly\r\nConvey a professional image\r\nBe able to work under pressure\r\nStrong analytical and problem solving\r\nExperience working in a team-oriented, collaborative environment\r\nExcellent written and oral communication skills\r\nPresenting & Communicating Information (Familiar with)\r\n\r\nDescription:\r\nTo translate, design, build bespoke applications given a set of requirements\r\nTo assist business during QA testing, resolving bugs and issues as their being discovered Frequent communication with colleagues and management\r\nCollaborate with IT/Business for any technical assistance required Integrating data from various back-end services and databases\r\nPerform website analysis and diagnostics according to planned schedules or after any website or product revisions\r\nDiagnose production issues and provide assistance to production support staff (2nd level support) Stay plugged into emerging technologies/industry trends and apply them into operations and activities\r\nEnsure work done adheres to quality guidelines and standards for all activities (e.g. naming conventions, code comments) as agreed in the team Be responsible for maintaining, expanding, and scaling all Universal sites\r\n\r\nPlease visit our website www.communicate.co.za to submit your CV directly or to view other I.T related jobs. If you have not had any response in two weeks, please consider your application unsuccessful. Your profile will be kept on our database for any other suitable positions.\r\n\r\n\r\n\r\nWe also invite you to contact us to discuss other exciting career opportunities in our niche area! For more information, please call Thato Kekana on 087 351 0711 or email on thkekana@communicate.co.za\r\n\r\n\r\nSector:\r\n\r\nDevelopment and Programming\r\n\r\n\r\nTown:\r\n\r\nJohannesburg North\r\n\r\n\r\nDate:\r\n\r\n07/07/2019\r\n\r\n\r\nExpiry Date:\r\n\r\n06/08/2019"},{"JobTitle":" LINUX INTERN - Linux Lover!","Url":"https://www.indeed.co.za/company/IT-Select-for-Randburg/jobs/Linux-Intern-d8f5e22570b72b87?fccid=a3e33af475619698&vjs=3","Source":" IT Select for Randburg","Salary":null,"Age":"30+ days ago","Location":"Randburg, Gauteng","Description":"\r\n\r\n\r\nRandburg, Gauteng\r\n\r\n\r\nInternship\r\n\r\nDie-hard Linux Tech-head for SysAdmin INTERNSHIPin Randburg.\r\n\r\nCan you make the OS jump through hoops because you Live-4-Linux?\r\nPaid internship for a complete enthusiast with great Linux skills.\r\nWork exp & Certified Linux SysAdmin is nice-to-have.\r\nLove for systems & real flair for Linux essential.\r\nYou’ll learn ITIL & do reporting & entry-level tasks, while being mentored in additional skills (focus on Hadoop & Isilon Admin); to become a full team member.\r\nYour Isilon / Hadoop exposure will be a huge bonus!\r\nLocated Randburg (possibly move to Constantia Kloof.)\r\nFair market related intern payment - regularly reviewed.\r\n\r\nTell me WHY you're the one on mail to Heather itselect.co.za\r\n\r\nJob Type: Internship\r\n\r\nExperience:\r\nLinux - Even INFORMAL at Home Networks etc: 3 years (Required)\r\n\r\nLanguage:\r\nLINUX (Required)"},{"JobTitle":" Pre-sales Consultant - DMS","Url":"https://www.indeed.co.za/rc/clk?jk=581323c40e200a05&fccid=2a90b491c8a55d0f&vjs=3","Source":" FICO","Salary":null,"Age":"30+ days ago","Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\nFounded in 1956, FICO is a leading analytics software company, helping businesses in over ninety countries make better decisions. Through its three lines of business – decision management software, business applications, and \r\n scores - FICO works across multiple industries to manage risk, fight fraud, build more profitable customer relationships, optimise operations and meet strict regulations. Many of our products reach industry-wide adoption, such as the FICO Score - the standard measure of consumer credit risk in the United States - and the Falcon Fraud Platform, which helps to protect 2.5 billion credit and debit cards globally against fraud. \r\n\r\nJob Description \r\n\r\nThe role \r\n\r\n\r\nFICO is recruiting for a Consultant to join FICO’s Decision Management Suite Pre-Sales Consulting team. The Decision Management Suite provides an easy way for customers to evaluate, customise, deploy and scale state-of-the-art analytics and decision management solutions and incorporates best-of-breed capabilities for analytics, decisioning, optimisation, data visualisation and exploration, and rapid application development. \r\n\r\nThe successful candidate will be based in our office in Johannesburg, focussing on the South African market. \r\n\r\n\r\nResponsibilities \r\nEngage with clients and prospects conservatively to understand their needs and pain points, and define and propose viable solutions based on FICO’s software, services and business consulting with a clear focus on business value and customer satisfaction \r\nDevelop and maintain a breadth and depth of knowledge on the functional and technical elements of the products in the FICO Decision Management Suite \r\nCreate and deliver presentations and demonstrations; contribute functional/technical/domain written content for RFQ, RFI and RFP responses; contribute to and lead client workshops \r\nContinually expand your domain knowledge of business processes in FICO’s core vertical industries and horizontal application areas \r\nUnderstand your client’s business, industry context and market pressures \r\nPlan, execute and manage targeted proofs of concept with well-defined success criteria \r\nManage a portfolio of client opportunities and actively contribute to the progression of each \r\nContribute to demand generation activities such as marketing events, webinars, blogs and white papers \r\n\r\n\r\nYour experience \r\nSignificant experience working either: vendor-side in pre-sales, or as an architect, with experience in enterprise business to business (B2B) solutions, ideally in horizontal capabilities such as Decision Management or Business Process Management \r\n‘in house’ as a Risk Technologist for a blue-chip financial services client \r\n\r\nA solid understanding of business-to-consumer (B2C) risk management processes in banking, consumer finance, automotive, telecoms, retail or insurance \r\nFirm understanding of what is required to deploy high performance decision automation systems \r\nProven practical experience of software packages falling into the following categories: Decision Management/Business Rule Management Systems \r\nPackages for Business Process Management (BPM) Rapid Application Development (RAD); and Business Intelligence (BI) \r\nMathematical optimisation \r\nPredictive analytics, model management, and data mining \r\nData visualisation and exploration \r\n\r\nApplied business analysis techniques including requirements capture and business process and decision modelling, ideally with working knowledge of the relevant industry standards DMN, BPMN and CMMN \r\nHands on, demonstrable experience with a wide range of industry standard technologies such as Java, web technologies such as HTML/JavaScript, relational databases, Windows/Linux systems, Python and R as well as big data technologies such as Apache Hadoop or Spark \r\n\r\n\r\nAbout you \r\nYou are passionate about the ability of technology and advanced analytics to power real world business applications across a wide range of use cases in the financial services sector and beyond \r\nYou are a team player who enjoys working with others to reach a goal and for whom customer satisfaction is paramount \r\nYou are a strong communicator and have excellent written language, verbal, and presentation skills \r\nYou are a self-starter who enjoys working in a dynamic environment, and enjoys international travel \r\n\r\n\r\nQualifications \r\nBachelor’s degree or higher, ideally in a subject such as Computer Science, Mathematics, Engineering, or Operations Research \r\nLanguage skills Fluent in English \r\nEuropean languages are an advantage"},{"JobTitle":" Software Engineer – Platform and DevOps","Url":"https://www.indeed.co.za/rc/clk?jk=7939c2c7d43a73e0&fccid=26d01f64c124ba71&vjs=3","Source":" Datafin IT Recruitment","Salary":null,"Age":"30+ days ago","Location":"Cape Town, Western Cape","Description":"\r\n\r\n\r\nCape Town, Western Cape\r\n\r\n\r\nPermanent\r\n\r\n\r\n\r\nA young, dynamic, leading Online Retailer in Cape Town is looking for a Software Engineer – Platform and DevOps to join their teams in Cape Town (CBD), Stellenbocsh and JHB.\r\n\r\n\r\n\r\nREQUIREMENTS:\r\n\r\n3 year computer science degree (or equivalent experience)\r\n\r\nAt least 2 years of professional experience\r\n\r\nAn understanding of computer science fundamentals, including linux and operating systems, networking, and some development.\r\n\r\n\r\n\r\nAdvantageous\r\n\r\nLinux experience (Ubuntu/Debian)\r\n\r\nShell scripting\r\n\r\nPython, ruby, or a similar language\r\n\r\nUnderstanding of linux and OS fundamentals (processes, signals, sysctl)\r\n\r\nGeneral debugging tools on linux (tcpdump, vmstat, strace)\r\n\r\nSystem administration (users, packages, ntp, smtp)\r\n\r\nNetwork theory and administration (linux)\r\n\r\nConfiguration management (chef, puppet)\r\n\r\nCommon web stack applications (nginx, apache, varnish, HAProxy, MemCache)\r\n\r\nDatabase operations, query optimization, backup strategy\r\n\r\nHardware installation and configuration (raid, filesystems, lvm)\r\n\r\nMetrics, monitoring (NaGios, Zabbix, sensu, graphite)\r\n\r\nSecurity (iptables, selinux, ssh)\r\n\r\nCloud infrastructure (AWS, Google, Azure)\r\n\r\nVirtualization technologies (xen, kvm)\r\n\r\nDistributed systems\r\n\r\nCapacity planning\r\n\r\nHadoop\r\n\r\n\r\n\r\n While we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.\r\n\r\n\r\n\r\nCOMMENTS:\r\n\r\nWhen applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence. Please e-mail a word copy of your CV to bev@datafin.com and mention the reference numbers of the jobs."},{"JobTitle":" Solution Architect","Url":"https://www.indeed.co.za/rc/clk?jk=2aacc3eb241d4559&fccid=e5b0c7e8f0872636&vjs=3","Source":" Nedbank","Salary":null,"Age":"30+ days ago","Location":"Johannesburg, Gauteng","Description":"\r\n\r\n\r\nJohannesburg, Gauteng\r\n\r\n\r\n\r\nNedbank Recruiting\r\n\r\n\r\n\r\n Job Id \r\n\r\n\r\n96142\r\n\r\n\r\n Job Purpose \r\n\r\n\r\nDesigning Patterns, on a Logical and physical layer, solutions around data integration, providing consulting to all clusters, input to the EDP Warehouse. Cover all aspects of security regarding all data integration, and security regarding all technology integration stacks. \r\n\r\n\r\nJob Responsibilities \r\n\r\nGenerate innovative approaches and solutions to complex issues.\r\nDesign solutions that require creative investigations of alternative architectural solutions.\r\nDesign architecture using innovative technologies in consultation with the patterns approval by Enterprise Architecture.\r\nCollaborate with the Architecture team to identify the right technologies to be used in the applications.\r\nContribute across the technology stack, from database and DevOps infrastructure that supports continuous deployment.\r\n\r\n\r\nEssential Qualification \r\n\r\nMatric / Grade 12 / National Senior Certificate\r\nAdvanced Diplomas/National 1st Degrees\r\n\r\n\r\nPreferred Qualification \r\n\r\nBachelor’s degree or equivalent combination of education and work experience in development and design (Application, Infrastructure, etc.).\r\nBachelor’s Degree in either Information Systems, Informatics or Computer Science or Engineering (or equivalent work experience).\r\n\r\n\r\nPreferred Certifications \r\n\r\nInformation Technology Architect Certification (ITAC) (Open Group) – Advantageous.\r\nTOGAF Foundation Training. – Advantageous.\r\nTOGAF / Zachman Certification. – Advantageous.\r\n\r\n\r\nMinimum Experience Level \r\n\r\n5-10 years’ experience with ETL and data design.\r\n\r\n\r\n\r\nAdvantageous experience (not a disqualifier):\r\nProgramming experience with Web, Windows .NET framework, PowerShell, and C#, with at least 3 years as a senior software development engineer and/or technical lead with similar roles.\r\nExperience developing customer facing applications.\r\nExperience with ASP. Net Web API or ASP. Net MVC, JavaScript, JSON and REST, NoSQL databases.\r\n\r\nSuccessful track record delivering high quality products on time while working in teams and following Agile methodologies.\r\n\r\nSkills (Technologies, systems or software knowledge etc.):\r\nAb Initio\r\nCDC DB2\r\nIDR\r\nKafka\r\nHadoop Stack\r\nData Warehousing\r\n\r\n\r\nBehavioural Competencies \r\nContinuous Learning \r\nCollaborating \r\nCustomer Focus \r\nInitiating Action \r\nWork Standards \r\nManaging Work \r\nTechnical/Professional Knowledge and Skills\r\n\r\n\r\n\r\n-\r\n\r\nPlease contact the Nedbank Recruiting Team at +27 860 555 566"},{"JobTitle":" German speaking Business Intelligence Data Analytics Consult...","Url":"https://www.indeed.co.za/rc/clk?jk=724bf4cd7b44480f&fccid=3531467db7a80912&vjs=3","Source":" Language Recruiters","Salary":null,"Age":"30+ days ago","Location":"South Africa","Description":"\r\n\r\n\r\nSouth Africa\r\nWould you like to work for a company that stay at the forefront of the latest technologies This team has an great job opportunity for a German speaking Business Intelligence Data Analytics Consultant looking to work in Cape Town, South Africa You will provide their clients with an extremely high level of technical expertise. If youre looking to work on challenging projects where you will never be bored, this job could be perfect for you \r\n\r\n Your key job responsibilities as the German speaking Business Intelligence Data Analytics Consultant in Cape Town, South Africa will include \r\n\r\n Be proficient in all pillars of the Microsoft Business Intelligence offering, including Azure technologies \r\nProficient in a range of NoSQL based offerings, such as graph databases and Azure HDInsights, and modelling and building solutions using those offerings \r\nConfiguring, Developing, Optimising, Testing, and Documenting solutions developed andor infrastructure implemented \r\nGathering Requirements from Business and IT Stakeholders \r\nDelivering and installing suitable solutions for customers \r\nActively participating in local technical forums, such as User Groups, involving Microsoft and their wider Developer community \r\n\r\n Requirements for this German speaking Business Intelligence Data Analytics Consultant job in Cape Town, South Africa \r\n\r\n Must be fluent in German and English \r\nAdvanced TSQL and SQL Server 2012, including Azure SQL \r\nSSIS, SSRS, and SSAS Multidimensional Expressions MDX \r\nSQL Server Administration Performance Tuning \r\nPowerBI Highly Beneficial \r\nTableau Highly Beneficial \r\nQlikView Beneficial \r\nSSAS Tabular Modelling Beneficial \r\nData Analysis Expressions DAX Beneficial \r\nAzure HDInsights andor Hadoop and related technologies Highly Beneficial \r\nMachine learning andor data mining Beneficial \r\nIoT, data ingestion, and stream analytics Beneficial \r\nWorking as part of a Scrum development team \r\n\r\n If you meet the above requirements for this German speaking Business Intelligence Data Analytics Consultant job in Cape Town, South Africa, make sure you get in touch today by sending your CV through to"},{"JobTitle":" Intermediate .NET Developer","Url":"https://www.indeed.co.za/rc/clk?jk=2e88311dbd44d8fd&fccid=399f716a0307ef50&vjs=3","Source":" Communicate Recruitment","Salary":" R400 000 - R500 000 a year","Age":"16 days ago","Location":"Johannesburg North, Gauteng","Description":"\r\n\r\n\r\nJohannesburg North, Gauteng\r\n\r\n\r\nR400 000 - R500 000 a year\r\n\r\n\r\n\r\nIntermediate .NET Developer\r\n\r\n\r\n\r\nRef. No:\r\n\r\nCER008172/TKE\r\n\r\n\r\n\r\nSalary Range:\r\n\r\nR400000 - R500000 Annually\r\n\r\n\r\n\r\nBrief Description:\r\n\r\nMy client is looking for an individual who will be responsible for development, enhancement and maintenance of all Post Trade vendor and bespoke application suites that fall within the Markets business area.\r\n\r\n\r\n\r\nJob Description:\r\n\r\n\r\nEducation: \r\nBachelor degree in related field or comparable experience in the web development required. Substantial experience working with similar technologies and environment\r\nMinimum 3 years’ experience using .NET technology stack such as (Web API, MVC, .NET4.5, .NET Core, WCF, Unity)\r\nMust have a good grasp of design principles (Solid, GOF Patterns and etc)\r\nFamiliarity with various design and architectural patterns\r\nFamiliarity with standard SDLC process and Agile/Scrum Methodology\r\nImplementing automated testing platforms and unit tests\r\nFamiliarity with versioning control tools {{such as Git, TFS and etc}}\r\nMust be able to design, develop, troubleshoot, and debug systems and their various integration points\r\nGood knowledge in writing SQL scripts, stored procedures and database design\r\nFamiliarity with Microsoft SQL Server 2008/12/14\r\nKnowledge of TeamCity a plus\r\nKnowledge of SSIS development a plus\r\nExposure to Non-Microsoft DB technologies a plus (MySQL, MongoDB, Hadoop etc.)\r\n\r\nSkills:\r\nDisplay an attitude of innovation\r\nDedicated and committed to achieving results\r\nSelf-motivated\r\nAble to adapt to change quickly\r\nConvey a professional image\r\nBe able to work under pressure\r\nStrong analytical and problem solving\r\nExperience working in a team-oriented, collaborative environment\r\nExcellent written and oral communication skills\r\nPresenting & Communicating Information (Familiar with)\r\n\r\nDescription:\r\nTo translate, design, build bespoke applications given a set of requirements\r\nTo assist business during QA testing, resolving bugs and issues as their being discovered Frequent communication with colleagues and management\r\nCollaborate with IT/Business for any technical assistance required Integrating data from various back-end services and databases\r\nPerform website analysis and diagnostics according to planned schedules or after any website or product revisions\r\nDiagnose production issues and provide assistance to production support staff (2nd level support) Stay plugged into emerging technologies/industry trends and apply them into operations and activities\r\nEnsure work done adheres to quality guidelines and standards for all activities (e.g. naming conventions, code comments) as agreed in the team Be responsible for maintaining, expanding, and scaling all Universal sites\r\n\r\nPlease visit our website www.communicate.co.za to submit your CV directly or to view other I.T related jobs. If you have not had any response in two weeks, please consider your application unsuccessful. Your profile will be kept on our database for any other suitable positions.\r\n\r\n\r\n\r\nWe also invite you to contact us to discuss other exciting career opportunities in our niche area! For more information, please call Thato Kekana on 087 351 0711 or email on thkekana@communicate.co.za\r\n\r\n\r\nSector:\r\n\r\nDevelopment and Programming\r\n\r\n\r\nTown:\r\n\r\nJohannesburg North\r\n\r\n\r\nDate:\r\n\r\n18/07/2019\r\n\r\n\r\nExpiry Date:\r\n\r\n17/08/2019"},{"JobTitle":" Information Security Officer","Url":"https://www.indeed.co.za/rc/clk?jk=6a4939b55f733c24&fccid=baf8f1e7b7eec29f&vjs=3","Source":" JobScape","Salary":null,"Age":"30+ days ago","Location":"City of Johannesburg, Gauteng","Description":"\r\n\r\n\r\nCity of Johannesburg, Gauteng\r\nAs an Information Security Officer you will be accountable to oversee and coordinate information security across the bank to identify and establish information security initiatives and standards throughout the organization. \r\n\r\n MIN REQUIREMENTS \r\n\r\n Power BI \r\nBig Data \r\nHadoop \r\nPenetration testing ethical hacking experience is quite critical \r\nDUTIES AND RESPONSIBILITIES \r\n\r\n Design the IT security architecture as well as appropriate security Controls in line with FRBG policies, processes, standards and procedures \r\nEnsure that proper and adequate IT technology and tools are in place to enforce these controls \r\nYou will also be responsible for planning, directing and coordinating the organizations information security policies by setting procedures and guidelines that will ensure all information systems are functional and secure \r\nQualifications \r\n\r\n 8 years or more experience in the information security environment \r\nUnderstand the information security assessment and auditing procedures \r\nKnowledge of enterprise scale network and host based IDS structures \r\nKnowledge of enterprise scale firewall architectures \r\nUnderstand the ecommerce security application \r\nEthical Hacking qualification or certificate advantageous \r\nDegree or Diploma in Computer Science with CISMCISSP Certification \r\n\r\n To Apply \r\nWhatsapp the keyword JOB to"},{"JobTitle":"Hadoop Developer","Url":"https://www.indeed.co.za/rc/clk?jk=3118f1f7173843d0&fccid=dd616958bd9ddc12&vjs=3","Source":" HR Genie","Salary":" R450 - R500 an hour","Age":"25 days ago","Location":"Gauteng","Description":"\r\n\r\n\r\nGauteng\r\n\r\n\r\nR450 - R500 an hour\r\nMy client in telecommunication sector is looking to fill in a position of Hadoop Developer for a 6 months contract"},{"JobTitle":" Data Warehouse Developer Lead","Url":"https://www.indeed.co.za/rc/clk?jk=4626685e77dee4a2&fccid=e87d374965cc1f57&vjs=3","Source":" AWCA Human Capital","Salary":" R80 000 a year","Age":"30+ days ago","Location":"Western Cape","Description":"\r\n\r\n\r\nWestern Cape\r\n\r\n\r\nR80 000 a year\r\n\r\n\r\nREQUIREMENTS\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nIntimate knowledge of Microsoft SQL Server (required)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nGood understanding and knowledge of SSIS, SSRS and SSAS\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nSSIS: Designing, Implementation and testing of ETL packages (required)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nSSRS: Designing and development of Reports (required)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nSSAS: Design, implementation and testing of Tabular and Multi-Dimensional Cubes (highly advantageous)\r\n\r\n\r\n\r\n\r\n\r\n\r\nKnowledge of Oracle database is advantageous and Power BI knowledge is preferred\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nFamiliar with agile development process\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nPrevious experience working with Hadoop, Azure &/or Apache Spark and 'BigData'\r\n\r\n\r\n\r\n\r\nRESPONSIBILITES\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nDevelop and deploy full Data warehousing strategy for the company.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nCo-ordinate and develop data integration for all third-party systems\r\n\r\n\r\n\r\n\r\n\r\n\r\nLiaise with business with respect to current and future data requirements\r\n\r\n\r\n\r\n\r\n\r\n\r\nManage a team of SQL and Reports Developers"}]